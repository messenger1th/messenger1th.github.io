{"meta":{"title":"Epoch","subtitle":"Epoch Blog","description":"Epoch Blog","author":"Epoch","url":"https://messenger1th.github.io","root":"/"},"pages":[{"title":"about","date":"2022-10-01T03:22:30.000Z","updated":"2024-07-06T12:41:09.200Z","comments":false,"path":"about/index.html","permalink":"https://messenger1th.github.io/about/index.html","excerpt":"","text":""}],"posts":[{"title":"架构","slug":"Work/架构","date":"2024-07-27T11:59:29.800Z","updated":"2024-07-27T11:59:33.921Z","comments":true,"path":"2024/07/27/Work/架构/","link":"","permalink":"https://messenger1th.github.io/2024/07/27/Work/%E6%9E%B6%E6%9E%84/","excerpt":"","text":"","categories":[{"name":"Work","slug":"Work","permalink":"https://messenger1th.github.io/categories/Work/"}],"tags":[]},{"title":"work","slug":"Work/work","date":"2024-07-24T15:06:26.496Z","updated":"2024-07-27T12:52:05.559Z","comments":true,"path":"2024/07/24/Work/work/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Work/work/","excerpt":"","text":"工作记录一下从学生时代过渡到工作，需要的技能和工具。 版本管理：git 开发环境：Linux的命令行使用 接口测试、联调：apipost、postman、swagger、JMeter 定位bug 查日志异常 查线上事故 其他 日志打印与上报：日志库、Prometheus 日志收集与分析：elk stack、Prometheus 容器编排：kubernates 链路追踪：openmetery 错误与异常处理 备份与恢复 接口文档：swagger 接口测试工具：apifox、postman 性能分析工具：pprof 正向代理和反向代理 负载均衡 CDN Restful 分布式锁原理和使用 同步：阻塞等待返回 异步：告诉你需要执行，只是触发流程，并不等待，常用实现有， 异步实现：用户调用服务端的接口，接口逻辑只是，记录一个消息到消息队列或其他的存储组件中，然后就返回结果，告诉用户记下了。具体的执行时间调用方并不关心。 结果查询：你执行完了，得通知我吧，所以常用的方式有 用户主动轮训，每隔一段时间请求服务端提供的接口（这里调哪个，具体怎么取就双方自行约定了） 用户注册回调，服务端执行完了后调用用户注册好的回调通知用户。 鉴权cookie session toke JWT 开发规范 请求和结果、耗时、trace等日志打印放在拦截器或中间件层去处理。 测试用例 集成和部署：CI&amp;CD 项目、目录、文件分类管理 dao层 model层 MVC Web同源跨域问题同源是指，域名，协议，端口相同，非同源的客户端脚本在没有明确授权的情况下，不能读写对方资源，在请求数据时，浏览器会在控制台中报一个异常，提示拒绝访问。非同源受到的限制: cookie不能读取 dom无法获得 ajax请求不能发送 跨域是指跨域名的访问，以下情况都属于跨域： 域名不同 www.jd.com与 www.taobao.com 域名相同，端口不同 www.jd.com:8080 与 www.jd.com:8081 二级域名不同 http://item.jd.com 与 http://miaosha.jd.com 跨域问题是浏览器对于ajax请求的一种安全限制：一个页面发起的ajax请求，只能是于当前页同域名的路径，这能有效的阻止跨站攻击。 因此：跨域问题 是针对ajax的一种限制。 JSONP跨域：JSON with Padding CORS跨域：全称”跨域资源共享”（Cross-origin resource sharing） JSONPJSONP：由于同源策略的限制，XmlHttpRequest只允许请求当前源（域名、协议、端口）的资源。而动态添加一个标签，script标签的src属性是没有跨域的限制的。这样一来,这种跨域方式就与ajax XmlHttpRequest协议无关了。 我们可以通过使用html的script标记来进行跨域请求，并在响应中返回要执行的script代码，其中可以直接使用JSON传递javascript对象,这种跨域的通讯方式称为JSONP。 JSONP的优点是：它不像XmlHttpRequest对象实现的Ajax请求那样受到同源策略的限制；它的兼容性更好，在更加古老的浏览器中都可以运行（IE跨域要用JSONP来解决），不需要XmlHttpRequest或ActiveX的支持；并且在请求完毕后可以通过调用callback的方式回传结果。 缺点是：需要服务的支持，且只能发起GET请求 CORSCORS需要浏览器和服务器同时支持，才可以实现跨域请求，目前几乎所有浏览器都支持CORS，IE则不能低于IE10。CORS的整个过程都由浏览器自动完成，前端无需做任何设置，跟平时发送ajax请求并无差异。所以，实现CORS的关键在于服务器，只要服务器实现CORS接口，就可以实现跨域通信。 它允许浏览器向跨源服务器，发出XMLHttpRequest请求，从而克服了AJAX只能同源使用的限制。 对于简单请求，浏览器会直接发送CORS请求，具体说来就是在header中加入origin请求头字段。同样，在响应头中，返回服务器设置的相关CORS头部字段，Access-Control-Allow-Origin字段为允许跨域请求的源。请求时浏览器在请求头的Origin中说明请求的源，服务器收到后发现允许该源跨域请求，则会成功返回。 简单请求 请求方法是以下三种方法之一： HEAD GET POST HTTP的头信息不超出以下几种字段： Accept Accept-Language Content-Language Last-Event-ID Content-Type：只限于三个值application/x-www-form-urlencoded、multipart/form-data、text/plain 当浏览器发现发现的ajax请求是简单请求时，会在请求头中携带一个字段：Origin. Origin中会指出当前请求属于哪个域（协议+域名+端口）。服务器会根据这个值决定是否允许其跨域。 如果服务器允许跨域，需要在返回的响应头中携带下面信息：Access-Control-Allow-Origin：可接受的域，是一个具体域名或者*，代表任意。 快速熟悉项目业务梳理 业务背景作用：这个项目是做什么的，解决什么问题 业务定位及上下游：业务架构所处位置、上下游有哪些，谁调用我们，我们又依赖谁。 业务上下游：我们和哪些组有业务依赖，需要和哪些组频繁合作 代码上下游： 技术梳理看技术文档 架构图 核心操作链路图、流程图、数据流向图：明白我们的代码上下游有什么 谁会使用or调用本系统 我们的上游什么情况下调用我们的接口、同步还是异步、架构是怎么样的、核心流程是怎么样的 核心数据库表有哪些 Redis缓存key有哪些 熟悉代码： 代码工程结构 走一遍核心链路：粗看，主要是印证架构图和流程图 再走一遍核心链路，查看重要细节 获取了哪些参数 有哪些不可少的步骤 有哪些由于历史原因导致的问题或者不直观的点 缓存是怎么处理的 业务发展迭代方向通过 了解组内最近需求内容，正在处理什么问题和痛点 了解部门最近战略方向 作用是方便了解业务优先级和代码扩张性考虑方向","categories":[{"name":"Work","slug":"Work","permalink":"https://messenger1th.github.io/categories/Work/"}],"tags":[]},{"title":"实践","slug":"Work/实践","date":"2024-07-24T14:47:34.225Z","updated":"2024-07-24T14:47:34.225Z","comments":true,"path":"2024/07/24/Work/实践/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Work/%E5%AE%9E%E8%B7%B5/","excerpt":"","text":"技术团队网页https://www.zhihu.com/question/20708586 腾讯团队：https://github.com/tencent 微信团队：https://github.com/tencent-wechat 微信前端团队：https://github.com/WechatFE 阿里巴巴团队：https://github.com/alibaba/ 阿里妈妈团队：https://github.com/thx 百度前端团队：https://github.com/ecomfe 百度前端研发团队：https://github.com/fex-team 百度前端技术团队：https://github.com/baidufe 百度人工智能团队：https://github.com/baidu-research 华为团队：https://github.com/Huawei 网易团队：https://github.com/netease 360团队：https://github.com/Qihoo360 小米团队：https://github.com/xiaomi 58团队：https://github.com/58code 携程团队：https://github.com/ctripcorp 饿了么团队：https://github.com/eleme 美团团队：https://github.com/Meituan 美团点评技术团队：https://github.com/Meituan-Dianping 大众点评团队：https://github.com/dianping 滴滴团队：https://github.com/didi 知乎团队：https://github.com/zhihu 哔哩哔哩团队：https://github.com/Bilibili 新浪微博团队：https://github.com/weibocom 搜狐团队：https://github.com/SOHUDBA 豆瓣团队：https://github.com/douban https://tech.meituan.com/ 公众号哔哩哔哩技术 得物技术","categories":[{"name":"Work","slug":"Work","permalink":"https://messenger1th.github.io/categories/Work/"}],"tags":[]},{"title":"实践参考","slug":"Work/实践参考","date":"2024-07-24T14:47:34.225Z","updated":"2024-07-24T14:47:34.225Z","comments":true,"path":"2024/07/24/Work/实践参考/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Work/%E5%AE%9E%E8%B7%B5%E5%8F%82%E8%80%83/","excerpt":"","text":"技术团队网页https://www.zhihu.com/question/20708586 腾讯团队：https://github.com/tencent 微信团队：https://github.com/tencent-wechat 微信前端团队：https://github.com/WechatFE 阿里巴巴团队：https://github.com/alibaba/ 阿里妈妈团队：https://github.com/thx 百度前端团队：https://github.com/ecomfe 百度前端研发团队：https://github.com/fex-team 百度前端技术团队：https://github.com/baidufe 百度人工智能团队：https://github.com/baidu-research 华为团队：https://github.com/Huawei 网易团队：https://github.com/netease 360团队：https://github.com/Qihoo360 小米团队：https://github.com/xiaomi 58团队：https://github.com/58code 携程团队：https://github.com/ctripcorp 饿了么团队：https://github.com/eleme 美团团队：https://github.com/Meituan 美团点评技术团队：https://github.com/Meituan-Dianping 大众点评团队：https://github.com/dianping 滴滴团队：https://github.com/didi 知乎团队：https://github.com/zhihu 哔哩哔哩团队：https://github.com/Bilibili 新浪微博团队：https://github.com/weibocom 搜狐团队：https://github.com/SOHUDBA 豆瓣团队：https://github.com/douban https://tech.meituan.com/ 公众号哔哩哔哩技术 得物技术","categories":[{"name":"Work","slug":"Work","permalink":"https://messenger1th.github.io/categories/Work/"}],"tags":[]},{"title":"对接","slug":"Work/对接","date":"2024-07-24T14:47:34.225Z","updated":"2024-07-24T14:47:34.225Z","comments":true,"path":"2024/07/24/Work/对接/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Work/%E5%AF%B9%E6%8E%A5/","excerpt":"","text":"对接记录一些工作时会打交道的内容，比如前端、大数据、推荐系统、搜索引擎、视频流等等，简单了解他们的机制和原理，会提高沟通的效率。 具体来说，有 前端：web、html、css、js；vue和react框架 客户端：安卓、IOS；uni-app。 大前端：前端、客户端、小程序 推荐引擎 搜索引擎 视频流：ffmpeg","categories":[{"name":"Work","slug":"Work","permalink":"https://messenger1th.github.io/categories/Work/"}],"tags":[]},{"title":"调研与选型","slug":"Work/调研与选型","date":"2024-07-24T14:47:34.225Z","updated":"2024-07-24T14:47:34.225Z","comments":true,"path":"2024/07/24/Work/调研与选型/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Work/%E8%B0%83%E7%A0%94%E4%B8%8E%E9%80%89%E5%9E%8B/","excerpt":"","text":"调研与选型可以实际测试，压测用数据说话 数据库数据库类型：结构化的还是非结构化的，非结构化的话是kv、向量还是图类型；又或者是混合 数据规模： 读写比例： 事务处理、一致性要求： 并发QPS要求： 存储成本： 使用（接入、部署、运维）成本： 开发框架编程语言技术栈架构微服务服务注册与发现服务注册与发现，通常会用到注册中心，记录了有哪些服务和对应的实例。常用的注册中心有 consul etcd nacos 服务配置 链路追踪 dapper OpenTelemetry 中间件作用是在一个请求来临时，对请求的参数做一些处理，比如记录日志、记录trace、校验参数、认证、熔断、限流等等。 常见的中间件有 logging: 用于请求日志的记录。 metrics: 用于启用 metric。 recovery: 用于 recovery panic。 tracing: 用于启用 trace。 validate: 用于处理参数校验。 metadata: 用于启用元信息传递。 auth: 用于提供基于 JWT 的认证请求。 ratelimit: 用于服务端流量限制。 circuitbreaker: 用于客户端熔断控制。 通常由框架提供，例如微服务框架kratos，grpc都提供了中间件的功能。","categories":[{"name":"Work","slug":"Work","permalink":"https://messenger1th.github.io/categories/Work/"}],"tags":[]},{"title":"项目管理","slug":"Work/项目管理","date":"2024-07-24T14:47:34.225Z","updated":"2024-07-24T14:47:34.226Z","comments":true,"path":"2024/07/24/Work/项目管理/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Work/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/","excerpt":"","text":"项目管理流程管理流程管理，站在个人角度来说，需要按时推进项目进行，其中，5个关键点为 1.识别事情的重要性和优先级 2.对做的事情建立起认知框架（难易程度、资源需求，里程碑设定，结果目标量化） 3.定期与上级及相关方沟通，识别潜在风险，保证工作持续性， 4.对工作做Plan B，应对突发情况 5.结果上还不错 有重点、有过程、有汇报，让上级有安全感和掌控感。 遇到困难的处理，例如有五件六件七件事的时候 梳理事情优先级和重要性 什么情况下要汇报 什么水平的问题、困难和风险，必须要汇报让老板知道 大概怎么让老板知道 你对于困难的备案Plan B。 汇报会做其实是一部分，汇报能够让领导理解你的处境，了解你的工作内容，明白你是有出很大力的。 如何汇报情况1：对于老板只了解大概，大方向的需求，需要按如下步骤 背景铺垫：是个什么事 进展现状和重要性：什么情况、优先级怎么样 痛点、卡点： 寻求支持：要哪方面的支持 情况2：工作背景，老板很清楚，只需你执行 进展 问题 寻求支持 情况3：大场汇报，做个演讲，汇报对象有别的部门的人、有和事情不相干的人，目的是扩大影响力，容易后面拉通资源。 问题：遇到一个什么问题，影响我们所有人或者我们公司的 思考和计划：解决方案的思考、我们的计划 进展：进展如何 困难：遇到了什么困难 支持：需要什么支持 团队协作除了自身角度的管理外，不可避免地有团队协作。 原则 目标导向的，以解决问题为目的。 不带入情绪 对事不对人，哪怕确实是对方能力稍差，但也需要说沟通对其问题，让其领导处理 遇到问题，充分沟通对齐。尝试解决，无果后，反馈给上级，告知风险，让上级决策。 工作推不动，同事不配合先标准流程走 和同级沟通交流 书面记录：项目管理表、邮件、日报周报 实在无法解决，上升 和+1沟通：梳理现状和矛盾，告知风险 让+1处理：要么他去和对方领导沟通，要么再找ta自己的领导。","categories":[{"name":"Work","slug":"Work","permalink":"https://messenger1th.github.io/categories/Work/"}],"tags":[]},{"title":"国际化","slug":"Work/国际化","date":"2024-07-24T14:47:34.224Z","updated":"2024-07-24T14:47:34.224Z","comments":true,"path":"2024/07/24/Work/国际化/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Work/%E5%9B%BD%E9%99%85%E5%8C%96/","excerpt":"","text":"国际化和本地化国际化与本地化（Internationalization and localization,通常用i18n和L10N表示），国际化是将针对某个地区设计的程序进行重构，以使它能够在更多地区使用，本地化是指在一个面向国际化的程序中增加对新地区的支持。 所谓的国际化：就是根据特定的locale信息，提取与之相应的字符串或其它一些东西（比如时间和货币的格式）等等。这涉及到三个问题： 1、如何确定locale。 2、如何保存与locale相关的字符串或其它信息。 3、如何根据locale提取字符串和其它相应的信息。 什么是LocaleLocale是一组描述世界上某一特定区域文本格式和语言习惯的设置的集合。locale名通常由三个部分组成：第一部分，是一个强制性的，表示语言的缩写，例如”en”表示英文或”zh”表示中文。第二部分，跟在一个下划线之后，是一个可选的国家说明符，用于区分讲同一种语言的不同国家，例如”en_US”表示美国英语，而”en_UK”表示英国英语。最后一部分，跟在一个句点之后，是可选的字符集说明符，例如”zh_CN.gb2312”表示中国使用gb2312字符集。 GO语言默认采用”UTF-8”编码集，所以我们实现i18n时不考虑第三部分，接下来我们都采用locale描述的前面两部分来作为i18n标准的locale名，无需关心字符集。例如常见的locale的值有zh-cn、en-US，表示不同语言和国家。 常见的需要本地化的东西有 本地化消息：用一个map，key是locale，value是消息。 本地化日期和时间：用一个map，key是locale，value是日期格式。拿到格式再用值fmt.Sprintf出来。 本地化货币值：USD $和RMB ¥。 本地化view视图和资源","categories":[{"name":"Work","slug":"Work","permalink":"https://messenger1th.github.io/categories/Work/"}],"tags":[]},{"title":"国际化和本地化","slug":"Work/国际化和本地化","date":"2024-07-24T14:47:34.224Z","updated":"2024-07-24T14:47:34.224Z","comments":true,"path":"2024/07/24/Work/国际化和本地化/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Work/%E5%9B%BD%E9%99%85%E5%8C%96%E5%92%8C%E6%9C%AC%E5%9C%B0%E5%8C%96/","excerpt":"","text":"国际化和本地化国际化与本地化（Internationalization and localization,通常用i18n和L10N表示），国际化是将针对某个地区设计的程序进行重构，以使它能够在更多地区使用，本地化是指在一个面向国际化的程序中增加对新地区的支持。","categories":[{"name":"Work","slug":"Work","permalink":"https://messenger1th.github.io/categories/Work/"}],"tags":[]},{"title":"安全与加密","slug":"Work/安全与加密","date":"2024-07-24T14:47:34.224Z","updated":"2024-07-24T14:47:34.225Z","comments":true,"path":"2024/07/24/Work/安全与加密/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Work/%E5%AE%89%E5%85%A8%E4%B8%8E%E5%8A%A0%E5%AF%86/","excerpt":"","text":"安全记录一些常见的安全漏洞 CSRFCSRF（Cross-site request forgery），中文名称：跨站请求伪造，也被称为：one click attack&#x2F;session riding，缩写为：CSRF&#x2F;XSRF。 一句话概括就是，通过你访问你个正常网站然后浏览器存下这个网站的cookie，然后再访问一个恶意网站，这个网站会在html中插入js脚本，然后该脚本会使用你的cookie去操作正常网站。 整个过程中，cookie都没有被窃取，脚本也不知道cookie的内容是什么，但脚本在你的浏览器环境中发送请求到正常网站时，该请求会默认携带cookie，也就是恶意脚本冒用cookie，去进行一些你不知道的操作。 总的来说，CSRF核心还是访问了恶意网站，执行脚本去请求正常网站，服务端并不知道这些操作是否用户本意，直接损害的是用户利益，所以要避免的话，还是用户别访问不安全的网站。 XSSXSS攻击：跨站脚本攻击(Cross-Site Scripting)，为了不和层叠样式表(Cascading Style Sheets, CSS)的缩写混淆，故将跨站脚本攻击缩写为XSS。XSS是一种常见的web安全漏洞，它允许攻击者将恶意代码植入到提供给其它用户使用的页面中。不同于大多数攻击(一般只涉及攻击者和受害者)，XSS涉及到三方，即攻击者、客户端与Web应用。 XSS主要分为两种，存储型和反射型。 存储型存储型XSS，主要出现在让用户输入数据，供其他浏览此页的用户进行查看的地方，包括留言、评论、博客日志和各类表单等。应用程序从数据库中查询数据，在页面中显示出来，攻击者在相关页面输入恶意的脚本数据后，用户浏览此类页面时就可能受到攻击。这个流程简单可以描述为 恶意用户侧 恶意用户插入带有脚本的信息，发送请求 服务端接受请求，但没有做输入过滤，直接存储到数据库。 普通用户侧（受害者角度） 获取评论、博客日志或者其他各类表单信息时，获取到了恶意用户的评论，该评论中带有恶意的脚本，浏览器自动执行脚本。 反射型反射型XSS，主要做法是将脚本代码加入URL地址的请求参数里，请求参数进入程序后在页面直接输出，用户点击类似的恶意链接就可能受到攻击。 例如，我们在百度时，都会输入关键词查询，然后跳转到查询结果的页面，该结果页面是含有查询时的关键词，也就意味着html中会含有该关键词，所以如果该关键词存在恶意脚本，那返回的查询结果的html中，实际会含有恶意脚本。 DOM型todo 避免和小结总的来说，XSS的核心都是在HTML中注入脚本，也是直接损害的是用户利益，但普通用户基本无法反制，所以服务端很有必要对用户各种输入做过滤。 SQL注入SQL注入攻击（SQL Injection），简称注入攻击，是Web开发中最常见的一种安全漏洞。可以用它来从数据库获取敏感信息，或者利用数据库的特性执行添加用户，导出文件等一系列恶意操作，甚至有可能获取数据库乃至系统用户最高权限。 而造成SQL注入的原因是因为程序没有有效过滤用户的输入，使攻击者成功的向服务器提交恶意的SQL语句，程序在接收后错误的将攻击者的输入作为查询语句的一部分执行，导致原始的查询逻辑被改变，额外的执行了攻击者精心构造的恶意代码。 SQL注入，其实类似XSS攻击，也是执行一些意外的程序，但是直接损害的是服务端的数据，所以服务端很有必要对用户各种输入做过滤。 密码存储如果你的密码只是用于校验，其实可以只存储hash值，对比请求的密码的哈希值，和实际密码的hash值即可。 如果安全性要求不高，可以进行编码，比如base64编码，但拿到该编码后的密码，在同时知道你的编码方式时，也能知道你的密码。 但如果有存储密码的需求，一定需要加密，目前主流的加密算法有AES、DES。Go语言的crypto对这两个算法都进行了支持。 参考 《Go Web编程》安全与加密 跨站请求伪造CSRF攻击的原理以及防范措施 XSS网络攻击 - 原理，类型和实践 SQL注入攻击原理，方法和类型 存储密码-进阶方案","categories":[{"name":"Work","slug":"Work","permalink":"https://messenger1th.github.io/categories/Work/"}],"tags":[]},{"title":"Makefile","slug":"Tools/Makefile","date":"2024-07-24T14:47:34.224Z","updated":"2024-07-24T14:47:34.224Z","comments":true,"path":"2024/07/24/Tools/Makefile/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Tools/Makefile/","excerpt":"","text":"Makefile 方便编译、管理工程 命名：Makefile 规则： app: sub.o add.o mult.o div.o main.o gcc sub.o add.o mult.o div.o main.o -o app sub.o:sub.c gcc -c sub.c -o sub.o add.o:add.c gcc -c add.c -o add.o mult.o:mult.c gcc -c mult.c -o mult.o div.o:div.c gcc -c div.c -o div.c main.o:main.c gcc -c main.c -o main.o 运行Makefile make 运行Makefile时，根据第一行规则查找依赖来运行","categories":[{"name":"Tools","slug":"Tools","permalink":"https://messenger1th.github.io/categories/Tools/"}],"tags":[]},{"title":"vim","slug":"Tools/vim","date":"2024-07-24T14:47:34.224Z","updated":"2024-07-24T14:47:34.224Z","comments":true,"path":"2024/07/24/Tools/vim/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Tools/vim/","excerpt":"","text":"vim命令撤销重做 按键 作用 u undo (常用) [Ctrl]+r redo (常用) . 不要怀疑！这就是小数点！意思是重复前一个动作的意思。 如果你想要重复删除、重复贴上等等动作，按下小数点『.』就好了！ (常用)。注意，对移动无效。 移动可长按，达到持续移动的效果。 小幅移动 h 左移一个字符 j 下移一行 k 上移一行 l 右移一个字符 除了vim风格的移动，上下左右也能用。 此外，还可以结合数字，达到一次移动多行的效果，如，10j，向下移动10行。 单词移动 w 移动到下一个单词头 e 移动到下一个单词尾 b 移动到上一个单词头 ge 移动到上一个单词尾 大幅上下移动 [Ctrl] + [d] 屏幕『向下』移动半页 [Ctrl] + [u] 屏幕『向上』移动半页 [Ctrl] + [f] 屏幕『向下』移动一页，相当于 [Page Down]按键 (常用) [Ctrl] + [b] 屏幕『向上』移动一页，相当于 [Page Up] 按键 (常用) 大福左右移动 0 或功能键[Home] 这是数字『 0 』：移动到这一行的最前面字符处 (常用) $ 或功能键[End] 移动到这一行的最后面字符处(常用) 文件头尾跳转 gg 跳转文件第一行的第一个字符 G 跳转文件最后一行的第一个字符 指定移动距离 nG n 为数字。移动到这个档案的第 n 行。例如 20G 则会移动到这个档案的第 20 行(可配合 :set nu) n&lt;Enter&gt; n 为数字。光标向下移动 n 行(常用) 屏幕内移动 H 光标移动到这个屏幕的最上方那一行的第一个字符 M 光标移动到这个屏幕的中央那一行的第一个字符 L 光标移动到这个屏幕的最下方那一行的第一个字符 其他 + 光标移动到非空格符的下一行 - 光标移动到非空格符的上一行 剪切、复制粘贴 剪切 dd 剪切游标所在的那一整行(常用)，用 p&#x2F;P 可以粘贴。 ndd n 为数字。剪切光标所在的向下 n 行，例如 20dd 则是剪切 20 行(常用)，用 p&#x2F;P 可以粘贴。 d1G 剪切光标所在到第一行的所有数据 dG 剪切光标所在到最后一行的所有数据 d$ 剪切游标所在处，到该行的最后一个字符 d0 那个是数字的 0 ，删除游标所在处，到该行的最前面一个字符 x, X 在一行字当中，x 为向后删除一个字符 (相当于 [del] 按键)， X 为向前删除一个字符(相当于 [backspace] 亦即是退格键) (常用) nx n 为数字，连续向后剪切 n 个字符。举例来说，我要剪切10 个字符， 『10x』。 复制 yw 复制当前字符到下个单词头（不包含）的数据。 ye 复制当前字符到当前单词尾（包含）的数据。 yy 复制游标所在的那一行(常用) nyy n 为数字。复制光标所在的向下 n 行，例如 20yy 则是复制 20 行(常用) y1G 复制游标所在行到第一行的所有数据 yG 复制游标所在行到最后一行的所有数据 y0 复制光标所在的那个字符到该行行首的所有数据 y$ 复制光标所在的那个字符到该行行尾的所有数据 粘贴 p, P 粘贴到当前行下面&#x2F;插入到当前行上面 搜索替换 搜索 &#x2F;[content] 向光标之下寻找一个[context]的字符串。 ?[content] 向光标之上寻找一个[context]的字符串。 n （在搜索中），下一个搜结果（如果是&#x2F;?，则相反）。 N （在搜索中），上一个搜结果（如果是&#x2F;?，则相反）。 替换 :n1,n2s&#x2F;word1&#x2F;word2&#x2F;g n1 与 n2 为数字。在第 n1 与 n2 行之间寻找 word1 这个字符串，并将该字符串取代为 word2 ！举例来说，在 100 到 200 行之间搜寻 vbird 并取代为 VBIRD 则： 『:100,200s&#x2F;vbird&#x2F;VBIRD&#x2F;g』。(常用) :1,$s&#x2F;word1&#x2F;word2&#x2F;g 或 :%s&#x2F;word1&#x2F;word2&#x2F;g 从第一行到最后一行寻找 word1 字符串，并将该字符串取代为 word2 ！(常用) :1,$s&#x2F;word1&#x2F;word2&#x2F;gc 或 :%s&#x2F;word1&#x2F;word2&#x2F;gc 从第一行到最后一行寻找 word1 字符串，并将该字符串取代为 word2 ！且在取代前显示提示字符给用户确认 (confirm) 是否需要取代！(常用) 其他 文件操作 :w 写入磁盘 :wq 写入并退出 :q 退出，如果有修改，则提示错误，无法退出。 :q! 强制退出，抛弃修改的内容。 :w [filename] 写入到新文件 :r [filename] 将 『filename』 这个文件内容加到游标所在行后面 :n1,n2 w [filename] 将 n1 到 n2 的内容储存成 filename 这个档案。 :! command 暂时离开 vi 到指令行模式下执行 command 的显示结果！例如 『:! ls &#x2F;home』即可在 vi 当中察看 &#x2F;home 底下以 ls 输出的档案信息！ 其他 :set number 临时显示行号；要永久设置，请在~&#x2F;.vimrc中设置。 :set nonu 与 set nu 相反，为取消行号！","categories":[{"name":"Tools","slug":"Tools","permalink":"https://messenger1th.github.io/categories/Tools/"}],"tags":[]},{"title":"Linux commands","slug":"Tools/Linux commands","date":"2024-07-24T14:47:34.223Z","updated":"2024-07-24T14:47:34.224Z","comments":true,"path":"2024/07/24/Tools/Linux commands/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Tools/Linux%20commands/","excerpt":"","text":"Linux 命令使用前置知识文件相关Linux系统中是通过link的数量来控制文件删除的，只有当一个文件不存在任何link的时候，这个文件才会被删除。 一般来说，每个文件都有2个link计数器:i_count 和 i_nlink，也就是说：Linux系统中只有i_nlink及i_count都为0的时候，这个文件才会真正被删除。 i_count表示当前文件使用者（或被调用）的数量 i_nlink表示介质连接的数量（硬链接的数量）； 可以理解为i_count是内存引用计数器，i_nlink是磁盘的引用计数器。 当一个文件被某一个进程引用时，对应i_count数就会增加；当创建文件的硬链接的时候，对应i_nlink数就会增加。 在Linux或者Unix系统中，通过rm或者文件管理器删除文件，只是将它会从文件系统的目录结构上解除链接(unlink)，实际上就是减少磁盘引用计数i_nlink，但是并不会减少i_count数。 如果一个文件正在被某个进程调用，用户使用rm命令把文件”删除”了，这时候通过ls等文件管理命令就无法找到这个文件了，但是并不意味着这个文件真正的从磁盘上删除了。 因为还有一个进程在正常的执行，在向文件中读取或写入，也就是说文件其实并没有被真正的”删除”，所以磁盘空间也就会一直被占用。 命令熟知的就不介绍了 ls、cat、cd 、tail、head等。 文本查询tail顾名思义，显示文件后几行（默认5行）。 tail -f [filename] 阻塞式监听新加进来的行。 grepgrep比较常见，过滤字符串。 可以通过-C [n]显示上下各5行的内容。 可以通过-n [n]显示行号。 less、moremore只能向下移动，推荐less。 less上下移动、查询跟vim操作相似。 cut给输入（或文件）的每行移除一部分。 搭配grep可以实现，只查看每行的前多少个字符，比如grep后查看前50个字符。 cat log | grep GetRecommend | cut -c1-50。 lsoflist open file。 列出被程序打开的文件，可能已经被unlink（此时会有deleted标识），但被程序引用，导致无法实际执行删除。 一般用于如何查看端口被哪个进程占用。 进程psps -ef 或者 ps -aux 在ps -ef命令输出的结果中，”TTY”列表示与进程关联的终端设备。 终端设备（Terminal Device）是指用于输入和输出的用户界面。在类Unix系统中，每个运行的进程都可以与一个终端设备关联。终端设备可以是物理终端（例如控制台）或虚拟终端（例如终端窗口、SSH会话等）。 在”TTY”列中，你会看到一个设备名称或终端名称，用于标识与进程相关联的终端。以下是一些常见的TTY值及其含义： “pts&#x2F;0”：伪终端设备（pseudo terminal），通常表示一个终端窗口或SSH会话。 “tty1”：”tty”是指物理终端设备，后面的数字表示设备编号。”tty1”表示第一个物理终端设备，通常是控制台。 “?”：表示没有与进程相关联的终端设备，即进程是一个守护进程（daemon），不与终端交互。 终端设备的信息对于了解进程是如何与用户进行交互以及进程的运行环境非常有用。通过查看TTY列，你可以确定进程是否与用户交互，以及它是在哪个终端上运行的。 killkill命令用于终止一个进程，实现原理是，操作系统向应用程序发送一个终止信号，应用程序进行退出。 kill默认是kill -15，系统会发送一个SIGTERM的信号给对应的程序。当程序接收到该信号后，具体要如何处理是自己可以决定的，通过注册对应的处理函数来实现。所以，这个处理函数也可以选择忽略这个信号，此时操作系统kill -15是无法终止这个程序的。 kill -9就相对强硬一点，系统会发出SIGKILL信号，他要求接收到该信号的程序应该立即结束运行，不能被阻塞或者忽略。 其中，JVM关闭就涉及这方面，JVM关闭方式分为3种： 正常关闭：当最后一个非守护线程结束或者调用了System.exit或者通过其他特定平台的方法关闭（接收到SIGINT（2）、SIGTERM（15）信号等） 强制关闭：通过调用Runtime.halt方法或者是在操作系统中强制kill（接收到SIGKILL（9）信号) 异常关闭：运行中遇到RuntimeException异常等。 资源查询命令top以下是一些常用的按键操作： 使用 k 键：通过输入进程的 PID（进程ID）来终止选定的进程。 使用 r 键：修改进程的优先级（nice value）。 使用 H 键：将线程（thread）模式和进程模式之间进行切换。 使用 f 键：进入字段管理模式，可以选择要显示的列。 使用 u 键：显示特定用户的进程。 使用 s 键：改变刷新间隔时间。 使用 q 键：退出 top 命令。 排序模式 P键：按照CPU使用率进行排序，高CPU使用率的进程会显示在前面。 M键：按照内存使用量进行排序，高内存使用量的进程会显示在前面。 N键：按照进程ID（PID）进行排序，按照进程ID的大小顺序进行排列。 T键：按照运行时间进行排序，按照进程运行的时间长短进行排列。 W键：将当前的排序方式写入到~/.toprc文件中，下次启动top命令时将使用该排序方式。 在top命令中按下相应的键后，进程列表将根据指定的排序方式进行重新排序，并且显示最新的排序结果。 df、dudf：查询磁盘使用情况。 -B[M|G|B|T] 按照不同规格显示。也可以使用 -H 按照human的习惯，自适应规格。 du：查询文件空间情况。 -B[M|G|B|T] 按照不同规格显示。也可以使用 -H 按照human的习惯，自适应规格。 free显示使用的和剩余的内存、以及交换区的情况。 vmstatvmstat 是一个常用的性能监控工具，用于显示系统的虚拟内存统计信息。它提供了有关系统内存、进程、IO等方面的信息。下面是 vmstat 命令输出的一些常见统计数据： procs：进程统计信息 r: 系统中正在运行的进程数量。 b: 等待资源的进程数量。 memory：内存使用统计信息 swpd: 使用的虚拟内存量（以KB为单位）。 free: 空闲内存量（以KB为单位）。 buff: 用作缓冲区的内存量（以KB为单位）。 cache: 用作缓存的内存量（以KB为单位）。 swap：交换空间使用统计信息 si: 从磁盘读入交换区的数据量（以KB为单位）。 so: 从交换区写出到磁盘的数据量（以KB为单位）。 io：IO统计信息 bi: 从块设备读取的块数量（每秒）。 bo: 写入块设备的块数量（每秒）。 system：系统统计信息 in: 每秒中断的数量。 cs: 每秒上下文切换的数量。 cpu：CPU使用统计信息 us: 用户空间CPU时间百分比。 sy: 内核空间CPU时间百分比。 id: 空闲CPU时间百分比。 wa: 等待IO的CPU时间百分比。 st: 被虚拟化层偷取的CPU时间百分比。 其它 uptime：显示系统的运行时间和负载平均值。 dmesg：显示内核日志信息，包括启动过程中的信息和硬件设备相关的消息。 sort：排序后输出。 todo &#96;&#96;cat &#x2F;proc&#x2F;meminfo&#96; sed、awd 常见问题 怎么看进程占用的CPU？ 怎么查看一个进程的进程号？ 怎么看端口被哪个进程占用了？ top命令有哪些信息？ top命令的CPU占用会超过100%吗？ Linux怎么修改文件权限","categories":[{"name":"Tools","slug":"Tools","permalink":"https://messenger1th.github.io/categories/Tools/"}],"tags":[]},{"title":"Git","slug":"Tools/Git","date":"2024-07-24T14:47:34.223Z","updated":"2024-07-24T14:47:34.223Z","comments":true,"path":"2024/07/24/Tools/Git/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Tools/Git/","excerpt":"","text":"Git 配置用户签名（首次需要设置，否则提交时报错） 初始化本地库 命令 初始化本地库(会在当前目录生成.git的文件夹) git init 连接远程仓库 git remote add origin xxxxx//x为remoteRepo的SSH或者https git clone xxxxx//克隆会直接连接 git remote -v//查看远程仓库地址 查看状态 git status 将文件加入追踪&#x2F;删除追踪 git add filename //单个文件 git add . //所有文件 git rm --cached filename //去除对文件的追踪 提交本地库 git commit -m &quot;desription of this version.&quot; //&quot;&quot;中是对这次提交的版本的描述 //git会输出 [main xxxxxxx] //xx为版本号前七位 查看版本信息 git reflog //版本号为前七位 git log //详细信息 版本设置（会修改本地文件） git reset --soft xxxxxxx //回退版本，但保留文件修改到untracked git reset --mixed xxxxxxx //回退版本，但保留文件修改到tracked git reset --hard xxxxxxx //--hard 强制回退到xxxxxx版本，并丢失数据，慎重！！！ 远程所有带push的才会修改远程，否则只是修改本地。例如git remote remove [ref]仅仅删除本地引用。 推送到远程 git push 推送到远程并设置默认推送 git push origin main # 将本地的main分支推送的远程的main分支 git push -u origin main # 将本地的main分支推送的远程的main分支并设置默认推送。 # 设置默认推送后，可以直接使用 git push git push origin &lt;local_branch&gt;:&lt;remote_branch&gt; # 将本地指定分支推送到远程指定分支 推送到远程（本地当前分支和远程要分支不一致的情况） git push origin [local_branch]:[remote_branch] 删除远程分支 git push -d [remote_branch] #方式1 git push origin :remote_branch #将空推送到远程分支，即删除。 拉取远端分支到本地 git fetch [origin] [remote_branch] 根据远端分支创建本地分支（得先fetch） git checkout -b [local_branch] [origin]/[remote_branch] 分支 可以并行开发多个功能，提高开发效率。 开发失败不会互相影响 查看分支 git branch -v 创建分支 git branch [name] # 仅创建分支。 git checkout -b [branch_name] #创建并切换到新分支 切换分支 git checkout [name] 合并分支 git merge [name] //将name分支合并到当前分支 删除分支 git branch -D localBranchName 修改当前所在分支名字 git branch -m &lt;new_branch_name&gt; 分支冲突 原因：被合并的分支与当前分支在同一文件的同一位置有不同修改) 解决步骤 手动操作文件，解决冲突。 git add conflictFile //将冲突文件加入追踪 git commit -m &quot;version description&quot; //最后不加文件名，直接默认commit到当前分支。 被合并的分支中冲突文件保持原状态。 协作团队协作 初始化项目库 将自己的分支交到代码托管平台如github git push &lt;remote name&gt; &lt;local branch&gt; 将远程库克隆\\拉取到本地 git clone git pull 友情协作 协助者fork项目到自己远程库。 协助者将远程库clone到本地 协助者进行本地修改后，commit本地分支，再push到自己远程库，提交pull request请求。经团队管理员审核后merge成功。 远程和本地交互 本地远程连接 git remote add origin xxxxx//x为remoteRepo的SSH或者https git clone xxxxx//克隆会直接连接 git remote -v//查看远程仓库地址 给remote repo创建别名 、查看别名 git remote add alaisName xxxx //xxx为项目地址 git remote -v //查看别名 将本地当前分支push到remote repo git push origin/address remoteBranch //origin是当前git对应github的项目 将远程分支pull到当前分支 git pull origin/address remoteBranch // origin是当前git对应github的项目 重要命令git add &lt;file&gt;...将工作目录中未追踪的文件加入跟踪，修改了的文件放入暂存区。 git restore &lt;file&gt;... git restore 在不指定--staged时，会将工作区的较于上一次提交的更改移除。会造成数据丢失。 git restore --staged会将暂存区的更改放回到工作区。可以看作是git add的undo。 git reset --soft 将已经commit的数据回滚到staged状态，相当与已经运行了git add. --mixed默认， 将已经commit的数据回滚到unstaged状态，相当与修改了但未git add，可以看作是git add的undo。 --hard会造成数据丢失，将已经commit的数据回滚到上一个commit的状态。 --merge &lt;commit_sha&gt;取消merge，回到&lt;commit_sha&gt;的状态。 git reset -- &lt;file&gt;...要么作用与版本，要么作用与未提交的内容。不能作用于已经提交的某一个文件。 git rm git rm &lt;file&gt;... 将文件彻底删除。 git rm --cached &lt;file&gt;... 取消对文件的追踪。 git rebase用于合并分支，但与merge有区别。将指定分支作为base即起点，将本分支的commits重新应用，看起来想是在一个分支上进行合作。 此外，如果制定-i还能修改这修commits的应用规则，例如多个commit压缩成一个，修改信息等等。 git revert 用于回退到某一个节点，但是通过新建一个commit来回滚，原来的记录仍然存在。这样就避免了修改线上已经存在的commit被删除而导致的困惑。 比较下来，reset一般用于本地，而revert一般用于线上。 同样的，这个也可能存在文件冲突。 git cherry-pick将其他的commit拿一份过来，不修改拿的地方，应用在当前分支。 对于多分支的代码库，将代码从一个分支转移到另一个分支是常见需求。这时分两种情况。一种情况是，你需要另一个分支的所有代码变动，那么就采用合并（git merge）。另一种情况是，你只需要部分代码变动（某几个提交），这时可以采用 Cherry pick。 git stash将修改但未commit的（Changes not staged for commit）内容暂存起来到一个栈里头（每个分支独有），方便切换到别的分支。 git stash 匿名存储，无法通过git stash list查看。 git stash list 查看栈内容。 git stash save &quot;description.&quot; 正常存储。 git stash pop 将栈顶的内容弹出并应用。 git stash apply 将堆栈的内容应用，不弹出。 git stash drop [stash@&#123;?&#125;]从堆栈中移除某个指定的stash git stash clear清除栈中的所有内容 git stash show查看堆栈中最新保存的stash和当前目录的差异。 通过 git stash show -p 查看详细的不同。 git stash branch从最新的stash创建分支。 其他命令git clean 从工作目录中删除所有没有tracked过的文件。 git stage 等于git add。 bfg --delete-files file_name：从git历史中删除文件","categories":[{"name":"Tools","slug":"Tools","permalink":"https://messenger1th.github.io/categories/Tools/"}],"tags":[]},{"title":"Cmake note","slug":"Tools/Cmake note","date":"2024-07-24T14:47:34.223Z","updated":"2024-07-24T14:47:34.223Z","comments":true,"path":"2024/07/24/Tools/Cmake note/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Tools/Cmake%20note/","excerpt":"","text":"CMake说明cmake的定义是什么 ？—–高级编译配置工具 当多个人用不同的语言或者编译器开发一个项目，最终要输出一个可执行文件或者共享库（dll，so等等）这时候神器就出现了—–CMake！ 所有操作都是通过编译CMakeLists.txt来完成的—简单 官 方网站是 www.cmake.org，可以通过访问官方网站获得更多关于 cmake 的信息 学习CMake的目的，为将来处理大型的C&#x2F;C++&#x2F;JAVA项目做准备 CMake安装1、绝大多数的linux系统已经安装了CMake 2、Windows或某些没有安装过的linux系统，去http://www.cmake.org/HTML/Download.html 可以下载安装 CMake一个HelloWord1、步骤一，写一个HelloWord #main.cpp #include &lt;iostream&gt; int main()&#123; std::cout &lt;&lt; &quot;hello word&quot; &lt;&lt; std::endl; &#125; 2、步骤二，写CMakeLists.txt #CMakeLists.txt PROJECT (HELLO) SET(SRC_LIST main.cpp) MESSAGE(STATUS &quot;This is BINARY dir &quot; $&#123;HELLO_BINARY_DIR&#125;) MESSAGE(STATUS &quot;This is SOURCE dir &quot;$&#123;HELLO_SOURCE_DIR&#125;) ADD_EXECUTABLE(hello $&#123;SRC_LIST&#125;) 3、步骤三、使用cmake，生成makefile文件 cmake . 输出： [root@localhost cmake]# cmake . CMake Warning (dev) in CMakeLists.txt: Syntax Warning in cmake code at /root/cmake/CMakeLists.txt:7:37 Argument not separated from preceding token by whitespace. This warning is for project developers. Use -Wno-dev to suppress it. -- The C compiler identification is GNU 10.2.1 -- The CXX compiler identification is GNU 10.2.1 -- Check for working C compiler: /usr/bin/cc -- Check for working C compiler: /usr/bin/cc -- works -- Detecting C compiler ABI info -- Detecting C compiler ABI info - done -- Check for working CXX compiler: /usr/bin/c++ -- Check for working CXX compiler: /usr/bin/c++ -- works -- Detecting CXX compiler ABI info -- Detecting CXX compiler ABI info - done -- This is BINARY dir /root/cmake -- This is SOURCE dir /root/cmake -- Configuring done -- Generating done -- Build files have been written to: /root/cmake 目录下就生成了这些文件-CMakeFiles, CMakeCache.txt, cmake_install.cmake 等文件，并且生成了Makefile.现在不需要理会这些文件的作用，以后你也可以不去理会。最关键的是，它自动生成了Makefile. 4、使用make命令编译 root@localhost cmake]# make Scanning dependencies of target hello [100%] Building CXX object CMakeFiles/hello.dir/main.cpp.o Linking CXX executable hello [100%] Built target hello 5、最终生成了Hello的可执行程序 CMake一个HelloWord-的语法介绍PROJECT关键字可以用来指定工程的名字和支持的语言，默认支持所有语言 PROJECT (HELLO) 指定了工程的名字，并且支持所有语言—建议 PROJECT (HELLO CXX) 指定了工程的名字，并且支持语言是C++ PROJECT (HELLO C CXX) 指定了工程的名字，并且支持语言是C和C++ 该指定隐式定义了两个CMAKE的变量 _BINARY_DIR，本例中是 HELLO_BINARY_DIR _SOURCE_DIR，本例中是 HELLO_SOURCE_DIR MESSAGE关键字就可以直接使用者两个变量，当前都指向当前的工作目录，后面会讲外部编译 问题：如果改了工程名，这两个变量名也会改变 解决：又定义两个预定义变量：PROJECT_BINARY_DIR和PROJECT_SOURCE_DIR，这两个变量和HELLO_BINARY_DIR，HELLO_SOURCE_DIR是一致的。所以改了工程名也没有关系 SET关键字用来显示的指定变量的 SET(SRC_LIST main.cpp) SRC_LIST变量就包含了main.cpp 也可以 SET(SRC_LIST main.cpp t1.cpp t2.cpp) MESSAGE关键字向终端输出用户自定义的信息 主要包含三种信息： SEND_ERROR，产生错误，生成过程被跳过。 SATUS，输出前缀为—的信息。 FATAL_ERROR，立即终止所有 cmake 过程. ADD_EXECUTABLE关键字生成可执行文件 ADD_EXECUTABLE(hello ${SRC_LIST}) 生成的可执行文件名是hello，源文件读取变量SRC_LIST中的内容 也可以直接写 ADD_EXECUTABLE(hello main.cpp) 上述例子可以简化的写成 PROJECT(HELLO)ADD_EXECUTABLE(hello main.cpp) 注意：工程名的 HELLO 和生成的可执行文件 hello 是没有任何关系的 语法的基本原则 变量使用${}方式取值，但是在 IF 控制语句中是直接使用变量名 指令(参数 1 参数 2…) 参数使用括弧括起，参数之间使用空格或分号分开。 以上面的 ADD_EXECUTABLE 指令为例，如果存在另外一个 func.cpp 源文件 就要写成：ADD_EXECUTABLE(hello main.cpp func.cpp)或者ADD_EXECUTABLE(hello main.cpp;func.cpp) 指令是大小写无关的，参数和变量是大小写相关的。但，推荐你全部使用大写指令 语法注意事项 SET(SRC_LIST main.cpp) 可以写成 SET(SRC_LIST “main.cpp”)，如果源文件名中含有空格，就必须要加双引号 ADD_EXECUTABLE(hello main) 后缀可以不行，他会自动去找.c和.cpp，最好不要这样写，可能会有这两个文件main.cpp和main 内部构建和外部构建 上述例子就是内部构建，他生产的临时文件特别多，不方便清理 外部构建，就会把生成的临时文件放在build目录下，不会对源文件有任何影响强烈使用外部构建方式 外部构建方式举例//例子目录，CMakeLists.txt和上面例子一致 [root@localhost cmake]# pwd /root/cmake [root@localhost cmake]# ll total 8 -rw-r--r--. 1 root root 198 Dec 28 20:59 CMakeLists.txt -rw-r--r--. 1 root root 76 Dec 28 00:18 main.cpp 1、建立一个build目录，可以在任何地方，建议在当前目录下 2、进入build，运行cmake .. 当然..表示上一级目录，你可以写CMakeLists.txt所在的绝对路径，生产的文件都在build目录下了 3、在build目录下，运行make来构建工程 注意外部构建的两个变量 1、HELLO_SOURCE_DIR 还是工程路径 2、HELLO_BINARY_DIR 编译路径 也就是 &#x2F;root&#x2F;cmake&#x2F;bulid 让Hello World看起来更像一个工程 为工程添加一个子目录 src，用来放置工程源代码 添加一个子目录 doc，用来放置这个工程的文档 hello.txt 在工程目录添加文本文件 COPYRIGHT, README 在工程目录添加一个 runhello.sh 脚本，用来调用 hello 二进制 将构建后的目标文件放入构建目录的 bin 子目录 将 doc 目录 的内容以及 COPYRIGHT&#x2F;README 安装到&#x2F;usr&#x2F;share&#x2F;doc&#x2F;cmake&#x2F; 将目标文件放入构建目录的 bin 子目录每个目录下都要有一个CMakeLists.txt说明 [root@localhost cmake]# tree . ├── build ├── CMakeLists.txt └── src ├── CMakeLists.txt └── main.cpp 外层CMakeLists.txt PROJECT(HELLO) ADD_SUBDIRECTORY(src bin) src下的CMakeLists.txt ADD_EXECUTABLE(hello main.cpp) ADD_SUBDIRECTORY 指令ADD_SUBDIRECTORY(source_dir [binary_dir] [EXCLUDE_FROM_ALL]) 这个指令用于向当前工程添加存放源文件的子目录，并可以指定中间二进制和目标二进制存放的位置 EXCLUDE_FROM_ALL函数是将写的目录从编译中排除，如程序中的example ADD_SUBDIRECTORY(src bin) 将 src 子目录加入工程并指定编译输出(包含编译中间结果)路径为bin 目录 如果不进行 bin 目录的指定，那么编译结果(包括中间结果)都将存放在build&#x2F;src 目录 更改二进制的保存路径SET 指令重新定义 EXECUTABLE_OUTPUT_PATH 和 LIBRARY_OUTPUT_PATH 变量 来指定最终的目标二进制的位置 SET(EXECUTABLE_OUTPUT_PATH ${PROJECT_BINARY_DIR}&#x2F;bin)SET(LIBRARY_OUTPUT_PATH ${PROJECT_BINARY_DIR}&#x2F;lib) 思考：加载哪个CMakeLists.txt当中 哪里要改变目标存放路径，就在哪里加入上述的定义，所以应该在src下的CMakeLists.txt下写 安装 一种是从代码编译后直接 make install 安装 一种是打包时的指定 目录安装。 简单的可以这样指定目录：make install DESTDIR&#x3D;&#x2F;tmp&#x2F;test 稍微复杂一点可以这样指定目录：.&#x2F;configure –prefix&#x3D;&#x2F;usr 如何安装HelloWord使用CMAKE一个新的指令：INSTALL INSTALL的安装可以包括：二进制、动态库、静态库以及文件、目录、脚本等 使用CMAKE一个新的变量：CMAKE_INSTALL_PREFIX // 目录树结构 [root@localhost cmake]# tree . ├── build ├── CMakeLists.txt ├── COPYRIGHT ├── doc │ └── hello.txt ├── README ├── runhello.sh └── src ├── CMakeLists.txt └── main.cpp 3 directories, 7 files 安装文件COPYRIGHT和READMEINSTALL(FILES COPYRIGHT README DESTINATION share&#x2F;doc&#x2F;cmake&#x2F;) FILES：文件 DESTINATION： 1、写绝对路径 2、可以写相对路径，相对路径实际路径是：${CMAKE_INSTALL_PREFIX}&#x2F;&lt;DESTINATION 定义的路径&gt; CMAKE_INSTALL_PREFIX 默认是在 &#x2F;usr&#x2F;local&#x2F; cmake -DCMAKE_INSTALL_PREFIX&#x3D;&#x2F;usr 在cmake的时候指定CMAKE_INSTALL_PREFIX变量的路径 安装脚本runhello.shPROGRAMS：非目标文件的可执行程序安装(比如脚本之类) INSTALL(PROGRAMS runhello.sh DESTINATION bin) 说明：实际安装到的是 &#x2F;usr&#x2F;bin 安装 doc 中的 hello.txt 一、是通过在 doc 目录建立CMakeLists.txt ，通过install下的file 二、是直接在工程目录通过 INSTALL(DIRECTORY doc&#x2F; DESTINATION share&#x2F;doc&#x2F;cmake) DIRECTORY 后面连接的是所在 Source 目录的相对路径 注意：abc 和 abc&#x2F;有很大的区别 目录名不以&#x2F;结尾：这个目录将被安装为目标路径下的 目录名以&#x2F;结尾：将这个目录中的内容安装到目标路径 安装过程cmake .. make make install 静态库和动态库的构建任务： １，建立一个静态库和动态库，提供 HelloFunc 函数供其他程序编程使用，HelloFunc 向终端输出 Hello World 字符串。 ２，安装头文件与共享库。 静态库和动态库的区别 静态库的扩展名一般为“.a”或“.lib”；动态库的扩展名一般为“.so”或“.dll”。 静态库在编译时会直接整合到目标程序中，编译成功的可执行文件可独立运行 动态库在编译时不会放到连接的目标程序中，即可执行文件无法单独运行。 构建实例[root@localhost cmake2]# tree . ├── build ├── CMakeLists.txt └── lib ├── CMakeLists.txt ├── hello.cpp └── hello.h hello.h中的内容 #ifndef HELLO_H #define Hello_H void HelloFunc(); #endif hello.cpp中的内容 #include &quot;hello.h&quot; #include &lt;iostream&gt; void HelloFunc()&#123; std::cout &lt;&lt; &quot;Hello World&quot; &lt;&lt; std::endl; &#125; 项目中的cmake内容 PROJECT(HELLO) ADD_SUBDIRECTORY(lib bin) lib中CMakeLists.txt中的内容 SET(LIBHELLO_SRC hello.cpp) ADD_LIBRARY(hello SHARED $&#123;LIBHELLO_SRC&#125;) ADD_LIBRARYADD_LIBRARY(hello SHARED ${LIBHELLO_SRC}) hello：就是正常的库名，生成的名字前面会加上lib，最终产生的文件是libhello.so SHARED，动态库 STATIC，静态库 ${LIBHELLO_SRC} ：源文件 同时构建静态和动态库// 如果用这种方式，只会构建一个动态库，不会构建出静态库，虽然静态库的后缀是.a ADD_LIBRARY(hello SHARED $&#123;LIBHELLO_SRC&#125;) ADD_LIBRARY(hello STATIC $&#123;LIBHELLO_SRC&#125;) // 修改静态库的名字，这样是可以的，但是我们往往希望他们的名字是相同的，只是后缀不同而已 ADD_LIBRARY(hello SHARED $&#123;LIBHELLO_SRC&#125;) ADD_LIBRARY(hello_static STATIC $&#123;LIBHELLO_SRC&#125;) SET_TARGET_PROPERTIES这条指令可以用来设置输出的名称，对于动态库，还可以用来指定动态库版本和 API 版本 同时构建静态和动态库 SET(LIBHELLO_SRC hello.cpp) ADD_LIBRARY(hello_static STATIC $&#123;LIBHELLO_SRC&#125;) //对hello_static的重名为hello SET_TARGET_PROPERTIES(hello_static PROPERTIES OUTPUT_NAME &quot;hello&quot;) //cmake 在构建一个新的target 时，会尝试清理掉其他使用这个名字的库，因为，在构建 libhello.so 时， 就会清理掉 libhello.a SET_TARGET_PROPERTIES(hello_static PROPERTIES CLEAN_DIRECT_OUTPUT 1) ADD_LIBRARY(hello SHARED $&#123;LIBHELLO_SRC&#125;) SET_TARGET_PROPERTIES(hello PROPERTIES OUTPUT_NAME &quot;hello&quot;) SET_TARGET_PROPERTIES(hello PROPERTIES CLEAN_DIRECT_OUTPUT 1) 动态库的版本号一般动态库都有一个版本号的关联 libhello.so.1.2 libhello.so -&gt;libhello.so.1 libhello.so.1-&gt;libhello.so.1.2 CMakeLists.txt 插入如下 SET_TARGET_PROPERTIES(hello PROPERTIES VERSION 1.2 SOVERSION 1) VERSION 指代动态库版本，SOVERSION 指代 API 版本。 安装共享库和头文件本例中我们将 hello 的共享库安装到&#x2F;lib目录， 将 hello.h 安装到&#x2F;include&#x2F;hello 目录 //文件放到该目录下 INSTALL(FILES hello.h DESTINATION include/hello) //二进制，静态库，动态库安装都用TARGETS //ARCHIVE 特指静态库，LIBRARY 特指动态库，RUNTIME 特指可执行目标二进制。 INSTALL(TARGETS hello hello_static LIBRARY DESTINATION lib ARCHIVE DESTINATION lib) 注意： 安装的时候，指定一下路径，放到系统下 cmake -DCMAKE_INSTALL_PREFIX=/usr .. 使用外部共享库和头文件准备工作，新建一个目录来使用外部共享库和头文件 [root@MiWiFi-R4CM-srv cmake3]# tree . ├── build ├── CMakeLists.txt └── src ├── CMakeLists.txt └── main.cpp main.cpp #include &lt;hello.h&gt; int main()&#123; HelloFunc(); &#125; 解决：make后头文件找不到的问题PS：include &lt;hello&#x2F;hello.h&gt; 这样include是可以，这么做的话，就没啥好讲的了 关键字：INCLUDE_DIRECTORIES 这条指令可以用来向工程添加多个特定的头文件搜索路径，路径之间用空格分割 在CMakeLists.txt中加入头文件搜索路径 INCLUDE_DIRECTORIES(&#x2F;usr&#x2F;include&#x2F;hello) 感谢： 网友：zcc720的提醒 解决：找到引用的函数问题报错信息：undefined reference to &#96;HelloFunc()’ 关键字：LINK_DIRECTORIES 添加非标准的共享库搜索路径 指定第三方库所在路径，LINK_DIRECTORIES(&#x2F;home&#x2F;myproject&#x2F;libs) 关键字：TARGET_LINK_LIBRARIES 添加需要链接的共享库 TARGET_LINK_LIBRARIES的时候，只需要给出动态链接库的名字就行了。 在CMakeLists.txt中插入链接共享库，主要要插在executable的后面 查看main的链接情况 [root@MiWiFi-R4CM-srv bin]# ldd main linux-vdso.so.1 =&gt; (0x00007ffedfda4000) libhello.so =&gt; /lib64/libhello.so (0x00007f41c0d8f000) libstdc++.so.6 =&gt; /lib64/libstdc++.so.6 (0x00007f41c0874000) libm.so.6 =&gt; /lib64/libm.so.6 (0x00007f41c0572000) libgcc_s.so.1 =&gt; /lib64/libgcc_s.so.1 (0x00007f41c035c000) libc.so.6 =&gt; /lib64/libc.so.6 (0x00007f41bff8e000) /lib64/ld-linux-x86-64.so.2 (0x00007f41c0b7c000) 链接静态库 TARGET_LINK_LIBRARIES(main libhello.a) 特殊的环境变量 CMAKE_INCLUDE_PATH 和 CMAKE_LIBRARY_PATH注意：这两个是环境变量而不是 cmake 变量，可以在linux的bash中进行设置 我们上面例子中使用了绝对路径INCLUDE_DIRECTORIES(&#x2F;usr&#x2F;include&#x2F;hello)来指明include路径的位置 我们还可以使用另外一种方式，使用环境变量export CMAKE_INCLUDE_PATH&#x3D;&#x2F;usr&#x2F;include&#x2F;hello 补充：生产debug版本的方法：cmake .. -DCMAKE_BUILD_TYPE&#x3D;debug","categories":[{"name":"Tools","slug":"Tools","permalink":"https://messenger1th.github.io/categories/Tools/"}],"tags":[]},{"title":"Persistence","slug":"Redis/Persistence","date":"2024-07-24T14:47:34.222Z","updated":"2024-07-24T14:47:34.222Z","comments":true,"path":"2024/07/24/Redis/Persistence/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Redis/Persistence/","excerpt":"","text":"持久化Redis提供了2种持久化的方式，「 AOF 日志」和 「 RDB 快照」。 这两种计数都会各用一个日志文件记录信息，但形式的内容不同。 AOF文件记录操作命令 RDB的文件内容是二进制数据。 AOF日志AOF全称Append only file，每一条命令以追加形式写入到一个文件。重启Redis时，读取这个文件以达到恢复的作用。注意，只会记录写操作，因为读操作不改变数据。 文件内容这种保存写操作命令到日志的持久化方式，就是 Redis 里的 AOF(*Append Only File*) 持久化功能，注意只会记录写操作命令，读操作命令是不会被记录的，因为没意义。 在 Redis 中 AOF 持久化功能默认是不开启的，需要我们修改 redis.conf 配置文件中的以下参数： AOF 日志文件其实就是普通的文本，我们可以通过 cat 命令查看里面的内容，不过里面的内容如果不知道一定的规则的话，可能会看不懂。 我这里以「set name xiaolin」命令作为例子，Redis 执行了这条命令后，记录在 AOF 日志里的内容如下图： 我这里给大家解释下。 「*3」表示当前命令有三个部分，每部分都是以「$+数字」开头，后面紧跟着具体的命令、键或值。然后，这里的「数字」表示这部分中的命令、键或值一共有多少字节。例如，「$3 set」表示这部分有 3 个字节，也就是「set」命令这个字符串的长度。 优点及缺陷优点：不知道大家注意到没有，Redis 是先执行写操作命令后，才将该命令记录到 AOF 日志里的，这样可以避免检查开销，只有命令执行成功，才会将命令记录到AOF日志。 缺陷：执行操作和记录日志是两个过程，当Redis在这两步中间时宕机了，这个数据就有会有丢失的分险。 落盘策略日志写入磁盘的过程是在主线程完成的，流程如下。 具体过程为 Redis执行完命令后，会将命令按照前面提到的协议格式，追加到server.aof_buf缓冲区。 通过write系统调用，将aof_buf缓冲区的数据写入到AOF文件，此时数据并没有写入到磁盘。 具体写入磁盘的时机由内核决定，也可以主动调用fsync写入。 Redis提供了3种策略，控制fsync的调用时机。在redis.conf的配置文件中appendfsync配置项有以下3种参数可选： Always，即每次写操作结束，都会主动调用fsync。 Everysec，即每秒调用一次fsync，这个过程由一个子线程完成。由主线程唤醒子线程。 No，意味着不主动调用fsync，由操作系统负责写入磁盘的时机。 重写机制当一个数据被频繁修改时，前面的命令就没有保存的意义了。比如， 127.0.0.1:6379&gt; set key value OK 127.0.0.1:6379&gt; set key NewValue OK 前一个命令就没有保存的意义了，所以可以通过重写机制，只记录有效的命令，节省一些空间。 注意，重写时，需要写到新AOF文件之后再覆盖过去，否则可能导致写入到一半的情况，导致AOF文件不可用。 后台重写由于重写整个文件是比较耗时的，所以**重写 AOF 过程是由后台子进程 bgrewriteaof来完成的**，这么做可以达到两个好处： 子进程进行 AOF 重写期间，主进程可以继续处理命令请求，从而避免阻塞主进程； 子进程不会有data race的问题，借助Linux提供的copy on write也可以很大程度上减少数据复制。 Redis设置了一个AOF重写缓冲区，在AOF后台重写期间，Redis会将命令同时写入「AOF 缓冲区」和 「AOF 重写缓冲区」。 当子进程完成 AOF 重写工作（扫描数据库中所有数据，逐一把内存数据的键值对转换成一条命令，再将命令记录到重写日志）后，会向主进程发送一条信号，信号是进程间通讯的一种方式，且是异步的。 主进程收到该信号后，会调用一个信号处理函数，该函数主要做以下工作： 将 AOF 重写缓冲区中的所有内容追加到新的 AOF 的文件中，使得新旧两个 AOF 文件所保存的数据库状态一致； 新的 AOF 的文件进行改名，覆盖现有的 AOF 文件。 信号函数执行完后，主进程就可以继续像往常一样处理命令了。 在整个 AOF 后台重写过程中，除了发生写时复制会对主进程造成阻塞，还有信号处理函数执行时也会对主进程造成阻塞，在其他时候，AOF 后台重写都不会阻塞主进程。 RDB快照Redis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave，他们的区别就在于是否在「主线程」里执行： 执行了 save 命令，就会在主线程生成 RDB 文件，由于和执行操作命令在同一个线程，所以如果写入 RDB 文件的时间太长，会阻塞主线程； 执行了 bgsave 命令，会创建一个子进程来生成 RDB 文件，这样可以避免主线程的阻塞； RDB 文件的加载工作是在服务器启动时自动执行的，Redis 并没有提供专门用于加载 RDB 文件的命令。 Redis 还可以通过配置文件(redis.conf)的选项来实现每隔一段时间自动执行一次 bgsave 命令，默认会提供以下配置： save 900 1 save 300 10 save 60 10000 别看选项名叫 save，实际上执行的是 bgsave 命令，也就是会创建子进程来生成 RDB 快照文件。 只要满足上面条件的任意一个，就会执行 bgsave，它们的意思分别是： 900 秒之内，对数据库进行了至少 1 次修改； 300 秒之内，对数据库进行了至少 10 次修改； 60 秒之内，对数据库进行了至少 10000 次修改。 这里提一点，Redis 的快照是全量快照，也就是说每次执行快照，都是把内存中的「所有数据」都记录到磁盘中。 所以可以认为，执行快照是一个比较重的操作，如果频率太频繁，可能会对 Redis 性能产生影响。如果频率太低，服务器故障时，丢失的数据会更多。 通常可能设置至少 5 分钟才保存一次快照，这时如果 Redis 出现宕机等情况，则意味着最多可能丢失 5 分钟数据。 这就是 RDB 快照的缺点，在服务器发生故障时，丢失的数据会比 AOF 持久化的方式更多，因为 RDB 快照是全量快照的方式，因此执行的频率不能太频繁，否则会影响 Redis 性能，而 AOF 日志可以以秒级的方式记录操作命令，所以丢失的数据就相对更少。 后台快照RDB的快照耗时一般比较长，所以推荐更bgsave，通过fork一个子进程，用到Linux提供的copy-on-write技术。 在生成RDB期间，主线程执行了写操作，那么RDB快照不会包含这个命令，RDB并没有提供AOF那样的一个缓冲区。 AOF+RDB Redis 配置文件redis.conf将下面这个配置项设置成 yes： aof-use-rdb-preamble yes 混合持久化工作在 AOF 日志重写过程。 当开启了混合持久化时，在 AOF 重写日志时，fork 出来的重写子进程会先将与主线程共享的内存数据以 RDB 方式写入到 AOF 文件，然后主线程处理的操作命令会被记录在重写缓冲区里，重写缓冲区里的增量命令会以 AOF 方式写入到 AOF 文件，写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。 也就是说，使用了混合持久化，AOF 文件的前半部分是 RDB 格式的全量数据，后半部分是 AOF 格式的增量数据。 这样的好处在于，重启 Redis 加载数据的时候，由于前半部分是 RDB 内容，这样加载的时候速度会很快。 加载完 RDB 的内容后，才会加载后半部分的 AOF 内容，这里的内容是 Redis 后台子进程重写 AOF 期间，主线程处理的操作命令，可以使得数据更少的丢失。 大Key影响AOF影响 在AOF3种策略下，有不同的影响 Always，由于是主线程执行fsync，所以会阻塞主线程一段时间。 EverySec，由于是子线程，所以不会阻塞主线程。 No，也不会。 RDB影响 fork创建子进程的途中，由于要复制父进程的页表等数据结构，阻塞的时间跟页表的大小有关，页表越大，阻塞的时间也越长； 创建完子进程后，如果子进程或者父进程修改了共享数据，就会发生写时复制，这期间会拷贝物理内存，如果内存越大，自然阻塞的时间也越长； 这里额外提一下， 如果 Linux 开启了内存大页，会影响 Redis 的性能的。 Linux 内核从 2.6.38 开始支持内存大页机制，该机制支持 2MB 大小的内存页分配，而常规的内存页分配是按 4KB 的粒度来执行的。 如果采用了内存大页，那么即使客户端请求只修改 100B 的数据，在发生写时复制后，Redis 也需要拷贝 2MB 的大页。相反，如果是常规内存页机制，只用拷贝 4KB。 两者相比，你可以看到，每次写命令引起的复制内存页单位放大了 512 倍，会拖慢写操作的执行时间，最终导致 Redis 性能变慢。 那该怎么办呢？很简单，关闭内存大页（默认是关闭的）。 禁用方法如下： echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled 其他影响 大 key 除了会影响持久化之外，还会有以下的影响。 客户端超时阻塞。由于 Redis 执行命令是单线程处理，然后在操作大 key 时会比较耗时，那么就会阻塞 Redis，从客户端这一视角看，就是很久很久都没有响应。 引发网络阻塞。每次获取大 key 产生的网络流量较大，如果一个 key 的大小是 1 MB，每秒访问量为 1000，那么每秒会产生 1000MB 的流量，这对于普通千兆网卡的服务器来说是灾难性的。 阻塞工作线程。如果使用 del 删除大 key 时，会阻塞工作线程，这样就没办法处理后续的命令。可以通过unlink来删除，它会唤醒一个子线程，异步删除。 内存分布不均。集群模型在 slot 分片均匀情况下，会出现数据和查询倾斜情况，部分有大 key 的 Redis 节点占用内存多，QPS 也会比较大。","categories":[{"name":"Redis","slug":"Redis","permalink":"https://messenger1th.github.io/categories/Redis/"}],"tags":[]},{"title":"Key Evication","slug":"Redis/Key Evication","date":"2024-07-24T14:47:34.218Z","updated":"2024-07-24T14:47:34.218Z","comments":true,"path":"2024/07/24/Redis/Key Evication/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Redis/Key%20Evication/","excerpt":"","text":"淘汰策略Redis是可以设置key的过期时间的，这些key会被存储到一个过期字典（expires dict）中，也就是说「过期字典」保存了数据库中所有 key 的过期时间。 typedef struct redisDb &#123; dict *dict; /* 数据库键空间，存放着所有的键值对 */ dict *expires; /* 键的过期时间 */ .... &#125; redisDb; 过期字典数据结构结构如下： 过期字典的 key 是一个指针，指向某个键对象； 过期字典的 value 是一个 long long 类型的整数，这个整数保存了 key 的过期时间； 如下图所示 过期删除策略常见策略对于过期的key，有不同的删除策略可以设置。常见的删除的策略如： 定时删除； 惰性删除； 定期删除； 定时删除 定时删除就是，设置key时，创建一个定时事件，当时间到达后，由事件处理器删除key。 优点是，可以让key尽快被删除，让内存尽快得到释放。 缺点是，需要定期检查，会占用一定的CPU时间。 惰性删除 惰性删除就是当访问到该key时，判断是否过期，过期则删除。 优点是，不需要额外检查的开销。 缺点是，可能key很久都没有访问，导致内存越来越少。 定期删除 定期删除策略的做法是，每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key。 优点是，通过限制删除操作执行的时长和频率，来减少删除操作对 CPU 的影响，同时也能删除一部分过期的数据减少了过期键对空间的无效占用。 缺点是， 内存清理方面没有定时删除效果好，同时没有惰性删除使用的系统资源少。算是折中的策略 难以确定删除操作执行的时长和频率。如果执行的太频繁，定期删除策略变得和定时删除策略一样，对CPU不友好；如果执行的太少，那又和惰性删除一样了，过期 key 占用的内存不会及时得到释放。 Redis过期删除策略前面介绍了三种过期删除策略，每一种都有优缺点，仅使用某一个策略都不能满足实际需求。 所以， Redis 选择「惰性删除+定期删除」这两种策略配和使用，以求在合理使用 CPU 时间和避免内存浪费之间取得平衡。 惰性删除的实现 Redis 的惰性删除策略由 db.c 文件中的 expireIfNeeded 函数实现，代码如下： int expireIfNeeded(redisDb *db, robj *key) &#123; // 判断 key 是否过期 if (!keyIsExpired(db,key)) return 0; .... /* 删除过期键 */ .... // 如果 server.lazyfree_lazy_expire 为 1 表示异步删除，反之同步删除； return server.lazyfree_lazy_expire ? dbAsyncDelete(db,key) : dbSyncDelete(db,key); &#125; Redis 在访问或者修改 key 之前，都会调用 expireIfNeeded 函数对其进行检查，检查 key 是否过期： 如果过期，则删除该 key，至于选择异步删除，还是选择同步删除，根据 lazyfree_lazy_expire 参数配置决定（Redis 4.0版本开始提供参数），然后返回 null 客户端； 如果没有过期，不做任何处理，然后返回正常的键值对给客户端； 定期删除的实现 每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key。 1、这个间隔检查的时间是多长呢？ 在 Redis 中，默认每秒进行 10 次过期检查一次数据库，此配置可通过 Redis 的配置文件 redis.conf 进行配置，配置键为 hz 它的默认值是 hz 10。 特别强调下，每次检查数据库并不是遍历过期字典中的所有 key，而是从数据库中随机抽取一定数量的 key 进行过期检查。 2、随机抽查的数量是多少呢？ 我查了下源码，定期删除的实现在 expire.c 文件下的 activeExpireCycle 函数中，其中随机抽查的数量由 ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP 定义的，它是写死在代码中的，数值是 20。 也就是说，数据库每轮抽查时，会随机选择 20 个 key 判断是否过期。 接下来，详细说说 Redis 的定期删除的流程： 从过期字典中随机抽取 20 个 key； 检查这 20 个 key 是否过期，并删除已过期的 key； 如果本轮检查的已过期 key 的数量，超过 5 个（20&#x2F;4），也就是「已过期 key 的数量」占比「随机抽取 key 的数量」大于 25%，则继续重复步骤 1；如果已过期的 key 比例小于 25%，则停止继续删除过期 key，然后等待下一轮再检查。 可以看到，定期删除是一个循环的流程。 那 Redis 为了保证定期删除不会出现循环过度，导致线程卡死现象，为此增加了定期删除循环流程的时间上限，默认不会超过 25ms。 内存淘汰策略前面是对于过期key的删除策略，内存淘汰是指，内存已经超过Redis设置的最大内存之后，则会使用内存淘汰策略删除符合条件的key。 Redis 最大运行内存在配置文件 redis.conf 中，可以通过参数 maxmemory &lt;bytes&gt; 来设定最大运行内存，只有在 Redis 的运行内存达到了我们设置的最大运行内存，才会触发内存淘汰策略。 不同位数的操作系统，maxmemory 的默认值是不同的： 在 64 位操作系统中，maxmemory 的默认值是 0，表示没有内存大小限制，那么不管用户存放多少数据到 Redis 中，Redis 也不会对可用内存进行检查，直到 Redis 实例因内存不足而崩溃也无作为。 在 32 位操作系统中，maxmemory 的默认值是 3G，因为 32 位的机器最大只支持 4GB 的内存，而系统本身就需要一定的内存资源来支持运行，所以 32 位操作系统限制最大 3 GB 的可用内存是非常合理的，这样可以避免因为内存不足而导致 Redis 实例崩溃。 Redis内存淘汰策略针对是否设置过期时间，有不同的策略 在设置了过期时间的数据中进行淘汰： volatile-random：随机淘汰设置了过期时间的任意键值； volatile-ttl：优先淘汰更早过期的键值。 volatile-lru（Redis3.0 之前，默认的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最久未使用的键值； volatile-lfu（Redis 4.0 后新增的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最少使用的键值； 在所有数据范围内进行淘汰： allkeys-random：随机淘汰任意键值; allkeys-lru：淘汰整个键值中最久未使用的键值； allkeys-lfu（Redis 4.0 后新增的内存淘汰策略）：淘汰整个键值中最少使用的键值。 设置内存淘汰策略有两种方法： 方式一：通过“config set maxmemory-policy &lt;策略&gt;”命令设置。它的优点是设置之后立即生效，不需要重启 Redis 服务，缺点是重启 Redis 之后，设置就会失效。 方式二：通过修改 Redis 配置文件修改，设置“maxmemory-policy &lt;策略&gt;”，它的优点是重启 Redis 服务后配置不会丢失，缺点是必须重启 Redis 服务，设置才能生效。 LRU与LFURedis中，LRU和LFU都是通过一个lru字段实现的 typedef struct redisObject &#123; ... // 24 bits，用于记录对象的访问信息 unsigned lru:24; ... &#125; robj; 在 LRU 算法中，Redis 对象头的 24 bits 的 lru 字段是用来记录 key 的访问时间戳，因此在 LRU 模式下，Redis可以根据对象头中的 lru 字段记录的值，来比较最后一次 key 的访问时间长，从而淘汰最久未被使用的 key。 在 LFU 算法中，Redis对象头的 24 bits 的 lru 字段被分成两段来存储，高 16bit 存储 ldt(Last Decrement Time)，低 8bit 存储 logc(Logistic Counter)。 ldt 是用来记录 key 的访问时间戳； logc 是用来记录 key 的访问频次，它的值越小表示使用频率越低，越容易淘汰，每个新加入的 key 的logc 初始值为 5。 注意，logc 并不是单纯的访问次数，而是访问频次（访问频率），因为 logc 会随时间推移而衰减的。 在每次 key 被访问时，会先对 logc 做一个衰减操作，衰减的值跟前后访问时间的差距有关系，如果上一次访问的时间与这一次访问的时间差距很大，那么衰减的值就越大，这样实现的 LFU 算法是根据访问频率来淘汰数据的，而不只是访问次数。访问频率需要考虑 key 的访问是多长时间段内发生的。key 的先前访问距离当前时间越长，那么这个 key 的访问频率相应地也就会降低，这样被淘汰的概率也会更大。 对 logc 做完衰减操作后，就开始对 logc 进行增加操作，增加操作并不是单纯的 + 1，而是根据概率增加，如果 logc 越大的 key，它的 logc 就越难再增加。 所以，Redis 在访问 key 时，对于 logc 是这样变化的： 先按照上次访问距离当前的时长，来对 logc 进行衰减； 然后，再按照一定概率增加 logc 的值 redis.conf 提供了两个配置项，用于调整 LFU 算法从而控制 logc 的增长和衰减： lfu-decay-time 用于调整 logc 的衰减速度，它是一个以分钟为单位的数值，默认值为1，lfu-decay-time 值越大，衰减越慢； lfu-log-factor 用于调整 logc 的增长速度，lfu-log-factor 值越大，logc 增长越慢。","categories":[{"name":"Redis","slug":"Redis","permalink":"https://messenger1th.github.io/categories/Redis/"}],"tags":[]},{"title":"Distributed Lock","slug":"Redis/Distributed Lock","date":"2024-07-24T14:47:34.218Z","updated":"2024-07-24T14:47:34.218Z","comments":true,"path":"2024/07/24/Redis/Distributed Lock/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Redis/Distributed%20Lock/","excerpt":"","text":"","categories":[{"name":"Redis","slug":"Redis","permalink":"https://messenger1th.github.io/categories/Redis/"}],"tags":[]},{"title":"Data Structure","slug":"Redis/Data Structure","date":"2024-07-24T14:47:34.208Z","updated":"2024-07-24T14:47:34.208Z","comments":true,"path":"2024/07/24/Redis/Data Structure/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Redis/Data%20Structure/","excerpt":"","text":"Redis中常用数据结构 String List Hash Set Zet String实现原理string有3种编码模式 INT：当字符串是数字，并且小于 long long时。 EMBSTR：字符串长度小于等于阈值。 RAW：上面的条件都不满足时，才用raw。 INT如果一个字符串对象保存的是整数值， 并且这个整数值可以用 long 类型来表示， 那么字符串对象会将整数值保存在字符串对象结构的 ptr 属性里面（将 void* 转换成 long ）， 并将字符串对象的编码设置为 int 。 EMBSTRsdshdr的内存是和redisObject一块分配的，是连续的。所以叫做embed string。 因为内存分配需要 RAW 不难发现RAW和EMBSTR都有个sdshdr结构，会在Data Structure Impl文章中介绍。 应用场景缓存对象使用 String 来缓存对象有两种方式： 直接缓存整个对象的 JSON，命令例子： SET user:1 &#39;&#123;&quot;name&quot;:&quot;xiaolin&quot;, &quot;age&quot;:18&#125;&#39;。 采用将 key 进行分离为 user:ID:属性，采用 MSET 存储，用 MGET 获取各属性值，命令例子： MSET user:1:name xiaolin user:1:age 18 user:2:name xiaomei user:2:age 20。 常规计数因为 Redis 处理命令是单线程，所以执行命令的过程是原子的。因此 String 数据类型适合计数场景，比如计算访问次数、点赞、转发、库存数量等等。 比如计算文章的阅读量： # 初始化文章的阅读量 &gt; SET aritcle:readcount:1001 0 OK #阅读量+1 &gt; INCR aritcle:readcount:1001 (integer) 1 #阅读量+1 &gt; INCR aritcle:readcount:1001 (integer) 2 #阅读量+1 &gt; INCR aritcle:readcount:1001 (integer) 3 # 获取对应文章的阅读量 &gt; GET aritcle:readcount:1001 &quot;3&quot; 分布式锁SET 命令有个 NX 参数可以实现「key不存在才插入」，可以用它配合过期时间来实现分布式锁： 如果 key 不存在，则显示插入成功，可以用来表示加锁成功； 如果 key 存在，则会显示插入失败，可以用来表示加锁失败。 更具体的实现，见其他文章。 共享 Session 信息通常我们在开发后台管理系统时，会使用 Session 来保存用户的会话(登录)状态，这些 Session 信息会被保存在服务器端，但这只适用于单系统应用，如果是分布式系统此模式将不再适用。 例如用户一的 Session 信息被存储在服务器一，但第二次访问时用户一被分配到服务器二，这个时候服务器并没有用户一的 Session 信息，就会出现需要重复登录的问题，问题在于分布式系统每次会把请求随机分配到不同的服务器。 分布式系统单独存储 Session 流程图： 因此，我们需要借助 Redis 对这些 Session 信息进行统一的存储和管理，这样无论请求发送到那台服务器，服务器都会去同一个 Redis 获取相关的 Session 信息，这样就解决了分布式系统下 Session 存储的问题。 分布式系统使用同一个 Redis 存储 Session 流程图： List实现原理3.2版本之前，List对象有两种编码，方式 ZipList LinkedList：双向链表 当满足如下条件时，用ZipList编码 当列表对象保存的所有字符串对象长度都小于64字节； 列表元素小于512个；（注意，这是List的限制，不是底层的ZipList的限制） 不满足时，自动转换成LinkedList编码。 Ziplist采用压缩列表实现，内存布局非常紧凑，指针域的空间占比非常少。 ZipList在数据较少时，用于节约内存，插入时也会造成多节点的内存复制。 LinkedList在数据多时，提升效率，但也会导致指针域占比高，占用不少内存。 3.2版本引入了quicklist，是ZipList和Linked的结合体。 LinkedList是一个节点放一个数据，现在QuickList是单个节点寸一个ZipList，即多个数据。 优势是 数据较少时，只有一个节点，即是ZipList。 数据多时，同时做了折中。 ZipList被ListPack取代 ZipList本身存在一个连锁更行的问题，所以在Redis7.0后，被ListPack给取代了，但本质都是压缩链表，内存是紧凑在一块的。 应用场景简单消息队列 不支持多个消费者消费同一条消息 不支持消费组的实现 Set实现原理Set有两种编码方式，整数集合INTSET和HASHTABLE。 INTSET当以下条件满足时，是用INTSET编码，反之使用HASHTABLE。 元素都是整数 元素数量不超过512个 INTSET实际上是有序的数组，通过二分查找来查询。布局如下 HASHTABLE实际上就是一个哈希表。 应用场景点赞点赞作为一个高频率的操作，如果每次操作都读写数据库会增加数据库的压力，所以采用缓存+定时任务来实现。点赞数据是在redis中缓存半小时，同时定时任务是每隔5分钟执行一次，做持久化存储，这里的缓存时间和任务执行时间可根据项目情况而定。 共同关注集合取交集。 抽奖活动存储某活动中中奖的用户名 ，Set 类型因为有去重功能，可以保证同一个用户不会中奖两次。 key为抽奖活动名，value为员工名称，把所有员工名称放入抽奖箱 。 如果允许重复中奖，可以使用 SRANDMEMBER 命令。 如果不允许重复中奖，可以使用 SPOP 命令。 Hash实现原理Hset底层有两种编码格式，压缩列表和HASHTABLE。 满足以下两个条件时，使用压缩链表，反之使用HASHTABLE。 Hset对象保存的所有key和value的长度都小于64字节。 Hset对象元素小于512个。 其中压缩链表就是把key-value这整体作为entry存入压缩链表。 HASHTABLE的编码方式的话，和Set的区别在于，在Set中value始终为NULL，而HSet是对应的value。 应用场景缓存对象一个hash就是一个对象，存储对象的每一个元素。 在介绍 String 类型的应用场景时有所介绍，String + Json也是存储对象的一种方式，那么存储对象时，到底用 String + json 还是用 Hash 呢？ 一般对象用 String + Json 存储，对象中某些频繁变化的属性可以考虑抽出来用 Hash 类型存储。 购物车以用户 id 为 key，商品 id 为 field，商品数量为 value，恰好构成了购物车的3个要素，如下图所示。 涉及的命令如下： 添加商品：HSET cart:&#123;用户id&#125; &#123;商品id&#125; 1 添加数量：HINCRBY cart:&#123;用户id&#125; &#123;商品id&#125; 1 商品总数：HLEN cart:&#123;用户id&#125; 删除商品：HDEL cart:&#123;用户id&#125; &#123;商品id&#125; 获取购物车所有商品：HGETALL cart:&#123;用户id&#125; 当前仅仅是将商品ID存储到了Redis 中，在回显商品具体信息的时候，还需要拿着商品 id 查询一次数据库，获取完整的商品的信息。 Zset实现原理Zset底层有两种编码方式，一种是压缩链表，一种是SkipList+HT。 满足下列条件时，采用压缩链表编码，反之采用SkipList+HT。 列表保存的字符串对象都小于64字节 列表对象元素个数少于128个。 应用场景 电话排序 姓名排序","categories":[{"name":"Redis","slug":"Redis","permalink":"https://messenger1th.github.io/categories/Redis/"}],"tags":[]},{"title":"Cluster","slug":"Redis/Cluster","date":"2024-07-24T14:47:34.205Z","updated":"2024-07-24T14:47:34.205Z","comments":true,"path":"2024/07/24/Redis/Cluster/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Redis/Cluster/","excerpt":"","text":"集群","categories":[{"name":"Redis","slug":"Redis","permalink":"https://messenger1th.github.io/categories/Redis/"}],"tags":[]},{"title":"Data Structure Impl","slug":"Redis/Data Structure Impl","date":"2024-07-24T14:47:34.205Z","updated":"2024-07-24T14:47:34.205Z","comments":true,"path":"2024/07/24/Redis/Data Structure Impl/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Redis/Data%20Structure%20Impl/","excerpt":"","text":"数据结构实现 以7.0.10版为例。 层级数据库在Redis中，数据库以redisDB对象存在，定义如下： typedef struct redisDb &#123; dict *dict; /* The keyspace for this DB */ dict *expires; /* Timeout of keys with a timeout set */ dict *blocking_keys; /* Keys with clients waiting for data (BLPOP)*/ dict *ready_keys; /* Blocked keys that received a PUSH */ dict *watched_keys; /* WATCHED keys for MULTI/EXEC CAS */ int id; /* Database ID */ long long avg_ttl; /* Average TTL, just for stats */ unsigned long expires_cursor; /* Cursor of the active expire cycle. */ list *defrag_later; /* List of key names to attempt to defrag one by one, gradually. */ clusterSlotToKeyMapping *slots_to_keys; /* Array of slots to keys. Only used in cluster mode (db 0). */ &#125; redisDb; 对象Redis是key-value存储，key value和都被抽象成对象。 key只能是string，value可以是多重类型，比如string，set，Zset、list等。 定义如下 //version: 7.0.10 typedef struct redisObject &#123; unsigned type:4; unsigned encoding:4; unsigned lru:LRU_BITS; /* LRU time (relative to global lru_clock) or * LFU data (least significant 8 bits frequency * and most significant 16 bits access time). */ int refcount; void *ptr; &#125; robj; type: 是哪种Redis对象。 encoding：表示对象是哪种底层编码，比如string的对象可以是embstr、也可以是raw。通过object encoding [key]来查看。 lru：lru相关，缓存淘汰机制。 refcount：引用计数，描述有多少个指针，指向该对象。 ptr：内容指针，指向实际的对象。 String编码格式INT如果一个字符串对象保存的是整数值， 并且这个整数值可以用 long 类型来表示， 那么字符串对象会将整数值保存在字符串对象结构的 ptr 属性里面（将 void* 转换成 long ）， 并将字符串对象的编码设置为 int 。 EMBSTRsdshdr的内存是和redisObject一块分配的，是连续的。所以叫做embed string。 因为内存分配需要 RAW 不难发现RAW和EMBSTR都有个sdshdr结构。 SDS字符串应用很频繁，在C语言中的字符串以\\0结尾，存在一些问题。 字符串里面不能含有 “\\0” 字符，否则最先被程序读入的 “\\0” 字符将被误认为是字符串结尾，这个限制使得 C 语言的字符串只能保存文本数据，不能保存像图片、音频、视频文化这样的二进制数据（这也是一个可以改进的地方） 使用strcat拼接时需要程序员自己考虑内存长度，不注意就会导致段错误。 获取长度时，需要遍历整个字符串，直到遇到\\0这个字符。 Redis的SDS解决了这些问题。 原理在7.0.10的版本下，Redis的SDS按照长度分为sdshdr8、sdshdr16、sdshdr32、sdshdr64等多个长度。以sdshdr32为例，结构如下。 struct __attribute__ ((__packed__)) sdshdr32 &#123; uint32_t len; /* used */ uint32_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[]; &#125;; len，记录了字符串长度。这样获取字符串长度的时候，只需要返回这个成员变量值就行，时间复杂度只需要 O（1）。 alloc，分配给字符数组的空间长度。这样在修改字符串的时候，可以通过 alloc - len 计算出剩余的空间大小，可以用来判断空间是否满足修改需求，如果不满足的话，就会自动将 SDS 的空间扩展至执行修改所需的大小，然后才执行实际的修改操作，所以使用 SDS 既不需要手动修改 SDS 的空间大小，也不会出现前面所说的缓冲区溢出的问题。 flags，用来表示不同类型的 SDS。一共设计了 5 种类型，分别是 sdshdr5、sdshdr8、sdshdr16、sdshdr32 和 sdshdr64，后面在说明区别之处。 buf[]，字符数组，用来保存实际数据。不仅可以保存字符串，也可以保存二进制数据。 C语言中的问题，得到了解决： 二进制安全：可以含有\\0，因为有一个长度变量记录长度。但是 SDS 为了兼容部分 C 语言标准库的函数， SDS 字符串结尾还是会加上 “\\0” 字符。 不会发生缓冲区溢出，因为sds暴露的api会检查缓冲区是否足够，不够则自动扩容。 $O(1)$复杂度获取字符串长度，直接获取len变量即可。 其中，扩容的规则如下 如果所需的 sds 长度小于 1 MB，那么最后的扩容是按照翻倍扩容来执行的，即 2 倍的newlen 如果所需的 sds 长度超过 1 MB，那么最后的扩容长度应该是 newlen + 1MB。 其他优化 设计多种长度sds，尽量节约空间。 Redis 在编程上还使用了专门的编译优化来节省内存空间，即在 struct 声明了 __attribute__ ((packed)) ，它的作用是：告诉编译器取消结构体在编译过程中的优化对齐，按照实际占用字节数进行对齐。这样，就可以节约空间。以时间换空间。 ZipList压缩链表的元素和控制头的内存是连续的，主要是为了节省指针域，整个空间都是连续的。 压缩列表在表头有三个字段： zlbytes，记录整个压缩列表占用对内存字节数； zltail，记录压缩列表「尾部」节点距离起始地址由多少字节，也就是列表尾的偏移量； zllen，记录压缩列表包含的节点数量； zlend，标记压缩列表的结束点，固定值 0xFF（十进制255）。 在压缩列表中，如果我们要查找定位第一个元素和最后一个元素，可以通过表头三个字段（zllen）的长度直接定位，复杂度是 O(1)。而查找其他元素时，就没有这么高效了，只能逐个查找，此时的复杂度就是 O(N) 了，因此压缩列表不适合保存过多的元素。 另外，压缩列表节点（entry）的构成如下： 压缩列表节点包含三部分内容： prevlen，记录了「前一个节点」的长度，目的是为了实现从后向前遍历； encoding，记录了当前节点实际数据的「类型和长度」，类型主要有两种：字符串和整数。 data，记录了当前节点的实际数据，类型和长度都由 encoding 决定； 其中，prevlen会根据前一个节点的长度进行不同的空间大小分配： 如果前一个节点的长度小于 254 字节，那么 prevlen 属性需要用 1 字节的空间来保存这个长度值； 如果前一个节点的长度大于等于 254 字节，那么 prevlen 属性需要用 5 字节的空间来保存这个长度值； 不难发现，prevlen记录的是前一个节点的大小，因此当前一个元素改动时，可能发生连锁反应。 例如下图，插入一个新节点new 会发生连锁反应，导致多次内存的复制。 listpack为了解决「连锁更新」的问题，引出来PackList， ZipList发生该问题的本质是 prevlen的字节数是可变动的。 prevlen表示的不是节点本身的大小，会收到其他节点长度变更，导致连锁变更。 所以其实只要解决一点，就可以解决这个问题。为了节约空间，ListPack从第二点入手，记录本节点的属性。其结构如下 listpack 头包含两个属性，分别记录了 listpack 总字节数和元素数量，然后 listpack 末尾也有个结尾标识。图中的 listpack entry 就是 listpack 的节点了。 每个 listpack 节点结构如下： ListPack节点的内存顺序如下 &lt;encoding-type&gt; &lt;element-data&gt; &lt;element-tot-len&gt; 这3个元素都是记录的本身的属性 encoding-type 编码类型 element-data 元素数据 element-tot-len 本元素除了本字段的长度 其他优化其中，elemnt-tot-len有一些特别：它所占用的每个字节的第一个bit用于表示是否结束。0是结束，1是继续，剩下7bit用于存储大小。例如0000-0001 1000-0100，我们逆序遍历时，首先读取最后那个字节，读到1000-0100,发现第一个bit是1，需要继续读取一个字节，直到第一个bit为0。所以这里element-tot-len一共两个字节，大小为 000-0001 000-0100， 即这个元素132字节。 QuickListquicklist 的结构体跟链表的结构体类似，都包含了表头和表尾，区别在于 quicklist 的节点是 quicklistNode。 typedef struct quicklist &#123; //quicklist的链表头 quicklistNode *head; //quicklist的链表头 //quicklist的链表尾 quicklistNode *tail; //所有压缩列表中的总元素个数 unsigned long count; //quicklistNodes的个数 unsigned long len; ... &#125; quicklist; 接下来看看，quicklistNode 的结构定义： typedef struct quicklistNode &#123; //前一个quicklistNode struct quicklistNode *prev; //前一个quicklistNode //下一个quicklistNode struct quicklistNode *next; //后一个quicklistNode //quicklistNode指向的压缩列表 unsigned char *zl; //压缩列表的的字节大小 unsigned int sz; //压缩列表的元素个数 unsigned int count : 16; //ziplist中的元素个数 .... &#125; quicklistNode; 可以看到，quicklistNode 结构体里包含了前一个节点和下一个节点指针，这样每个 quicklistNode 形成了一个双向链表。但是链表节点的元素不再是单纯保存元素值，而是保存了一个压缩列表，所以 quicklistNode 结构体里有个指向压缩列表的指针 *zl。 我画了一张图，方便你理解 quicklist 数据结构。 在向 quicklist 添加一个元素的时候，不会像普通的链表那样，直接新建一个链表节点。而是会检查插入位置的压缩列表是否能容纳该元素，如果能容纳就直接保存到 quicklistNode 结构里的压缩列表，如果不能容纳，才会新建一个新的 quicklistNode 结构。 quicklist 会控制 quicklistNode 结构里的压缩列表的大小或者元素个数，来规避潜在的连锁更新的风险，但是这并没有完全解决连锁更新的问题。 Hash为了避免 rehash 在数据迁移过程中，因拷贝数据的耗时，影响 Redis 性能的情况，所以 Redis 采用了渐进式 rehash，也就是将数据的迁移的工作不再是一次性迁移完成，而是分多次迁移。 渐进式rehash渐进式 rehash 步骤如下： 给「哈希表 2」 分配空间； 在 rehash 进行期间，每次哈希表元素进行新增、删除、查找或者更新操作时，Redis 除了会执行对应的操作之外，还会顺序将「哈希表 1 」中索引位置上的所有 key-value 迁移到「哈希表 2」 上； 随着处理客户端发起的哈希表操作请求数量越多，最终在某个时间点会把「哈希表 1 」的所有 key-value 迁移到「哈希表 2」，从而完成 rehash 操作。 这样就巧妙地把一次性大量数据迁移工作的开销，分摊到了多次处理请求的过程中，避免了一次性 rehash 的耗时操作。 在进行渐进式 rehash 的过程中，会有两个哈希表，所以在渐进式 rehash 进行期间，哈希表元素的删除、查找、更新等操作都会在这两个哈希表进行。 比如，查找一个 key 的值的话，先会在「哈希表 1」 里面进行查找，如果没找到，就会继续到哈希表 2 里面进行找到。 另外，在渐进式 rehash 进行期间，新增一个 key-value 时，会被保存到「哈希表 2 」里面，而「哈希表 1」 则不再进行任何添加操作，这样保证了「哈希表 1 」的 key-value 数量只会减少，随着 rehash 操作的完成，最终「哈希表 1 」就会变成空表。 rehash 触发条件介绍了 rehash 那么多，还没说什么时情况下会触发 rehash 操作呢？ rehash 的触发条件跟负载因子（load factor）有关系。 负载因子可以通过下面这个公式计算： 触发 rehash 操作的条件，主要有两个： 当负载因子大于等于 1 ，并且 Redis 没有在执行 bgsave 命令或者 bgrewiteaof 命令，也就是没有执行 RDB 快照或没有进行 AOF 重写的时候，就会进行 rehash 操作。 当负载因子大于等于 5 时，此时说明哈希冲突非常严重了，不管有没有有在执行 RDB 快照或 AOF 重写，都会强制进行 rehash 操作。 rehash的问题 对于键空间字典和过期字典，会有个 serverCron 时间事件自动跟进 rehash 的过程，就算之后马上没有流量访问了，也会推进 rehash，可以通过配置修改是否推进。 普通的其它字典则不会推进。 整数集合整数集合本质上是一块连续内存空间，它的结构定义如下： typedef struct intset &#123; //编码方式 uint32_t encoding; //集合包含的元素数量 uint32_t length; //保存元素的数组 int8_t contents[]; &#125; intset; 可以看到，保存元素的容器是一个 contents 数组，虽然 contents 被声明为 int8_t 类型的数组，但是实际上 contents 数组并不保存任何 int8_t 类型的元素，contents 数组的真正类型取决于 intset 结构体里的 encoding 属性的值。比如： 如果 encoding 属性值为 INTSET_ENC_INT16，那么 contents 就是一个 int16_t 类型的数组，数组中每一个元素的类型都是 int16_t； 如果 encoding 属性值为 INTSET_ENC_INT32，那么 contents 就是一个 int32_t 类型的数组，数组中每一个元素的类型都是 int32_t； 如果 encoding 属性值为 INTSET_ENC_INT64，那么 contents 就是一个 int64_t 类型的数组，数组中每一个元素的类型都是 int64_t； 不同类型的 contents 数组，意味着数组的大小也会不同。 升级操作","categories":[{"name":"Redis","slug":"Redis","permalink":"https://messenger1th.github.io/categories/Redis/"}],"tags":[]},{"title":"推荐文章","slug":"Others/推荐文章","date":"2024-07-24T14:47:34.204Z","updated":"2024-07-24T14:47:34.204Z","comments":true,"path":"2024/07/24/Others/推荐文章/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Others/%E6%8E%A8%E8%8D%90%E6%96%87%E7%AB%A0/","excerpt":"","text":"推荐连接池大小设置：数据库连接池到底应该设多大？这次直接从100ms优化到3ms！","categories":[{"name":"Others","slug":"Others","permalink":"https://messenger1th.github.io/categories/Others/"}],"tags":[]},{"title":"Idea","slug":"Others/Idea","date":"2024-07-24T14:47:34.204Z","updated":"2024-07-24T14:47:34.204Z","comments":true,"path":"2024/07/24/Others/Idea/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Others/Idea/","excerpt":"","text":"Idea1. epoll中使用哈希表替换红黑树对比来看，从时间来说 红黑树所有操作都是$O(log{n})$；哈希表是$O(1)$，但存在哈希碰撞问题，且扩容时需要复制全表，为$O(n)$。 从空间上看 红黑树是离散结构，不要求连续空间；哈希表是连续空间。 红黑树新增节点只需要分配节点内存；哈希表新增可能涉及扩容，扩容时需要占用更大空间。 树中元素有序，而哈系表元素无序。 为什么操作系统选用epoll而不是哈希表呢？作为一个操作系统，需要做到尽量普适和稳定，对于哈希表扩容需要的双倍空间和$O(n)$的时间，是难以接受的。而epoll主要用于高并发场景，稳定性就更重要了，此外，占用双倍内存，对于一个数据量庞大的系统来说，双倍内存的花销也很大，利用率也不够高。 什么操作系统可能用到哈希表呢？如果是哈希表作为存储结构的话，主要解决扩容的时间问题。由于是连续空间，空间问题似乎是不可避免的。 解决扩容的时间问题原理上是把扩容时间均摊。 后台线程扩容当负载因子（load factor）达到一定阈值时，开启一个后台线程，首先开辟一块更大内存用于扩容，分配好后，操作如下。 查询时候就查询两个表，查到一个则返回。 插入时检查两个表是否都是没有，都没有则成功插入。 删除时需要尝试删除两个表的元素。 由于是后台线程，需要和用户线程做数据竞争，需要用到锁等同步机制。 不难发现，扩容的时间均摊出来了，但由于后台线程和用户线程竞争，锁占用花销很高。 渐进式哈希顾名思义，将数据迁移分成多次迁移。不同与后台线程扩容，渐进式哈希不需要锁，扩容时间均摊到了用户的每次请求上。 渐进式 rehash 步骤如下： 给「哈希表 2」 分配空间； 在 rehash 进行期间，每次哈希表元素进行新增、删除、查找或者更新操作时，Redis 除了会执行对应的操作之外，还会顺序将「哈希表 1 」中索引位置上的所有 key-value 迁移到「哈希表 2」 上； 随着处理客户端发起的哈希表操作请求数量越多，最终在某个时间点会把「哈希表 1 」的所有 key-value 迁移到「哈希表 2」，从而完成 rehash 操作。 这样就巧妙地把一次性大量数据迁移工作的开销，分摊到了多次处理请求的过程中，避免了一次性 rehash 的耗时操作。 具体操作逻辑如下 查询时候就查询两个表，查到一个则返回。 插入时检查两个表是否都是没有，都没有则成功插入。 删除时需要尝试删除两个表的元素。 当负载因子超过阈值时，就开启rehash。 当然，如果一些数据迟迟不被用户请求，可能导致一直占用这部分空间无法释放。解决这一问题，可以在负载因子低到一定值的时候，可以让用户线程进行迁移或者请求后台线程迁移（当然需要做数据同步，比如加锁）。 那么什么情况可能用到哈希表呢？解决了时间问题，如果能够接受内存的利用率低，数据无序的情况的话，就可以采用哈希表。总得来说，采用哈希表是一种激进的优化策略，只能适用极小部分场景。 2. MySQL中使用跳表替换B+树由于MySQL是基于磁盘的，而磁盘的开销是主导的，所以重点落在减少磁盘IO上。 B+树的特性就是一个节点有多个子节点，叶子节点存储数据。 在Innodb中，一个节点就是一个页面，如果是叶子节点就存放数据，如果是非叶子节点就存放索引数据。 不难发现，B+树查找数据实际上就跟层高有关，有多少层，就需要经过多少个页面。 Innodb每次读取都是以页面为单位。读取时将页面加载到内存中进行操作，时机合适再写页面回磁盘。 我们以阶数M表示B+数一个节点最多有M个子节点。 假设M为5，我们发现，查找下一个页面时，都会找到5个子节点中的一个，进入这个子节点进行下一层的查找，即排除了这快数据里头的$\\frac{4}{5}$，而和这5个子节点比较的过程是在内存进行的，开销远不及磁盘IO。这样，就实现了一次磁盘IO，排除了大部分数据的效果。如果是红黑树，是一次磁盘IO，仅仅排除$\\frac{1}{2}$。 那跳表怎么做到一个页面，排除更大比例数据的效果呢？ 答案是，修改层高函数，减小升层概率。 假如升层概率是$\\frac{1}{2}$，则上一层的数据是下一层的一半，每次磁盘IO能够排除一半的数据。 假如升层概率是$\\frac{1}{4}$，则上一层的数据是下一层的$\\frac{1}{4}$，每次磁盘IO就能够排除$\\frac{3}{4}$的数据。 假如升层概率是$\\frac{1}{m}$，则上一层的数据是下一层的$\\frac{1}{m}$，每次磁盘IO就能够排除$\\frac{m-1}{m}$的数据。 不难发现，升层概率就类似于B+树的阶数。能够起到同样奇妙的效果。 除了减小升层概率之外，可以类比MySQL的页面那样，一个页面存放多条记录，记录由slot管理，页面内不同slot间使用二分查找加速。 此外，由于跳表本身结构简单，没有B+树复杂的旋转操作。 3. Redis为什么使用跳表而不使用B+树或红黑树呢?redis支持多种数据结构，里面有个有序集合，也叫ZSET。内部实现就是跳表。那为什么要用跳表而不用B+树等结构呢? Redis是基于内存的，无需考虑磁盘IO，所以层高就不再是劣势。同时，由于加层概率是1&#x2F;4，所以判断一次可以排除1&#x2F;4的数据，而B+树如果阶数大的话，一次能够排除的数据量少，效率就更低。 从内存占用上来比较，比平衡树更灵活一些。平衡树每个节点包含 2 个指针（分别指向左右子树），而跳表每个节点包含的指针数目平均为 1&#x2F;(1-p)，具体取决于参数 p 的大小。如果像 Redis里的实现一样，取 p&#x3D;1&#x2F;4，那么平均每个节点包含 1.33 个指针，比平衡树更有优势。 并且前面也提到B+树是有一系列合并拆分操作的，换成红黑树或者其他AVL树的话也是各种旋转，目的也是为了保持树的平衡。 在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在跳表上进行范围查找就非常简单，只需要在找到小值之后，对第 1 层链表进行若干步的遍历就可以实现。 而跳表插入数据时，只需要随机一下，就知道自己要不要往上加索引，根本不用考虑前后结点的感受，也就少了旋转平衡的开销。 总结下来： 层高不再是劣势，查找比较次数更少。 内存占用更少 无需旋转平衡的开支。 范围查找操作更简单。 编码实现、调试简单。 所以选择的是跳表。 4. 优化MySQL特殊情况下的加锁粒度","categories":[{"name":"Others","slug":"Others","permalink":"https://messenger1th.github.io/categories/Others/"}],"tags":[]},{"title":"Cache","slug":"Redis/Cache","date":"2024-07-24T14:47:34.204Z","updated":"2024-07-24T14:47:34.204Z","comments":true,"path":"2024/07/24/Redis/Cache/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Redis/Cache/","excerpt":"","text":"缓存缓存雪崩由于缓存一般是会设置过期时间，所以，缓存大量同时失效就会出现问题。 即，缓存血崩是指缓存大量失效或者Redis故障，导致大量请求到了数据库上。 缓存雪崩原因 缓存大量同时失效 Redis宕机 针对不同原因，有不同的解决方式 缓存大量同时失效 分散设置过期时间，尽量均匀在时间线上。 加互斥锁，保证只有一个请求来构建缓存，记得最好设置过期时间。 双key策略：主key设置过期时间，备用key永久，过期时，返回备用key的值。 后台更新缓存 定时更新 业务通过消息队列通知失效。 Redis宕机由于请求量过大导致的宕机，可以通过 请求熔断或请求限制机制 构建Redis缓存高可用集群 缓存击穿当缓存的某些热点数据过期时，大量请求打到了数据库上，导致的数据库压力过大。 互斥锁，保证一个只有请求构建缓存。 不给热点数据设置过期时间，由后台异步更新缓存，或者在热点数据准备要过期前，提前通知后台线程更新缓存以及重新设置过期时间。 缓存穿透缓存穿透的发生一般有这两种情况： 业务误操作，缓存中的数据和数据库中的数据都被误删除了，所以导致缓存和数据库中都没有数据； 黑客恶意攻击，故意大量访问某些读取不存在数据的业务； 针对上述原因，有对应处理。 针对非法请求，校验请求参数来限制。 针对大量不存在的key， 使用布隆过滤器快速判断数据是否存在，避免通过查询数据库来判断数据是否存在； 当查询到缓存和db都不存在时，给缓存建立一个空或者错误值，防止db大量访问。 一致性两次更新一致性方面 无论是先更新数据库还是先更新缓存，都有可能导致数据不一致。因为无法保证两个请求分别在缓存和数据库处的更新顺序一致。 有效方面 由于是直接更新，而不是删除了再更新，缓存会一直存在，缓存可以一直命中，只不过可能有些过时。 优化 如果是一致性要求高，则可以通过一定的控制手段来解决这个问题。 在更新缓存前先加一个分布式锁，保证更新缓存和更新数据库的顺序。 更新缓存后，给缓存添加过期时间，减少数据不一致的时间。 先更新还是先删除？先删除缓存，再更新数据库也会发生不一致的情况，如下例。且这种情况发生概率不低。 解决方案针对「先删除缓存，再更新数据库」方案在「读 + 写」并发请求而造成缓存不一致的解决办法是「延迟双删」。 延迟双删实现的伪代码如下： #删除缓存 redis.delKey(X) #更新数据库 db.update(X) #睡眠 Thread.sleep(N) #再删除缓存 redis.delKey(X) 加了个睡眠时间，主要是为了确保请求 A 在睡眠的时候，请求 B 能够在这这一段时间完成「从数据库读取数据，再把缺失的缓存写入缓存」的操作，然后请求 A 睡眠完，再删除缓存。 所以，请求 A 的睡眠时间就需要大于请求 B 「从数据库读取数据 + 写入缓存」的时间。 但是具体睡眠多久其实是个玄学，很难评估出来，所以这个方案也只是尽可能保证一致性而已，极端情况下，依然也会出现缓存不一致的现象。 先更新数据库，再删除缓存缓存存在时，读直接返回结果。写操作，先更新数据库，再删除缓存。 缓存不存在时，读会请求数据库。 只有在极端情况下，才会发生不一致的情况，如下例。 不难发现，这个例子的情况是比较难发生的，需要满足两个条件。 缓存不存在，此时读写并发。 读请求回写缓存，延时很长，直到写请求删除完缓存之后。 一般来说，缓存不存在，同时读写发生了并发，这个情况还是有一定的发生条件的。 此外，更新数据库的时间一般比回写缓存的时间长很多，所以这个条件很难发生。 所以，「先更新数据库 + 再删除缓存」的方案，是可以保证数据一致性的。 删除失败但也存在一定问题，特殊情况下，在删除缓存的时候失败了，会导致缓存中的数据是旧值。 删除失败原因可能是： Redis网络断开 Redis性能抖动导致删除命令超时。 针对缓存失败的情况，可以通过 设置过期时间，最多维持一小段不一致的时间。 将操作加入消息队列，由消费者来操作数据，如果应用删除缓存失败，可以从消息队列中重新读取数据，然后再次删除缓存，这个就是重试机制。 订阅 MySQL binlog，再操作缓存。比如，Cancel中间件，伪装成一个MySQL节点，向 MySQL 主节点发送 dump 请求，MySQL 收到请求后，就会开始推送 Binlog 给 Canal，Canal 解析 Binlog 字节流之后，转换为便于读取的结构化数据，供下游程序订阅使用。","categories":[{"name":"Redis","slug":"Redis","permalink":"https://messenger1th.github.io/categories/Redis/"}],"tags":[]},{"title":"os-overview","slug":"Operating System/os-overview","date":"2024-07-24T14:47:34.190Z","updated":"2024-07-24T14:47:34.190Z","comments":true,"path":"2024/07/24/Operating System/os-overview/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Operating%20System/os-overview/","excerpt":"","text":"Operating System硬件结构CPU缓存一致性由于内存和CPU读写速度的差异，为了加速内存中数据的读写，CPU引入了缓存体系。 缓存的速度比内存快很多很多，将需要读写的数据读取到缓存中，下一次就无须再去内存中寻找。 但缓存也是内存数据的一份副本，也就存在着数据不一致的情况，需要保证数据同步。 写直达（Write Through）：每次需要写缓存中的数据时就修改内存的数据，使其同步。对于读来说，不仅没有加速，反而还多了写缓存的过程。显然效率不高。 写回（write back）：为了防止频繁将缓存的数据写回内存，就引入了写回的的方法。 写数据，且数据已经存储在cache block中时，则无须直接修改内存，而是仅修改cache block中的数据，并标记该cache block为脏。 但由于现代CPU基本上都是多核CPU，就又涉及到多缓存的一致性问题。要保证多缓存的一致性，就要做到两点要求。 写传播（Write Propagation）：一个核心写数据时，需要同步到其他核的缓存中。 事务串行化（Transaction Serialization）：所有核心的数据变化是一致的，即顺序一致性。 要实现写传播，常用总线嗅探（Bus Snooping）实现。 要实现事务串行化，要做到以下两点，常用MESI协议实现。 CPU 核心对于 Cache 中数据的操作，需要同步给其他 CPU 核心； 要引入「锁」的概念，如果两个 CPU 核心里有相同数据的 Cache，那么对于这个 Cache 数据的更新，只有拿到了「锁」，才能进行对应的数据更新。 MESI协议MESI协议定义了一个CPU核心的四种状态，和每个状态对于本核心读写、其他核心读写的四种操作的行为。 Modified，已修改 Exclusive，独占 Shared，共享 Invalidated，已失效。 其中，已修改和独占都是仅当前缓存存有该数据。 整个过程可以用有限状态机（finite-state machine）表示 每个状态对于不同的行为产生的变化如下表。 编译过程 编译预处理 编译 汇编 链接 为什么要有虚拟内存？绝对物理地址：单片机从单片机说起，单片机的程序是直接编译，烧进单片机的，一旦需要更改程序，就得重新编译，烧录。 编译后的程序，直接写在单片机的内存ROM中，必要的话，还可以手动更改ROM内容，这些都是直接操作绝对物理地址。 虚拟内存而现代操作系统会将物理地址和程序操纵的地址解耦开，让MMU（memory manage unit）去管理。程序请求操作内存，则MMU查找对应的物理地址。 那么问题来了，操作系统是如何处理虚拟内存和物理内存的关系呢？ 内存分段程序是由若干个逻辑分段组成的，如可由代码分段、数据分段、栈段、堆段组成。不同的段是有不同的属性的，所以就用分段（*Segmentation*）的形式把这些段分离出来。分段机制下的虚拟地址由两部分组成，段选择因子和段内偏移量。 可以看出这样分配是一大块分配的，很不利于动态分配内存。这样分配内存存在以下问题 段间内存碎片：段与段之间的内存由于不够分配给一个段而无法使用。 内存交换效率低：为了解决内存碎片问题，就有了将段内容复制到硬盘，再从硬盘读入到新内存中的过程。 内存分页分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小。这样一个连续并且尺寸固定的内存空间，我们叫页（Page）。在 Linux 下，每一页的大小为 4KB。 程序请求内存时，以页为单位。这样页间的碎片就不会超过一个页大小。 但由于页也需要页表管理，占用不少额外空间用于管理页表。就衍生出多级页表。 对于一级页表来说，如果没有用到该项，而无需为其分配二级页表，虽然在页表全部使用的情况下多占用了一级页表的空间，但多数情况下可以节省内存。 此外，由于采用了多级页表这种寻址时间来换空间的做法，势必会导致查表耗时更长。于是衍生出缓存机制。 在CPU芯片中加入TLB（Translation Lookaside Buffer），根据程序的空间局部性原理，缓存的命中率通常不低。 段页式管理顾名思义就是分段和分页结合使用 总结总的来说，虚拟内存有如下优势 对于程序来说，只需关心自己的那部分内存，无需关系物理内存，内存管理交给操作系统。进程之间的内存也不会互相影响。算是程序和物理地址解耦的一种方式。 此外，由于页表的存在，虚拟内存和物理内存之间存在一层代理。对于那些非法的访问、特殊权限等可以做一些控制。 虚拟内存还可以节省空间。并不是所有程序都在使用其所有空间，对于那些暂时不用的部分，可以暂时换出到硬盘。 栈和堆的区别栈和堆都是分配内存的方式，其中 栈主要用于一些局部变量，函数传参等程序一般需求，因此栈由编译器管理更方便。 堆主要用于程序特殊需要，因此需要手动管理（当然有垃圾回收的语言不用）。 从实现原理上来说 栈一般是静态分配的（alloca函数动态分配），分配时大小确定，向下、低地址方向增长，需要多少内存直接移动栈指针即可，也就没有内存碎片的问题。 堆是动态管理的，由链表实现，也就可能产生内存碎片问题，向上、低地址增长。 从效率上来说， 栈是一般程序都需要的，因此会有优化，如专门的寄存器和指令 堆是C&#x2F;C++语言调用相关函数再经操作系统分配，机制复杂，效率不及栈。 从分配大小来看， 栈受限于操作系统指定的参数 堆受限于操作系统的虚拟内存 线程和进程的区别线程是CPU调度的最小单位，而进程资源分配的最小单位，不同进程的资源是独立的。 进程拥有资源，由PCB控制。所以，线程基于进程。一个进程可以有多个线程，线程共享进程的大部分资源，独有自己的寄存器和栈等资源。 从调度角度来说，切换进程需要替换进程的绝大部分资源，消耗较多。而切换线程，仅仅需要切换独有的那部分寄存器和栈等资源。 在Linux系统下，线程实际上是一种进程，用的相同结构task_struct表示线程和进程，只不过多个线程共享地址空间、文件系统、打开的文件、信号处理函数，但独有寄存器和栈来保证执行的相对独立。实际上，进程的创建是通过一个系统调用clone来实现的，而线程底层也是通过clone来实现。 clone(CLONE_VM | CLONE_FS | CLONE_FILES | CLONE_SIGHAND, 0); 只不过指明了需要与其他线程共享的四个参数。 进程调度常见算法 先来先服务（First Come First Severd, FCFS）算法 最短作业优先调度算法 高响应比优先调度算法 时间片轮转调度算法 最高优先级调度算法 多级反馈队列调度算法 Linux下的进程调度调度类Linux将进程调度抽象成模块，称为调度类（Sched Class）。如何选择调度类，有一定的顺序。 顺序遍历实际上意味着调度类之间存在优先级关系，Linux 总共实现了5种调度类，按照优先级有高到底排序依次为： stop_sched_class Stop 是特殊的调度类，内核使用该调度类来停止 CPU. 该调度类用来强行停止CPU 上的其他任务，由于该调度类的优先级最高，因此一旦生效就将抢占任何当前正在运行的任务，并且在运行过程中自己不会被抢占。 该调度类只有在SMP架构的系统中存在，内核使用该调度类来完成负载均衡与CPU热插拔等工作。 dl_sched_class 有些任务必须在指定时间窗口内完成。例如视频的编码与解码，CPU 必须以特定频率完成对应的数据处理； 这类任务是优先级最高的用户任务，CPU 应该首先满足。 Deadline 调度类用来调度这类任务，dl 便是单词 Deadline 的缩写，因此该调度类的优先级仅仅低于 Stop 调度类。 rt_sched_class 在本节开头我们提到，实时任务（Real-time Task）对响应时间要求更高，例如编辑器软件，它可能由于等待用户输入长期处于睡眠之中，但一旦用户有输入动作，我们就期望编辑器能够立马响应，而不是等系统完成其它任务之后才开始反应，这一点对用户体验十分重要。 RT 调度类用来调度这类任务，该调度类的优先级低于 DL. fair_sched_class Fair 调度类用来调度绝大多数用户任务，CFS 实现的就是这种调度类，其核心逻辑是根据任务的优先级公平地分配 CPU 时间。我们会在后续章节中详细讨论 CFS 的实现细节。 idle_sched_class 与 Stop 类似，Idle 调度类也是仅供内核使用的特殊调度类，其优先级最低，只有在没有任何用户任务时才会用到。内核会为每个 CPU 绑定一个内核线程（kthread）来完成该任务，该线程会在队列无事可做的情况下启动该任务，并将 CPU 的功耗降到最低。 每一个调度类都实现了pick_next_task，用于选择下一个调度的进程。 对于每个调度类，都有对应的调度策略。 调度策略 Stop 调度类 Stop 调度类中只有一个任务可供执行，不需要定义任何调度策略。 DL （Deadline）调度类 DL 只实现了一种调度策略：SCHED_DEADLINE, 用来调度优先级最高的用户任务。 RT （Real-Time） RT 提供了两种调度策略：SCHED_FIFO 与 SCHED_RR,对于使用 SCHED_FIFO 的任务，其会一直运行到主动放弃CPU; 而对于 SCHED_RR 的任务，如果多个任务的优先级相同，则大家会按照一定的时间配额来交替运行，即使一个任务一直处于可运行状态，在使用完自己的时间切片之后也会被抢占，然后被放入队列的尾巴等待下次机会。 Fair CFS 实现了三种调度策略： SCHED_NORMAL: 被用于绝大多数用户进程 SCHED_BATCH: 适用于没有用户交互行为的后台进程，用户对该类进程的响应时间要求不高，但对吞吐量要求较高，因此调度器会在完成所有 SCHED_NORMAL 的任务之后让该类任务不受打扰地跑上一段时间，这样能够最大限度地利用缓存。 SCHED_IDLE: 这类调度策略被用于系统中优先级最低的任务，只有在没有任何其他任务可运行时，调度器才会将运行该类任务。 Idle 同 Stop 一样，Idle 调度类也没有实现调度策略，注意不要将这类调度类与 CFS 中的 SCHED_IDLE 混淆。 每个进程在创建时都会指定一个调度策略，从而自动归结到某个调度类下。 我们可以通过 /proc/&lt;pid&gt;/sched 中的内容来查看进程的调度策略。 #define SCHED_NORMAL 0 #define SCHED_FIFO 1 #define SCHED_RR 2 #define SCHED_BATCH 3 /* SCHED_ISO: reserved but not implemented yet */ #define SCHED_IDLE 5 #define SCHED_DEADLINE 6 从上述描述不难看出，只有RT和CFS进程会参与调度的逻辑，Linux也提供了系统调用来修改进程优先级。 nice(); //修改静态优先级，作用于CFS sched_setscheduler(); //修改动态优先级和调度策略，用于实时进程。 运行队列运行队列（run queue）rq 是系统可运行任务的容器，调度器的很多工作都是围绕着 rq 来进行的，调度类 struct sched_class 所申明的函数中，绝大多数函数都与 rq 相关。在系统中，每个 CPU 都有一个自己的 rq, 这样可以避免多个 CPU 访问同一个 rq 时产生的并发问题，提升调度器效率。 每个rq都包含上述5个调度类，按照调度类优先级选取进程进行调度。 Linux RT调度Linux实时进程的调度依赖于实时优先级。Linux提供两种实时进程的调度策略，分别是SCHED_FIFO和SCHED_RR。 SCHED_FIFO 一直执行，直到它阻塞或者显式释放，不依赖时间片，一直执行。 只能被更高优先级的实时进程抢占。 多个同级的进程会轮流运行。 SCHED_RR 类似SCHED_FIFO，但分配时间片。 Linux CFS调度Linux CFS的设计理念是，每个进程都是完全公平的，他们的虚拟运行时间应该尽可能的相等，虚拟时间根据nice值的比例来分配。CFS分配运行时间不是按照时间片来分配的，而是每个进程运行一段时间，循环轮转，选择运行最少（虚拟运行时间最少）的进程作为下一个运行进程。CFS将nice值作为比列的分配标准，越低的nice值能够获得更高的使用权重。 时间记账：Linux使用一个变量vruntime记录虚拟运行时长。vruntime的更改是由系统定时器周期性调用update_curr()实现。 进程选择：CFS采用红黑树数据结构，按照vruntime大小给进程排序。红黑树用一个变量记录最小vruntime的进程。 进程插入：插入动作发生在进程创建或是进程唤醒时。 进程删除：删除动作发生在进程阻塞或是进程终止时。 休眠和唤醒： 休眠：当进程等待一些事件，例如等待文件I&#x2F;O、硬件事件、获取锁、磁盘read时，进程会把自己标记成休眠，然后从红黑树移除，加入等待队列。 唤醒：进程设置为可执行状态，然后再从等待队列中加入红黑树。 上下文切换 进程的五种主要状态 创建状态 就绪状态 阻塞状态 运行状态 结束状态 进程上下文切换进程是分配资源的最小单位，因而不同进程拥有不同的 在用户空间中的：虚拟内存（堆栈、全局变量、数据块、代码块）。 在内核空间中的：内核堆栈、寄存器、PC、进程标识信息、进程现场信息、进程控制信息等。 切换时，需要把交换信息保存在进程的PCB中，恢复时取出。 线程上下文切换线程是CPU调度的最小单位，依托进程存在，同一个进程下的线程共享 虚拟内存、全局变量等资源 线程切换时，无需更改以上资源，而线程独有的 栈、寄存器、私有数据等 需要切换。 在Linux下，线程和进程的都是用task_struct表示，为什么进程需要更大的花销呢？没错，线程和进程的都是用task_struct表示，而该结构体大部分都是指针和一些小变量，没有数组等很大花销的变量，那么又是什么导致进程花销大呢？ 问题出在虚拟内存上。Linux下， 虚拟内存存在多级页表，切换是需要花一定时间的。 除此之外，由于进程切换需要切换整个虚拟内存，因此，CPU的TLB缓存也是需要全部更新的。 而线程之间是共享虚拟内存的，就不存在这些花销。 此外，由于进程和线程切换都存在内核态的切换，也是一笔不小的花销。也因此，衍生出协程这个概念。 协程是轻量级的线程，协程之间的切换全程在用户态进行，也就没有内核态切换的花销。 死锁的条件和预防四个必要条件 互斥条件（在多线程环境中，由于共享资源，可能发生race condition情况，通常采用加互斥锁来解决。因而有了互斥条件） 占有并请求。（占有一个共享资源并请求另一个资源） 不可剥夺。（在使用资源后才主动释放资源） 环路等待。 预防破坏四个必要条件之一即可。比如 最常见的，破坏环路等待：给资源编号，资源按顺序获取。 破坏占有并请求：请求不到需要的资源就释放已经占有的资源。 IO：阻塞\\非阻塞\\同步\\异步在前面我们知道了，I&#x2F;O 是分为两个过程的： 数据准备的过程 数据从内核空间拷贝到用户进程缓冲区的过程 阻塞 I&#x2F;O 会阻塞在「过程 1 」和「过程 2」，而非阻塞 I&#x2F;O 和基于非阻塞 I&#x2F;O 的多路复用只会阻塞在「过程 2」，所以这三个都可以认为是同步 I&#x2F;O。 异步 I&#x2F;O 则不同，「过程 1 」和「过程 2 」都不会阻塞。 网络系统DMA技术在没有DMA(Direct Memory Access)技术前，I&#x2F;O需要CPU参与，而由于没有数据处理，实际上就没有必要让CPU参与，因此DMA技术就诞生了。 无DMA流程图 含DMA 零拷贝在 Linux 系统中，传统的访问方式是通过 write() 和 read() 两个系统调用实现的，通过 read() 函数读取文件到到缓存区中，然后通过 write()方法把缓存中的数据输出到网络端口，伪代码如下： read(file_fd, tmp_buf, len); write(socket_fd, tmp_buf, len); 从网络中获取到的数据，需要从磁盘复制到内核，内核复制到内存两个过程，而发送数据需要将用户态数据复制到内核态，再从内核状态复制到网卡发送。 经历了4次拷贝，不仅存在无用拷贝的情况，还有内核态和用户态切换的开销。 就引出了零拷贝技术。零拷贝技术实现的方式通常有 2 种： mmap + write sendfile mmap + write在前面我们知道，read() 系统调用的过程中会把内核缓冲区的数据拷贝到用户的缓冲区里，于是为了减少这一步开销，我们可以用 mmap() 替换 read() 系统调用函数。 buf = mmap(file, len); write(sockfd, buf, len); mmap() 系统调用函数会直接把内核缓冲区里的数据「映射」到用户空间，这样，操作系统内核与用户空间就不需要再进行任何的数据拷贝操作。 我们可以得知，通过使用 mmap() 来代替 read()， 可以减少一次数据拷贝的过程。 但这还不是最理想的零拷贝，因为仍然需要通过 CPU 把内核缓冲区的数据拷贝到 socket 缓冲区里，而且仍然需要 4 次上下文切换，因为系统调用还是 2 次。 sendfile在 Linux 内核版本 2.1 中，提供了一个专门发送文件的系统调用函数 sendfile()，函数形式如下： #include &lt;sys/socket.h&gt; ssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count); 它的前两个参数分别是目的端和源端的文件描述符，后面两个参数是源端的偏移量和复制数据的长度，返回值是实际复制数据的长度。 首先，它可以替代前面的 read() 和 write() 这两个系统调用，这样就可以减少一次系统调用，也就减少了 2 次上下文切换的开销。 其次，该系统调用，可以直接把内核缓冲区里的数据拷贝到 socket 缓冲区里，不再拷贝到用户态，这样就只有 2 次上下文切换，和 3 次数据拷贝。如下图： 但是这还不是真正的零拷贝技术，如果网卡支持 SG-DMA（The Scatter-Gather Direct Memory Access）技术（和普通的 DMA 有所不同），我们可以进一步减少通过 CPU 把内核缓冲区里的数据拷贝到 socket 缓冲区的过程。 你可以在你的 Linux 系统通过下面这个命令，查看网卡是否支持 scatter-gather 特性： $ ethtool -k eth0 | grep scatter-gather scatter-gather: on 于是，从 Linux 内核 2.4 版本开始起，对于支持网卡支持 SG-DMA 技术的情况下， sendfile() 系统调用的过程发生了点变化，具体过程如下： 第一步，通过 DMA 将磁盘上的数据拷贝到内核缓冲区里； 第二步，缓冲区描述符和数据长度传到 socket 缓冲区，这样网卡的 SG-DMA 控制器就可以直接将内核缓存中的数据拷贝到网卡的缓冲区里，此过程不需要将数据从操作系统内核缓冲区拷贝到 socket 缓冲区中，这样就减少了一次数据拷贝； 所以，这个过程之中，只进行了 2 次数据拷贝，如下图： 这就是所谓的零拷贝（Zero-copy）技术，因为我们没有在内存层面去拷贝数据，也就是说全程没有通过 CPU 来搬运数据，所有的数据都是通过 DMA 来进行传输的。。 零拷贝技术的文件传输方式相比传统文件传输的方式，减少了 2 次上下文切换和数据拷贝次数，只需要 2 次上下文切换和数据拷贝次数，就可以完成文件的传输，而且 2 次的数据拷贝过程，都不需要通过 CPU，2 次都是由 DMA 来搬运。 所以，总体来看，零拷贝技术可以把文件传输的性能提高至少一倍以上。 使用零拷贝技术的项目 Kafka Nginx Tomcat Page Cache类似CPU cache，Page Cache算是磁盘和内存之间的缓存。ageCache 的优点主要是两个： 缓存最近被访问的数据； 预读功能； 但是，在传输大文件（GB 级别的文件）的时候，PageCache 会不起作用，那就白白浪费 DMA 多做的一次数据拷贝，造成性能的降低，即使使用了 PageCache 的零拷贝也会损失性能 绕开 PageCache 的 I&#x2F;O 叫直接 I&#x2F;O，使用 PageCache 的 I&#x2F;O 则叫缓存 I&#x2F;O。通常，对于磁盘，异步 I&#x2F;O 只支持直接 I&#x2F;O。 于是，在高并发的场景下，针对大文件的传输的方式，应该使用「异步 I&#x2F;O + 直接 I&#x2F;O」来替代零拷贝技术。 所以，传输文件的时候，我们要根据文件的大小来使用不同的方式： 传输大文件的时候，使用「异步 I&#x2F;O + 直接 I&#x2F;O」； 传输小文件的时候，则使用「零拷贝技术」； 在 nginx 中，我们可以用如下配置，来根据文件的大小来使用不同的方式： location /video/ &#123; sendfile on; aio on; directio 1024m; &#125; 当文件大小大于 directio 值后，使用「异步 I&#x2F;O + 直接 I&#x2F;O」，否则使用「零拷贝技术」。 I&#x2F;O多路复用高性能网络模式ReactorPreactor一致性哈希","categories":[{"name":"Operating System","slug":"Operating-System","permalink":"https://messenger1th.github.io/categories/Operating-System/"}],"tags":[]},{"title":"索引","slug":"MySQL/索引","date":"2024-07-24T14:47:34.171Z","updated":"2024-07-24T14:47:34.171Z","comments":true,"path":"2024/07/24/MySQL/索引/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/MySQL/%E7%B4%A2%E5%BC%95/","excerpt":"","text":"索引InnoDB读写基本单位是页, 数据页结构(大致7个部分): File Header: 表示页的一些通用信息, 占固定38字节 Page HeadD:\\blog\\docs\\.vuepress\\nav-backUp.jser: 表示数据页专有的一些信息, 占固定的56字节 lnfimum + Supremum ，两个虚拟的伪记 ，分 表示页中的最小记录和最大记录，占固定的 26 字节。 User Records 真正存储我们插入的记录,大小不固定. Free Space 页中尚未使用的部分, 大小不固定. Page Directory 页中某些记录的相对位置 ，也就是各个槽对应的记录在页面中的地址 偏移量, 大小不固定, 插入的记录越多，这个部分占用的空间就越多 File Trailer 用于检验页是否完整，占固定8字节. 每个记录的头信息中都有一个next_record属性, 从而可以使页中的所有记录串联成一个单向链表. 每个数据页的 File Header都有上一个页和下一个页的编号，所以所有的数据页会组 成一个双向链表. lnnoDB 会把页中的记录划分为若干个组，每个组的最后一个 录的地址偏移量作为一个 槽，存放在 Page Directory一个槽占用8字节.在一个页中根据主键查找记录是非常快的， 分为两步. 通过二分法确定该记录所在分组的槽, 并找到该槽所在分组中主键最小的那条记录 通过记录的next_record属性遍历该槽所在组的各个记录. 整个表的结构如下图 在表中的查询同理 在定位记录所在哪一个页时，也是通过二分法快速定位到包含该记录的页。由于B+树可能有多层, 因此这步可能不止一次查询. 定位到该页后，又会在该页内进行二分法快速定位记录所在的分组（槽号），最后在分组内进行遍历查找 聚簇索引和二级索引 聚簇索引的叶子节点存放的是实际数据，所有完整的用户记录都存放在聚簇索引的叶子节点； 二级索引的叶子节点存放的是主键值，而不是实际数据。 InnoDB 在创建聚簇索引时，会根据不同的场景选择不同的列作为索引： 如果有主键，默认会使用主键作为聚簇索引的索引键； 如果没有主键，就选择第一个不包含 NULL 值的唯一列作为聚簇索引的索引键； 在上面两个都没有的情况下，InnoDB 将自动生成一个隐式自增 id 列作为聚簇索引的索引键； 一张表只能有一个聚簇索引，那为了实现非主键字段的快速搜索，就引出了二级索引（非聚簇索引&#x2F;辅助索引），它也是利用了 B+ 树的数据结构，但是二级索引的叶子节点存放的是主键值，不是实际数据。 二级索引存放的’’数据’’只有主键值, 结构如下, 因此如果是通过二级索引查询, 在还需要除了主键值之外的数据的情况下, 获取到主键值后, 需要回到聚簇索引的B+树查找其他需要的数据, 这个过程叫做「回表」. 但如果通过二级索引查询, 查询的是主键值就, 就无需回表, 直接在二级索引的表中获取即可, 这个过程叫做「索引覆盖」 对索引中包含的字段先做判断，过滤掉不符合条件的记录，减少回表字数, 这个过程叫做「索引下推」 为什么 MySQL 采用 B+ 树作为索引？由于数据库需要很大容量, 又需要持久化保存. 肯定不能存放在内存, 只能放在磁盘. 因此, 为了读写效率, 除了数据结构外, 还需要从磁盘角度考虑. 减少磁盘I&#x2F;O 要能高效地查询某一个记录，也要能高效地执行范围查找 磁盘读写的最小单位是扇区，扇区的大小只有 512B 大小，操作系统一次会读写多个扇区，所以**操作系统的最小读写单位是块（Block）。Linux 中的块大小为 4KB**，也就是一次磁盘 I&#x2F;O 操作会直接读写 8 个扇区。 可考虑的数据结构有 哈希表 二分查找树 自平衡二叉树 B树 B+树 哈希表哈希表在单点查询时可以做到$O(1)$的时间复杂度, 但这是无序的表, 对于查找就需要遍历整个表, 时间复杂度为$O(n)$, 而数据库对于范围查找的查询情景还是很频繁的, 因此需要寻找别的解决方案. 二分查找树 二分查找树虽然是一个天然的二分结构，能很好的利用二分查找快速定位数据，但是它存在一种极端的情况，每当插入的元素都是树内最大的元素，就会导致二分查找树退化成一个链表，此时查询复杂度就会从 O(logn)降低为 O(n)。 自平衡二叉树为了解决二分查找树退化成链表的问题，就出现了自平衡二叉树，保证了查询操作的时间复杂度就会一直维持在 O(logn) 。但是它本质上还是一个二叉树，每个节点只能有 2 个子节点，随着元素的增多，树的高度会越来越高。 而树的高度决定于磁盘 I&#x2F;O 操作的次数，因为树是存储在磁盘中的，访问每个节点，都对应一次磁盘 I&#x2F;O 操作，也就是说树的高度就等于每次查询数据时磁盘 IO 操作的次数，所以树的高度越高，就会影响查询性能。 为了减少磁盘I&#x2F;O次数, 就出现了有多个子节点数的树, 即多叉树, 称为B树, B+树. B树而如果同样的节点数量在平衡二叉树的场景下，树的高度就会很高，意味着磁盘 I&#x2F;O 操作会更多。所以，B 树在数据查询中比平衡二叉树效率要高。 但是 B 树的每个节点都包含数据（索引+记录），而用户的记录数据的大小很有可能远远超过了索引数据，这就需要花费更多的磁盘 I&#x2F;O 操作次数来读到「有用的索引数据」。 而且，在我们查询位于底层的某个节点（比如 A 记录）过程中，「非 A 记录节点」里的记录数据会从磁盘加载到内存，但是这些记录数据是没用的，我们只是想读取这些节点的索引数据来做比较查询，而「非 A 记录节点」里的记录数据对我们是没用的，这样不仅增多磁盘 I&#x2F;O 操作次数，也占用内存资源。 另外，如果使用 B 树来做范围查询的话，需要使用中序遍历，这会涉及多个节点的磁盘 I&#x2F;O 问题，从而导致整体速度下降。 B+树 B+树仅在叶子节点存放数据页, 其他都是索引页. 1、单点查询B 树进行单个索引查询时，最快可以在 O(1) 的时间代价内就查到，而从平均时间代价来看，会比 B+ 树稍快一些。 但是 B 树的查询波动会比较大，因为每个节点即存索引又存记录，所以有时候访问到了非叶子节点就可以找到索引，而有时需要访问到叶子节点才能找到索引。 B+ 树的非叶子节点不存放实际的记录数据，仅存放索引，因此数据量相同的情况下，相比存储即存索引又存记录的 B 树，B+树的非叶子节点可以存放更多的索引，因此 B+ 树可以比 B 树更「矮胖」，查询底层节点的磁盘 I&#x2F;O次数会更少。 2、插入和删除效率B+ 树有大量的冗余节点，这样使得删除一个节点的时候，可以直接从叶子节点中删除，甚至可以不动非叶子节点，这样删除非常快, 一般没有复杂调整树结构的过程. B+ 树的插入也是一样，有冗余节点，插入可能存在节点的分裂（如果节点饱和），但是最多只涉及树的一条路径。而且 B+ 树会自动平衡，不需要像更多复杂的算法，类似红黑树的旋转操作等。 3、范围查询B 树和 B+ 树等值查询原理基本一致，先从根节点查找，然后对比目标数据的范围，最后递归的进入子节点查找。 因为 B+ 树所有叶子节点间还有一个链表进行连接，这种设计对范围查找非常有帮助，比如说我们想知道 12 月 1 日和 12 月 12 日之间的订单，这个时候可以先查找到 12 月 1 日所在的叶子节点，然后利用链表向右遍历，直到找到 12 月12 日的节点，这样就不需要从根节点查询了，进一步节省查询需要的时间。 而 B 树没有将所有叶子节点用链表串联起来的结构，因此只能通过树的遍历来完成范围查询，这会涉及多个节点的磁盘 I&#x2F;O 操作，范围查询效率不如 B+ 树。 因此，存在大量范围检索的场景，适合使用 B+树，比如数据库。而对于大量的单个索引查询的场景，可以考虑 B 树，比如 nosql 的MongoDB 索引失效 ‘%李’ 对索引使用左或者左右模糊匹配 对索引使用函数 对索引进行表达式计算 联合索引非最左匹配 WHERE 子句中的 OR 注: 使用左模糊不一定会走全表聚簇索引, 在仅询问二级索引和主键值的情况下, 也可能直接走全表二级索引, 因为二级索引的记录的东西少, 且不用回表, 成本更低. 同理, 如果数据库表中的字段都是索引的话，即使查询过程中，没有遵循最左匹配原则，也是走索引扫描的，而且 type 也是为 index. Relevant Question 都知道数据库索引采⽤B+树⽽不是B树，原因也有很多，原因是什么？ 主要原因：B+树只要遍历叶⼦节点就可以实现整棵树的遍历，⽽且在数据库中基于范围的查询是⾮常频繁的，⽽B 树只能中序遍历所有节点，需要读取很多页面, 也就需要很多磁盘I&#x2F;O, 效率就低. B+ Tree 查询效率更稳定: 每次都需要到叶子节点才能找到数据, 长度是相同的. 单点查询的情况下, 相同大小的B+树由于索引页含更多页面记录, 结构比B树更矮胖, 涉及更少的磁盘I&#x2F;O, 因此效率更高. 插入删除的效率更高, 一般不涉及复杂的树结构变化, 仅在叶子节点插入删除. 范围查询时, 无需中序遍历, 只需要找到第一个向后遍历即可.","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://messenger1th.github.io/categories/MySQL/"}],"tags":[]},{"title":"调优实例","slug":"MySQL/调优实例","date":"2024-07-24T14:47:34.171Z","updated":"2024-07-24T14:47:34.171Z","comments":true,"path":"2024/07/24/MySQL/调优实例/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/MySQL/%E8%B0%83%E4%BC%98%E5%AE%9E%E4%BE%8B/","excerpt":"","text":"调优实例针对具体的实例调优的话，通过由一下几个步骤 明确背景 明确瓶颈、问题。 对齐需求 针对问题分析 结合业务提出优化手段 offset无效回表 简单总结： sql层和engine分工明确 由sql层负责条件判断、聚合以及offset条件等 由engine层负责具体的数据读写 所以，engine并不理解offset的概念，由sql层记录，所以每次都是sql层调用engine获取完整数据，sql判断不是需要的offset，那就查找下一条。 对齐sql首先问面试官，目前表的结构大概是怎样，索引的建设，又是怎样的，假设通过沟通，我们得到如下简化过的表t_player： 字段名 类型 描述 id bigint(20) unsigned 主键id score int(11) unsigned 分数 name varchar(128) 姓名 只在score字段上建了二级索引，大小是从小到大。这里要找第k个，其实就是偏移k-1： select * from t_player order by score desc offset k - 1 limit 1 复杂度分析看起来有offset，可以走索引，实际上，由于不知道子节点元素个数，并不能走索引。 所以实际上是遍历。 offset慢问题一方面遍历，使得慢。实际上，会特别慢，主要原因是对于前k个不需要到的数据，都需要回表查找，导致了很多次的随机IO。 而这个问题本质就是sql层和engine层的分工问题。 sql层和engine分工明确 由sql层负责条件判断、聚合以及offset条件等 由engine层负责具体的数据读写 所以，engine并不理解offset的概念，由sql层记录，所以每次都是sql层调用engine获取完整数据，sql判断不是需要的offset，那就查找下一条。 也就是说，每次查询，engine都需要回表查询到数据，然后再返回sql层做判断。 优化方案1.业务上绕过 将limit、offset，改为next，也就是将第x页，改为下一页，这样就 可以通过树分支查找。 举个例子，百度的搜索界面，就是典型的分页面。 而现在移动互联网时代，用得更多的就是上一页、下一页这样的翻页逻辑，微博、抖音都是这样的逻辑。 -- 记录score为prev_score select score from t_player order by score desc limit 20 -- 记录score为prev_score select score from t_player where score &lt; prev_score order by score desc limit 20 使用这种模式，可以利用树索引直接找到目标，也绕过了无效回表问题，在Offset超过一万的情况下，性能通常都能提高两个量级以上。 当然，这种适合给分页做优化，如果回到我们题目本身来说，那查找第k大的数，就需要循环“下一页”下去，损耗反而更大。 2. sql拆分优化 select * from t_player id in ( select id from t_player order by score offset 10000 limit 1 -- 这里虽然也是遍历，但由于只查了id，省略了回表的过程。 ） 3.预判边界值 这其实也是根据业务场景的做法，能通过业务预判边界，这种方式并不是通用解决方案，但因为《高性能MySQL》中提到了，也一并列出来。 分层设计为什么MySQL不直接丢掉无用数据，还要傻乎乎地回表？ 也许你曾经听过一个词，叫索引下推，在MySQL5.6之后，MySQL通过索引下推提升了性能。 这个问题也类似，答案是Offset未曾下推！我们先review下查找流程： 1.存储引擎通过二级索引查找，获取主键值； 2.进行回表操作，将完整记录返回给上层； 3.上层判断是否需要该记录，需要则返回给客户端，不需要则跳过该记录； 4.存储引擎接着查找下一条； 5.重复第二步。 从流程其实我们能看出，存储引擎层是没有Offset信息的。 MySQL不做的原因，无非两点： 1.限制场景太多，给多个引擎做有点得不偿失； 2.更核心的，分层设计理念，这件事本身是Sql层的，本就不该存储引擎做。 但如果是自研的sql，就可以更考虑实用而非通用。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://messenger1th.github.io/categories/MySQL/"}],"tags":[]},{"title":"Cache Coherence","slug":"Operating System/Cache Coherence","date":"2024-07-24T14:47:34.171Z","updated":"2024-07-24T14:47:34.171Z","comments":true,"path":"2024/07/24/Operating System/Cache Coherence/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Operating%20System/Cache%20Coherence/","excerpt":"","text":"缓存一致性CPU缓存由于内存和CPU之间速度存在的巨大差异，在CPU和内存之间引入缓存，缓存速度介于内存于CPU之间，以减轻这种差异。 如果仅仅是从内存读到缓存，然后读写缓存，最后写会内存这3个简单步骤，缓存的作用就发挥不出来，甚至因为多拷贝、写回一次导致副作用。而由于程序的 时间局部性（Temporal Locality）：如果一个信息项正在被访问，那么在近期它很可能还会被再次访问。 空间局部性（Spatial Locality）：如果一个存储器的位置被引用，那么将来他附近的位置也会被引用。 这两个原理，就让本来需要多次读写内存，改为一次读写内存，多次读写缓存。而由于缓存的速度较内存快得多，所以能够提高效率。 CPU多核心缓存现代CPU一般都是多个核心的，每一个核心都拥有自己的缓存，通过总线与内存交互数据。两核实例如下 实际上，Cache也不只一级，通常是3级缓存，L1和L2是CPU核心专属，L3是CPU核心共享。 而由于存在多个缓存，数据总是要进行同步的，否则会导致一致性问题。比如A &#x3D; 0, 两个核心同时让A = A+1，导致，写回内存的时候，内存看到A就是1，而需求上，A应该是2。 为了解决这类问题，需要一定的机制来实现缓存一致性。就是本文的主题MESI协议和总线嗅探。 MESI缓存一致性协议MESI（Modified Exclusive Shared Or Invalid）(也称为伊利诺斯协议，是因为该协议由伊利诺斯州立大学提出的）是一种广泛使用的支持写回策略的缓存一致性协议。为了保证多个CPU缓存中共享数据的一致性，定义了缓存行(Cache Line)的四种状态，而CPU对缓存行的四种操作可能会产生不一致的状态，因此缓存控制器监听到本地操作和远程操作的时候，需要对地址一致的缓存行的状态进行一致性修改，从而保证数据在多个缓存之间保持一致性。 CPU缓存数据的基本单位是缓存行（Cache Line）。 MESI协议定义了四种状态如下 Modified，已修改 Exclusive，独占 Shared，共享 Invalidated，已失效。 其中，已修改和独占都是仅当前缓存存有该数据。 根据本地（Local）和内存（remote）读写，进行状态的变更，整个过程可以用有限状态机（finite-state machine）表示。 每个状态对于不同的行为产生的变化如下表。 MESI仅仅是描述了缓存行的状态变迁，没有提到如何防止两个缓存同时操作的互斥问题，比如两个核心同时写一个数据对应的缓存行，究竟谁先谁后、缓存如何知道其他缓存的操作等。所以，引出总线嗅探和总线仲裁机制。 总线嗅探 &amp; 总线仲裁总线嗅探（Bus snooping or bus sniffing）后的基本思想是，所有内存传输都发生在一条共享的总线上，而所有的处理器都能看到这条总线：缓存本身是独立的，但是内存是共享资源，所有的内存访问都要经过仲裁（arbitrate）：同一个指令周期中，只有一个缓存可以读写内存。 窥探协议的思想是，缓存不仅仅在做内存传输的时候才和总线打交道，而是不停地在窥探总线上发生的数据交换，跟踪其他缓存在做什么。所以当一个缓存代表它所属的处理器去读写内存时，其他处理器都会得到通知，它们以此来使自己的缓存保持同步。只要某个处理器一写内存，其他处理器马上就知道这块内存在它们自己的缓存中对应的段已经失效。 总线嗅探机制保证了缓存能够立即监听其他缓存的处理，从而改变本身的状态。 总线仲裁：高并发情况下可能出现两个CPU同时修改缓存a，并同时向总线发出将各自的缓存行更改为M状态的情况，此时总线会采用相应的裁决机制进行裁决，将其中一个置为M状态，另一个置为I状态，且I状态的缓存行修改无效。 说到这里，MESI协议、总线嗅探和总线仲裁机制保证了缓存一致性。但也引出一些效率方面的问题。 问题及优化MESI协议、总线嗅探和总线仲裁机制保证了缓存一致性，但完全地遵循协议会影响性能。 缓存的一致性消息传递是要时间的，这就使其切换时会产生延迟。当一个缓存切换状态，其他缓存收到消息，完成各自的切换，并且发出回应消息，这么一长串的时间中CPU都会等待所有缓存响应完成。可能出现的阻塞都会导致各种各样的性能问题和稳定性问题。 比如你需要修改本地缓存中的一条信息，必须等到其他拥有该数据的缓存的状态变为invalid。等待确认的过程会阻塞处理器，这会降低处理器的性能。因为这个等待远远比一个指令的执行时间长的多。 Store Buffer为了避免这种CPU运算能力的浪费，Store Buffer被引入使用。 为了提高效率，可以使用异步的方式去处理：先将值写入到一个 Buffer 中，再发送通讯的信号，等到信号被响应，再应用到 cache 中。这么做有两个风险 处理器会尝试从存储缓存（Store buffer）中读取值，但它还没有进行提交。这个的解决方案称为 Store Forwarding，它使得加载的时候，如果存储缓存中存在，则进行返回。 不保存什么时候会完成，这个并没有任何保证。 除了优化主动修改缓存呢，还有优化被动通告修改缓存，类似Store Buffer，引入了**失效队列(invalidate queue)**。 Invalidate Queue接到Invalidate请求后，回Invalidate Acknowlege消息但异步执行实际的invalidate操作。 对于所有的收到的Invalidate请求，Invalidate Acknowlege消息必须立刻发送。 Invalidate并不真正执行，而是被放在一个特殊的队列中，在方便的时候才会去执行。 处理器不会发送任何消息给所处理的缓存条目，直到它处理Invalidate。 布局引入Store Buffer和Invalid Queue后，可能会发生”重排序（reorderings）“现象。注意，这不意味着你的指令的位置被恶意（或者好意）地更改。它只是意味着其他的CPU会读到跟程序中写入的顺序不一样的结果。 引入Store Buffer和Invalid Queue后的布局如下 内存屏障引入Store Buffer和Invalid Queue，效率是更高了，但是结果的一致性无法保证了。 干脆处理器将这个任务丢给了写代码的人。这就是内存屏障（Memory Barriers）。 如果引入了store buffer、invalidate queue之后，又该如何工作呢？ 必须要有办法，将该store buffer中的更新，通知到其他CPU，这就是write barrier干的事情。它就是暂停CPU 0执行，并将CPU 0把store buffer中记录的一些更新应用到cache中，此时会触发cache一致性协议MESI通知CPU 1 cacheline invalidate； 必须要有办法，将CPU 1中invalidate queue记录下来的invalidate对应的cacheline及时清理掉，这就是read barrier干的事情。它就是暂停CPU 1执行，将其invalidate queue中的每个invalidate请求对应的cacheline全部标记为无效，下次读取时从内存或者CPU 0读取最新数据； 写屏障 Store Memory Barrier(a.k.a. ST, SMB, smp_wmb)是一条告诉处理器在执行这之后的指令之前，应用所有已经在存储缓存（store buffer）中的保存的指令。 读屏障Load Memory Barrier (a.k.a. LD, RMB, smp_rmb)是一条告诉处理器在执行任何的加载前，先应用所有已经在失效队列（Invalidate Queue）中的失效操作的指令。 总结一下 这里的读写屏障要依赖处理器提供的屏障指令 在屏障指令之上，内核可以按需选择，如Linux在x86平台选择用 lock; addl来实现读写屏障 smp_mb&#x2F;smp_rmb&#x2F;smp_wmb，x86其实也提供了mfence、lfence、sfence。至于Linux为什么这么选择，应该是跟x86实现有关系，一条指令lock;addl同时实现全屏障&#x2F;读屏障&#x2F;写屏障足矣。 其他编程语言内存模型，通常会定义一些Happens-Before关系，这里面就隐含了各种屏障的应用。基于屏障实现的各种同步原语如mutex、semaphore等就比较常见了。 重排序重排序的 3 种情况 编译器优化 内存的“重排序” CPU 重排序 volatilevolatile 不能解决多线程中的问题,，仅仅用于抑制编译器重排和优化。 按照Hans Boehm &amp; Nick Maclaren 的总结，volatile只在三种场合下是合适的。 和信号处理（signal handler）相关的场合； 和内存映射硬件（memory mapped hardware）相关的场合； 和非本地跳转（setjmp 和 longjmp）相关的场合。 volatile、Memory Barrier、std::atomic的区别如下 C++ volatile Memory Barrier atomic 抑制编译器重排 Yes Yes Yes 抑制编译器优化 Yes No Yes 抑制 CPU 乱序 No Yes Yes 保证访问原子性 No No Yes 参考 C++ 中的 volatile，atomic 及 memory barrier 吊打字节面试官，CPU缓存一致性协议MESI 缓存一致性（Cache Coherency）入门 volatile与内存屏障总结 12 张图看懂 CPU 缓存一致性与 MESI 协议，真的一致吗？ 谈谈 C&#x2F;C++ 中的 volatile Locks实现:背后不为人知的故事 TODO 理解内存模型：为什么定义内存模型、它们的区别与联系。 happens-before语义有什么用？跟MESI、Store Buffer、Invalidate Queue有什么联系？ std::atomic底层实现","categories":[{"name":"Operating System","slug":"Operating-System","permalink":"https://messenger1th.github.io/categories/Operating-System/"}],"tags":[]},{"title":"File System","slug":"Operating System/File System","date":"2024-07-24T14:47:34.171Z","updated":"2024-07-24T14:47:34.171Z","comments":true,"path":"2024/07/24/Operating System/File System/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Operating%20System/File%20System/","excerpt":"","text":"文件系统文件系统：FAT、HPFS Linux：EXT4 Windows：NTFS 文件存储连续存储即文件头保存起始地址和文件大小。 连续空间存放的方式虽然读写效率高，但是有「磁盘空间碎片」和「文件长度不易扩展」的缺陷。 磁盘空间碎片是由于是连续连续存放，当空间不足以放下新文件就会出现该现象。 不易扩展就得找到一个更大的新空间，复制过去，很耗时。 非连续空间存放方式非连续空间存放方式分为「链表方式」和「索引方式」。 链表方式 隐式链表：文件头记录头尾块，磁盘每个数据块中记录下一个数据块地址. 显式链表：取出每个磁盘块的指针，把它放在内存的一个表中，这个表称为文件分配表FAT，也就是FAT格式。 隐式链表 显式链表：内存中的FAT 由于查找记录的过程是在内存中进行的，因而不仅显著地提高了检索速度，而且大大减少了访问磁盘的次数。但也正是整个表都存放在内存中的关系，它的主要的缺点是不适用于大磁盘，需要消耗大量内存资源。。 索引方式磁盘中存放一个文件头，记录所有数据块地址。 索引的方式优点在于： 文件的创建、增大、缩小很方便； 不会有碎片的问题； 支持顺序读写和随机读写； 但如果数据块过多，一个索引数据块放不下，就要用到其他存储方式了，比如链式索引数据块，称为「链式索引块」。 还有另外一种组合方式是索引 + 索引的方式，这种组合称为「多级索引块」 总结 Unix实现Unix用到了多种方式来管理文件。 它是根据文件的大小，存放的方式会有所变化： 如果存放文件所需的数据块小于 10 块，则采用直接查找的方式； 如果存放文件所需的数据块超过 10 块，则采用一级间接索引方式； 如果前面两种方式都不够存放大文件，则采用二级间接索引方式； 如果二级间接索引也不够存放大文件，这采用三级间接索引方式； 那么，文件头（Inode）就需要包含 13 个指针： 10 个指向数据块的指针； 第 11 个指向索引块的指针； 第 12 个指向二级索引块的指针； 第 13 个指向三级索引块的指针； 所以，这种方式能很灵活地支持小文件和大文件的存放： 对于小文件使用直接查找的方式可减少索引数据块的开销； 对于大文件则以多级索引的方式来支持，所以大文件在访问数据块时需要大量查询； 这个方案就用在了 Linux Ext 2&#x2F;3 文件系统里，虽然解决大文件的存储，但是对于大文件的访问，需要大量的查询，效率比较低。 为了解决这个问题，Ext 4 做了一定的改变，具体怎么解决的，本文就不展开了。 空闲空间管理要快速找到空闲的空间，肯定不能遍历查找，那样太慢了，有如下常见方法。 空闲表法 空闲链表法 位图法 空闲表法空闲表法就是为所有空闲空间建立一张表，表内容包括空闲区的第一个块号和该空闲区的块个数，注意，这个方式是连续分配的。如下图： 当请求分配磁盘空间时，系统依次扫描空闲表里的内容，直到找到一个合适的空闲区域为止。当用户撤销一个文件时，系统回收文件空间。这时，也需顺序扫描空闲表，寻找一个空闲表条目并将释放空间的第一个物理块号及它占用的块数填到这个条目中。 这种方法仅当有少量的空闲区时才有较好的效果。因为，如果存储空间中有着大量的小的空闲区，则空闲表变得很大，这样查询效率会很低。另外，这种分配技术适用于建立连续文件。 空闲链表法我们也可以使用「链表」的方式来管理空闲空间，每一个空闲块里有一个指针指向下一个空闲块，这样也能很方便的找到空闲块并管理起来。如下图： 当创建文件需要一块或几块时，就从链头上依次取下一块或几块。反之，当回收空间时，把这些空闲块依次接到链头上。 这种技术只要在主存中保存一个指针，令它指向第一个空闲块。其特点是简单，但不能随机访问，工作效率低，因为每当在链上增加或移动空闲块时需要做很多 I&#x2F;O 操作，同时数据块的指针消耗了一定的存储空间。 空闲表法和空闲链表法都不适合用于大型文件系统，因为这会使空闲表或空闲链表太大。 位图法位图是利用二进制的一位来表示磁盘中一个盘块的使用情况，磁盘上所有的盘块都有一个二进制位与之对应。 当值为 0 时，表示对应的盘块空闲，值为 1 时，表示对应的盘块已分配。它形式如下： 1111110011111110001110110111111100111 ... 在 Linux 文件系统就采用了位图的方式来管理空闲空间，不仅用于数据空闲块的管理，还用于 inode 空闲块的管理，因为 inode 也是存储在磁盘的，自然也要有对其管理。 目录的存储在前面，我们知道了一个普通文件是如何存储的，但还有一个特殊的文件，经常用到的目录，它是如何保存的呢？ 基于 Linux 一切皆文件的设计思想，目录其实也是个文件，你甚至可以通过 vim 打开它，它也有 inode，inode 里面也是指向一些块。 和普通文件不同的是，普通文件的块里面保存的是文件数据，而目录文件的块里面保存的是目录里面一项一项的文件信息。 在目录文件的块中，最简单的保存格式就是列表，就是一项一项地将目录下的文件信息（如文件名、文件 inode、文件类型等）列在表里。 列表中每一项就代表该目录下的文件的文件名和对应的 inode，通过这个 inode，就可以找到真正的文件。 通常，第一项是「.」，表示当前目录，第二项是「..」，表示上一级目录，接下来就是一项一项的文件名和 inode。 如果一个目录有超级多的文件，我们要想在这个目录下找文件，按照列表一项一项的找，效率就不高了。 于是，保存目录的格式改成哈希表，对文件名进行哈希计算，把哈希值保存起来，如果我们要查找一个目录下面的文件名，可以通过名称取哈希。如果哈希能够匹配上，就说明这个文件的信息在相应的块里面。 Linux 系统的 ext 文件系统就是采用了哈希表，来保存目录的内容，这种方法的优点是查找非常迅速，插入和删除也较简单，不过需要一些预备措施来避免哈希冲突。 目录查询是通过在磁盘上反复搜索完成，需要不断地进行 I&#x2F;O 操作，开销较大。所以，为了减少 I&#x2F;O 操作，把当前使用的文件目录缓存在内存，以后要使用该文件时只要在内存中操作，从而降低了磁盘操作次数，提高了文件系统的访问速度。 软链接和硬链接有时候我们希望给某个文件取个别名，那么在 Linux 中可以通过硬链接（Hard Link） 和软链接（Symbolic Link） 的方式来实现，它们都是比较特殊的文件，但是实现方式也是不相同的。 硬链接是多个目录项中的「索引节点」指向一个文件，也就是指向同一个 inode，但是 inode 是不可能跨越文件系统的，每个文件系统都有各自的 inode 数据结构和列表，所以硬链接是不可用于跨文件系统的。由于多个目录项都是指向一个 inode，那么只有删除文件的所有硬链接以及源文件时，系统才会彻底删除该文件。 软链接相当于重新创建一个文件，这个文件有独立的 inode，但是这个文件的内容是另外一个文件的路径，所以访问软链接的时候，实际上相当于访问到了另外一个文件，所以软链接是可以跨文件系统的，甚至目标文件被删除了，链接文件还是在的，只不过指向的文件找不到了而已。 文件 I&#x2F;O文件的读写方式各有千秋，对于文件的 I&#x2F;O 分类也非常多，常见的有 缓冲与非缓冲 I&#x2F;O 直接与非直接 I&#x2F;O 阻塞与非阻塞 I&#x2F;O VS 同步与异步 I&#x2F;O 接下来，分别对这些分类讨论讨论。 缓冲与非缓冲 I&#x2F;O文件操作的标准库是可以实现数据的缓存，那么根据「是否利用标准库缓冲」，可以把文件 I&#x2F;O 分为缓冲 I&#x2F;O 和非缓冲 I&#x2F;O： 缓冲 I&#x2F;O，利用的是标准库的缓存实现文件的加速访问，而标准库再通过系统调用访问文件。 非缓冲 I&#x2F;O，直接通过系统调用访问文件，不经过标准库缓存。 这里所说的「缓冲」特指标准库内部实现的缓冲。 比方说，很多程序遇到换行时才真正输出，而换行前的内容，其实就是被标准库暂时缓存了起来，这样做的目的是，减少系统调用的次数，毕竟系统调用是有 CPU 上下文切换的开销的。 直接与非直接 I&#x2F;O我们都知道磁盘 I&#x2F;O 是非常慢的，所以 Linux 内核为了减少磁盘 I&#x2F;O 次数，在系统调用后，会把用户数据拷贝到内核中缓存起来，这个内核缓存空间也就是「页缓存」，只有当缓存满足某些条件的时候，才发起磁盘 I&#x2F;O 的请求。 那么，根据是「否利用操作系统的缓存」，可以把文件 I&#x2F;O 分为直接 I&#x2F;O 与非直接 I&#x2F;O： 直接 I&#x2F;O，不会发生内核缓存和用户程序之间数据复制，而是直接经过文件系统访问磁盘。 非直接 I&#x2F;O，读操作时，数据从内核缓存中拷贝给用户程序，写操作时，数据从用户程序拷贝给内核缓存，再由内核决定什么时候写入数据到磁盘。 如果你在使用文件操作类的系统调用函数时，指定了 O_DIRECT 标志，则表示使用直接 I&#x2F;O。如果没有设置过，默认使用的是非直接 I&#x2F;O。 如果用了非直接 I&#x2F;O 进行写数据操作，内核什么情况下才会把缓存数据写入到磁盘？ 以下几种场景会触发内核缓存的数据写入磁盘： 在调用 write 的最后，当发现内核缓存的数据太多的时候，内核会把数据写到磁盘上； 用户主动调用 sync，内核缓存会刷到磁盘上； 当内存十分紧张，无法再分配页面时，也会把内核缓存的数据刷到磁盘上； 内核缓存的数据的缓存时间超过某个时间时，也会把数据刷到磁盘上； 阻塞与非阻塞 I&#x2F;O VS 同步与异步 I&#x2F;O为什么把阻塞 &#x2F; 非阻塞与同步与异步放一起说的呢？因为它们确实非常相似，也非常容易混淆，不过它们之间的关系还是有点微妙的。 先来看看阻塞 I&#x2F;O，当用户程序执行 read ，线程会被阻塞，一直等到内核数据准备好，并把数据从内核缓冲区拷贝到应用程序的缓冲区中，当拷贝过程完成，read 才会返回。 注意，阻塞等待的是「内核数据准备好」和「数据从内核态拷贝到用户态」这两个过程。过程如下图： 知道了阻塞 I&#x2F;O ，来看看非阻塞 I&#x2F;O，非阻塞的 read 请求在数据未准备好的情况下立即返回，可以继续往下执行，此时应用程序不断轮询内核，直到数据准备好，内核将数据拷贝到应用程序缓冲区，read 调用才可以获取到结果。过程如下图： 注意，这里最后一次 read 调用，获取数据的过程，是一个同步的过程，是需要等待的过程。这里的同步指的是内核态的数据拷贝到用户程序的缓存区这个过程。 举个例子，访问管道或 socket 时，如果设置了 O_NONBLOCK 标志，那么就表示使用的是非阻塞 I&#x2F;O 的方式访问，而不做任何设置的话，默认是阻塞 I&#x2F;O。 应用程序每次轮询内核的 I&#x2F;O 是否准备好，感觉有点傻乎乎，因为轮询的过程中，应用程序啥也做不了，只是在循环。 为了解决这种傻乎乎轮询方式，于是 I&#x2F;O 多路复用技术就出来了，如 select、poll，它是通过 I&#x2F;O 事件分发，当内核数据准备好时，再以事件通知应用程序进行操作。 这个做法大大改善了 CPU 的利用率，因为当调用了 I&#x2F;O 多路复用接口，如果没有事件发生，那么当前线程就会发生阻塞，这时 CPU 会切换其他线程执行任务，等内核发现有事件到来的时候，会唤醒阻塞在 I&#x2F;O 多路复用接口的线程，然后用户可以进行后续的事件处理。 整个流程要比阻塞 IO 要复杂，似乎也更浪费性能。但 I&#x2F;O 多路复用接口最大的优势在于，用户可以在一个线程内同时处理多个 socket 的 IO 请求（参见：I&#x2F;O 多路复用：select&#x2F;poll&#x2F;epoll (opens new window)）。用户可以注册多个 socket，然后不断地调用 I&#x2F;O 多路复用接口读取被激活的 socket，即可达到在同一个线程内同时处理多个 IO 请求的目的。而在同步阻塞模型中，必须通过多线程的方式才能达到这个目的。 下图是使用 select I&#x2F;O 多路复用过程。注意，read 获取数据的过程（数据从内核态拷贝到用户态的过程），也是一个同步的过程，需要等待： 实际上，无论是阻塞 I&#x2F;O、非阻塞 I&#x2F;O，还是基于非阻塞 I&#x2F;O 的多路复用都是同步调用。因为它们在 read 调用时，内核将数据从内核空间拷贝到应用程序空间，过程都是需要等待的，也就是说这个过程是同步的，如果内核实现的拷贝效率不高，read 调用就会在这个同步过程中等待比较长的时间。 而真正的异步 I&#x2F;O 是「内核数据准备好」和「数据从内核态拷贝到用户态」这两个过程都不用等待。 当我们发起 aio_read 之后，就立即返回，内核自动将数据从内核空间拷贝到应用程序空间，这个拷贝过程同样是异步的，内核自动完成的，和前面的同步操作不一样，应用程序并不需要主动发起拷贝动作。过程如下图： 下面这张图，总结了以上几种 I&#x2F;O 模型： 在前面我们知道了，I&#x2F;O 是分为两个过程的： 数据准备的过程 数据从内核空间拷贝到用户进程缓冲区的过程 阻塞 I&#x2F;O 会阻塞在「过程 1 」和「过程 2」，而非阻塞 I&#x2F;O 和基于非阻塞 I&#x2F;O 的多路复用只会阻塞在「过程 2」，所以这三个都可以认为是同步 I&#x2F;O。 异步 I&#x2F;O 则不同，「过程 1 」和「过程 2 」都不会阻塞。","categories":[{"name":"Operating System","slug":"Operating-System","permalink":"https://messenger1th.github.io/categories/Operating-System/"}],"tags":[]},{"title":"存储结构","slug":"MySQL/存储结构","date":"2024-07-24T14:47:34.170Z","updated":"2024-07-24T14:47:34.171Z","comments":true,"path":"2024/07/24/MySQL/存储结构/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/MySQL/%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84/","excerpt":"","text":"MySQL存储的结构 记录: Record 页: Page 区: extent 组: 段: Segement 表: Table 库 记录: Record记录与记录之间连成单向链表, 便于二分查找到页面最小记录向后遍历查询. 页: Page这是MySQL存储最基本的单位, 一般为16KB, 页与页之间连成双向链表, 便于双向查询. 区: Extent对于16KB的页来说 连续的64个页就是一个区, 也就是说一个区默认占用1MB空间大小. 在表中数据量很大时, 为某个索引分配空间的时候就以区为单位分配, 甚至是一次分配多个区, 来减少磁盘I&#x2F;O. 但由于数据量较小时, 这种策略会造成存储空间浪费, 因此提出了Fragment碎片区的概念, 直属于表空间 区的分类:区有4种状态 空闲区 FREE 有剩余页面的碎片区: FREE FRAG 没有剩余页面的碎片区 FREE FRAG 附属于某个段的区 FSEG 每个区都对应一个XDES Entry结构, 这个结构记录了对应的区的一些属性 区与区之间可以通过List Node中的来连成一个双向链表. 连成链表有什么特殊用处呢? 等谈到段的概念再来解释. 组每256个区被划分为一个组.组的前几页是用于管理组的, 由于页面的大小有限, XDES Entry结构大小为40字节, 所以才把256个区分为一组, 在每组的第一个页面存放256个XDES Entry 结构. 此外, 由于第一个组的第一个页面有些特殊, 它也是整个表空间的第一个页面, 因此也记录的表空间的一些属性, 为了区分命名, 将其命名为FSP_HDR, 含有File Space Header等, 其他部分与XDES差不多. 此外, 索引页和数据页分开在不同的区, 存放叶子节点的区的集合算是一个段, 存放非叶子节点的区的集合也算是一个段. 段: Segment段不是一个物理上的区域, 是一个逻辑上的概念,由一些完整的区和若干零散页面组成. 像每个区都有对应的XDES Entry来记录这个区的属性一样, InnoDB的设计者为每个段都定义了一个INODE Entry来记录这个段的属性, 方便管理段. 第一个分组中的第三个页面类型是INODE, 用于存储INODE Entry. Segment ID: 记录段的编号 NOT_FULL_N_USED: 在NOT_FULL链表中已经使用了多少个页面 3个List Base Node分别为段的FREE,NOT_FULL,FULL链表的头节点和尾节点 Magic Number: 用来标记这个INODE Entry是否已经被初始化. Framgent Array Entry: 对应一些零散的页面, 表示一些零散的页面页号. 如何快速定位各种状态的区呢? 前面提到各种状态的区会通过List Node连成链表, 通过三种List Base Node可以快速定位在段中各种不同状态的区的头节点, 从而快速获取需要的区来存储数据. 每一个索引都对应两个段 每个段都会维护如下个链表. Free 链表 NOT_FULL 链表 FULL链表 ​ 这就可以快速定位需要的区, 使用该页面后, 页面的状态改变, 继而从该状态的链表移动到转换后状态的链表. 如图中描述, .每个INODE Entry 结构占用 192 字节 个页面中可以存储 85 个这样的结构. 那如果该结构不够用了怎么办? 类似段中的三种区域链表, 将是否有空闲INODE Entry结构分成2类, 用SEG_INODES_FULL和SEG_INDOE_FREE链表连接起来, 基节点位于FSP_HDR类型页面的File Space Header中 说到这里, 我们来总结一下共有哪些结构连成了链表吧 便于表空间管理段, 第一个组中的第第一个区的第一个页面, 即FSP_HDR页面里头的File Space Header , 将每个段的INODE以是否有空闲的INODE Entry分类, 连成两条链表SEG_INODE_FULL 和SGE_INODE_FREE链表. 便于段管理使用区, 段中的INODE Entry中记录了三种状态的区域的基节点, FREE, NOT_FULL和Full链表 页面之间形成双向链表 页面中的记录之间形成单向链表. 此外, 由于段的三种区存储空间是从表空间分配而来, 因此 表空间也有三种链表FREE, FREE_FRAG和FULL_FRAG链表, 基节点位于FSP_HDR页面的File Space Header, 便于管理分配各种区. Other Tips我们知道，一个索引会产生两个段，分别是叶子节点段和非叶子节点段，而每个段都会对 应一个 INODE结构. 我们 怎么知道某个段对应哪个INODE Entry结构呢? 索引页(INDEX页) 中有一个Page Header部分 其中的 PAGE BTR_SEG_LEAF PAGE_BTR_SEG_TOP 都占用 10 字节，它们其实对应一个名为 Segmen Header 的结构，如图 9- 所示. 这样就很清晰了， Page_BTR_SEG_LEAF 记录着叶子节点段对应的 INODE Entry结构的 地址是哪个表空间中哪个页丽的哪个偏移量 PAGE_BTR_SEG_TOP 记录着非叶子节点段对应 INODE Entry结构的地址是哪个表空间中哪个页面的哪个偏移量. 这样, 索引和对应的段的关系就建立起来了. 不过需要注意的点是, 因为一个索引只对应两个段，所以只需要在索引的根页面中记录这两个结构即可.","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://messenger1th.github.io/categories/MySQL/"}],"tags":[]},{"title":"子查询优化","slug":"MySQL/子查询优化","date":"2024-07-24T14:47:34.170Z","updated":"2024-07-24T14:47:34.170Z","comments":true,"path":"2024/07/24/MySQL/子查询优化/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/MySQL/%E5%AD%90%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96/","excerpt":"","text":"查询优化连接优化条件化简 移除不必要的括号。 常量传递，例如条件中有a = 5 and b &gt; a会变为a = 5 and b &gt; 5 移除没必要的条件，如移除永远为True和False的条件。 表达式的计算，将能够计算的就计算出来。 Having和Where子句的合并，如果没有出现聚合函数、GROUP BY等，Having就等同于where。 常量表检测：如果查询条件为唯一索引等值匹配，或者表中不存在或者只存在一条记录，认为是常量表。 外连接消除由于内连接的驱动表和被驱动表可以互相转换，可以进行优化。 但左（外）连接和右（外）连接的驱动表是固定的，这就导致无法优化连接顺序，因此考虑将外连接转化为内连接，然后进行内连接优化。 被驱动表的列不为NULL，称为空值拒绝reject NULL。此时，可以保证两表都符合连接条件，因此可以转化为内连接。 子查询优化标量子查询、行子查询由于只需要查询一个记录，因此，这种查询就如预期那样，对于驱动表的每一条记录都查询一次被驱动表。 IN子查询物化表如果表中数据过多，子查询查询到的结果太多，内存可能放不下，提出来物化表的概念，即将子查询结果集写入一个临时表。此外，因为IN只是判断是否存在，还对临时表的记录进行去重。 临时表的引擎可以是MEMORY，或者InnoDB，取决于表记录量。 转化为连接如果外表与物化表可以转化为连接，则按连接处理，对连接进行分析优化。比如查询条件为唯一索引的等值查询，就可以转化为与物化表的内连接。 半连接由于物化存在一定的开销，考虑直接和子表进行连接，如半连接。 s1和s2半连接的意思是，对于s1的某条记录来说，我们只关心在s2表中是否存在对应的记录，而不关心是一条还是多条。 半连接的方式有很多，例如，表上拉Table Pullout、重复值消除Duplicate Weedout、松散扫描Loose Scan、。 表上拉当子查询的查询列表只有主键或者唯一索引时，可以把子查询的表上拉到外层的FROM子句中，并把搜索条件合并到外层查询的搜索条件中。如 SELECT * FORM s1 WHERE key2 IN ( SELECT key2 FROM s2 WHERE key3 = &#x27;a&#x27; ) 即可表上拉为 SELECT s1.* FROM s1 INNER JOIN s2 ON s1.key2 = s2.key2 WHERE s2.key3 = &#x27;a&#x27; 之所以要求主键或者唯一索引，是因为不要求就会导致查询出多条相同记录。根据这点，就有了重复值消除的方式。 重复值消除按照表上拉的方式连接，但由于不是唯一索引，可能重复，因此对结果进行去重。 总结如果符合转化为半连接的条件，查询优化器会优先转化为半连接，然后根据预估成本从以下5种办连接的策略中选择执行 Table pullout Duplicate Weed out Loose Scan Semi-join Materialization First Match execution 如果不符合转化为半连接的条件，则会根据预估成本选择如下两种方式执行。 先将子查询物化，再执行查询。 执行IN到EXISTS的转换。 把子查询外在外成查询的FROM子句，这个子查询相当于派生表，如 SELECT * FROM ( SELECT * FROM tab where id &gt; 1 ) 派生表的处理类似，也是先尝试连接，不行则物化查询。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://messenger1th.github.io/categories/MySQL/"}],"tags":[]},{"title":"事务","slug":"MySQL/事务","date":"2024-07-24T14:47:34.163Z","updated":"2024-07-24T14:47:34.163Z","comments":true,"path":"2024/07/24/MySQL/事务/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/MySQL/%E4%BA%8B%E5%8A%A1/","excerpt":"","text":"事务起因: 转账时, 我这边扣100, 你那边加100, 当我这边扣完, 你那边还没加, 服务器出断电, 导致我这少了100, 你那没加, 就出现了问题. 解决办法: 事务（Transaction） 原子性（Atomicity）：一个事务中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节，而且事务在执行过程中发生错误，会被回滚到事务开始前的状态，就像这个事务从来没有执行过一样； 一致性（Consistency）：数据库的完整性不会因为事务的执行而受到破坏，比如表中有一个字段为姓名，它有唯一约束，也就是表中姓名不能重复, 高考成绩不可能为1000，如果一个事务对姓名字段进行了修改，但是在事务提交后，表中的姓名变得非唯一性了，这就破坏了事务的一致性要求，这时数据库就要撤销该事务，返回初始化的状态。 隔离性（Isolation）：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。 持久性（Durability）：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。 InnoDB 引擎通过什么技术来保证事务的这四个特性的呢？ 持久性是通过 redo log （重做日志）来保证的； 原子性是通过 undo log（回滚日志） 来保证的； 隔离性是通过 MVCC（多版本并发控制） 或锁机制来保证的； 一致性则是通过持久性+原子性+隔离性来保证； 并行事务如果一条一条地执行事务, 就会导致一个客户端占用的情况, 其他客户端则需要「排队」, 因此, 引出「并行事务」的概念. 不难想到, 由于事务并行, 他们所读取的可能会互相影响, 因此可能会出现如下三种问题脏读（dirty read）、不可重复读（non-repeatable read）、幻读（phantom read） 脏读: 如果一个事务「读到」了另一个「未提交事务修改过的数据」，就意味着发生了「脏读」现象. 不可重复读:在一个事务内多次读取同一个数据，如果出现前后两次读到的数据不一样的情况，就意味着发生了「不可重复读」现象 幻读:在一个事务内多次查询某个符合查询条件的「记录数量」，如果出现前后两次查询到的记录数量不一样的情况，就意味着发生了「幻读」现象 为了解决这些问题, 就需要保证事务之间的「隔离性」, SQL标准提出四种隔离级别 读未提交（read uncommitted），指一个事务还没提交时，它做的变更就能被其他事务看到； 读提交（read committed），指一个事务提交之后，它做的变更才能被其他事务看到； 可重复读（repeatable read），指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，MySQL InnoDB 引擎的默认隔离级别； 串行化（serializable ）；会对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行； 这四种隔离级别具体是如何实现的呢？ 对于「读未提交」隔离级别的事务来说，因为可以读到未提交事务修改的数据，所以直接读取最新的数据就好了； 对于「串行化」隔离级别的事务来说，通过加读写锁的方式来避免并行访问； 对于「读提交」和「可重复读」隔离级别的事务来说，它们是通过 Read View来实现的，它们的区别在于创建 Read View 的时机不同，大家可以把 Read View 理解成一个数据快照，就像相机拍照那样，定格某一时刻的风景。「读提交」隔离级别是在「每个语句执行前」都会重新生成一个 Read View，而「可重复读」隔离级别是「启动事务时」生成一个 Read View，然后整个事务期间都在用这个 Read View。 来说, 「读提交」和 「可重复读」都是在事务执行时对数据的某一个版本进行操作, 「读提交」是操作事务每条命令时的版本(即可以读到已经提交的事务)「可重复读」是操作整个事务开始之前的版本. 接下来详细说下，Read View 在 MVCC 里如何工作的？ 也就是怎么找到当前隔离水平对应的版本呢? Read View 在 MVCC 里如何工作的？Read View 有四个重要的字段： m_ids ：指的是在创建 Read View 时，当前数据库中「活跃事务」的事务 id 列表，注意是一个列表，“活跃事务”指的就是，启动了但还没提交的事务。 min_trx_id ：指的是在创建 Read View 时，当前数据库中「活跃事务」中事务 id 最小的事务，也就是 m_ids 的最小值。 max_trx_id ：这个并不是 m_ids 的最大值，而是创建 Read View 时当前数据库中应该给下一个事务的 id 值，也就是全局事务中最大的事务 id 值 + 1； creator_trx_id ：指的是创建该 Read View 的事务的事务 id。 聚簇索引中有两个列 trx_id : 当一个事务对某条聚簇索引记录进行改动时，就会把该事务的事务 id 记录在 trx_id 隐藏列里； oll_pointer，每次对某条聚簇索引记录进行改动时，都会把旧版本的记录写入到 undo 日志中，然后这个隐藏列是个指针，指向每一个旧版本记录，于是就可以通过它找到修改前的记录。 重点看min_trx_id和max_trx_id和m_ids min_trx_id 和 max_trx_id之间的是暂未提交的事务id范围, m_ids是具体事务的列表 Read View创建时, 设置好min_trx_id, max_trx_id和m_ids列表. 执行命令时, 比较记录的trx_id 该记录trx_id比Read View的min_trx还小, 即记录不是活跃事务的操作对象, 即当前事务可见 如果记录的 trx_id 值大于等于 Read View 中的 max_trx_id 值，表示这个版本的记录是在创建 Read View 后才启动的事务生成的，所以该版本的记录对当前事务不可见。 在这俩之间就需要查看m_ids列表了 如果记录的 trx_id 在 m_ids 列表中，表示生成该版本记录的活跃事务依然活跃着（还没提交事务），所以该版本的记录对当前事务不可见。 如果记录的 trx_id 不在 m_ids列表中，表示生成该版本记录的活跃事务已经被提交，所以该版本的记录对当前事务可见。 Read VIew在不同隔离级别下的行为总的来说: 可见就可以直接读取, 不可见则根据该记录的roll_pointer指向之前的记录查找, 直到符合可见条件的位置, 这就是找历史版本的过程.具体读不读取决于隔离级别, 如果是可重复读就需要找整个事务之前的历史版本, 如果是读提交就可以直接读取可见的记录 幻读 由于可以读取历史记录, 普通读就可以避免不可重复度. 但在当前读的情况下(如select ... for update/ delete update等语句), 必须得读取当前记录,此时MVCC的历史版本就被忽略, 就可能出现幻读的情况, 因此, InnoDB采取加锁来防止幻读. 加锁的情况在 lock 中详细说明 并发问题 咱读 不可重复读 幻读 更新丢失 读偏斜 写偏斜 Others Tips 注意，执行「开始事务」命令，并不意味着启动了事务。在 MySQL 有两种开启事务的命令，分别是： 第一种：begin&#x2F;start transaction 命令； 第二种：start transaction with consistent snapshot 命令； 这两种开启事务的命令，事务的启动时机是不同的： 执行了 begin&#x2F;start transaction 命令后，并不代表事务启动了。只有在执行这个命令后，执行了增删查改操作的 SQL 语句，才是事务真正启动的时机； 执行了 start transaction with consistent snapshot 命令，就会马上启动事务。 普通Select语句 在不同隔离级别都不加锁, 在可重复读隔离级别使用MVCC(即读取历史版本)来避免问题, 此时 Select …for update(Update, insert, delete同理, 都是读取当前的数据)会出问题, 需要加next-key锁 事务在执行过程中所获取的锁一般在事务提交或者回滚时才会释 但是在隔离级别不大于 读提交READ COMMlTTED时，在某些情况下也会提前将一些不符合搜 条件的记录上的锁释放掉, 提高并发.","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://messenger1th.github.io/categories/MySQL/"}],"tags":[]},{"title":"Undo Log","slug":"MySQL/Undo Log","date":"2024-07-24T14:47:34.123Z","updated":"2024-07-24T14:47:34.123Z","comments":true,"path":"2024/07/24/MySQL/Undo Log/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/MySQL/Undo%20Log/","excerpt":"","text":"Undo LogUndo PagePage formatNormal Undo Page First Page In Linked List Specific Logsinsert Speficic data delete Flow UpdateNot Update Primary Keyif it’s in-place update, it just update. else, meaning that record will take more place and it’s not enough, it will delete original record, and insert a new record Update Primary Key delete mask on original record create a new record Second indexif it update second index, it will execute delete mask operation and change File Header’s PAGE_MAX_TRX_ID to the transaction’s id. Transactionfor a transaction, mysql wiil create at most 2 kinds of undo page list for normal table, respectively insert undo list and update undo list. It’s a lazy load technology meaning that it will be create only it needed. for a temp table, Undo Page List do the same as normal table, but it doesn’t need to create redo page for temp table. Rollback SegmentArchitecture Fifth Page Rollback Segment Header Page Reuse Undo ListIf Undo List satisfies two conditions only one Undo Page used space in the page less than 3&#x2F;4. for different kinds of undo page list, has different strategy insert undo list: Just Use. update undo list : append write a new Undo Log Header and new logs. PurgeWhen purge a undo list ?if the minimum ReadVies’s transaction_no is bigger than this undo list’s transaction_no, it’s time to purge it, meaning that all the ReadViess can see this change. How to purge a undo listInsert Undo ListAfter a transaction commit, for insert undo list, it can be purged right now, because it’s designed to rallback and not useful anymore. But its trx_id and roll_pointer should be keeped, not been purged. Update Undo Listafter a transaction commit, write its transaction_no which means committing order to Undo Logo Header, and the whole list will be insert into history list. History list will range there Undo list order by their transaction_no. Also, ReadView will be ranged an ordered list order by theirtransaction_no. While purging, background thread will get current mimimum transaction_no of ReadView list, and check history list, if Uodo list’s transaction_no is less than ReadView’s, the Undo list could be purged. if Undo list marked delete mask, it will delete record acctually.","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://messenger1th.github.io/categories/MySQL/"}],"tags":[]},{"title":"Structure","slug":"MySQL/Structure","date":"2024-07-24T14:47:34.097Z","updated":"2024-07-24T14:47:34.097Z","comments":true,"path":"2024/07/24/MySQL/Structure/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/MySQL/Structure/","excerpt":"","text":"StructureTableevery table has three linked list to orgnize 3 kinds of extent. FREE List FREE_FRAG List FULL_FRAG List every table has many segment SET_INODES_FULL List SET_INODES_FREE List when segment SET_INODES_FREE List is not enough, It will get a page from table’s FREE_FRAG List. Table Structure Table InformationFSP_HDR page store the table information, locate in the first extent, first pag. Detail as follow Segment every segment associate a INODE Entry INODE Entry are stored in INODE page. INODE Page controlled by two double linked list SEG_INODES_FULL SET_INODES_FREE Segment structureINODE Page : locate in first extent, third page. INODE Entry ExtentExtent Structure PageBasic Page: File Header + File Trailer File Header Page Type FIL_PAGE_INDEX Page Detail as follow. Page Header Other Information index page and file page are separate into different segment. when a table’s data has been over 32 pages, it will allocate extent rather than page.","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://messenger1th.github.io/categories/MySQL/"}],"tags":[]},{"title":"Redo Log","slug":"MySQL/Redo Log","date":"2024-07-24T14:47:34.077Z","updated":"2024-07-24T14:47:34.077Z","comments":true,"path":"2024/07/24/MySQL/Redo Log/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/MySQL/Redo%20Log/","excerpt":"","text":"Redo LogFormat Example By the way, for a sparse page, there are logs(MLOG_COMP_LIST_START ,MLOG_COMP_LIST_END and etc) that store a list of operation. Mini-TransactionAtomic operations Group Redo Log: make multi redo log atomic. Single Redo Log Group Redo Log Single Redo Log Mini-TransactionMini-Transaction is a atomic operation, including a group redo log or a Single atomic redo log. Relationship Redo Log BufferRedo Log Block Write Redo Log to Redo Log Buffer Concurrency of Redo Log Buffer When write to disk Not enough log buffer space. transaction is committing. write redo log before writing dirty. background thread write periodically. power off checkpoint update. Redo Log FileFile Group File Format Log File header Log File checkpoint Flags Long Sequence Number Flushed_to_disk_lsn oldest_modification checkpoint_lsn Variables Meaning How to update Long Sequence Number Next redo start number. do operation Flushed_to_disk_lsn lsn that has been written to disk write redo log page in redo log bugger to disk oldest_modification oldest lsn of dirty page. periodically flush checkpoint_lsn checkpoint of transaction execute checkpoint: update checkpoint_lst and write checkpoint to log file rankcheckpoint_lsn &lt;&#x3D; oldest_modification &lt;&#x3D; flushed_to_disk_lsn &lt;&#x3D; Long Sequence Number How to update checkpoint_lsn : checkpoint read current oldest_modification and set it to checkpoint_lsn write current checkpoint’s information to redo log file(actually the first log filie’s checkpoint area). Crash RecoveryRecovery RangeLook at rank picture. Recovery range is from checkpoint_lsn to flushed_to_disk_lsn, namely part 4. but part 1 has been write to disk before crash, so it will be passed. Start Pointget checkpoint_lsn from first log’s checkpoint area. End Pointscan from checkpoint until log file’s LOG_BLOCK_HDR_DATA_LEN is not 512. How to pass part 1 while recoveringThere are a FIL_PAGE_LSN in redo log file header. if this value is bigger than last checkpoint_lsn, meaning that it’s more updated, it will passed. OptimizationWhile reading redo log file, arrange redo log by hash table. Key is redo log’s space ID and page number. arrange them by writing order to keep original order. If this page has been passed(namely has been written be crash), it will not wirte again. minimize disk I&#x2F;O by hash table avoid duplicate write Safety vs Concurencyinnodb_flush_log_at_trx_commit when flush redo while committing. 0: not right now, depends on background thread. default 1: now. write to disk directly. 2: wriiten by buffer IO. live in System’s page buffer.","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://messenger1th.github.io/categories/MySQL/"}],"tags":[]},{"title":"Record","slug":"MySQL/Record","date":"2024-07-24T14:47:34.060Z","updated":"2024-07-24T14:47:34.060Z","comments":true,"path":"2024/07/24/MySQL/Record/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/MySQL/Record/","excerpt":"","text":"Recordfor each record, MySQL will add other default three column. But if any column could be primary key , row_id will not be added. There are totally four kinds of formats in MySQL compact redundant dynamic compressed Current default is compact. We can indicate it. create table tb ( ... ) ROW_FORMAT=COMPACT FormatCompact Formatmain structure is as follow. when we want to locate a record, we find its record header’s position. Then parser NULL list and variables list in reverse order.(Because it store reversely). Recorder Headerfor compact format, it take fixed 5 bytes. NULL listNull list is stored as a bit for every column, which is not declare NOT NULL. For not full a byte condition, fulfill it with zero bit. Variable listIn this list, use one or two bytes to express data length. set W bytes is the longest bytes of the table’s dataset. set M bytes is the longest characters it can store. set L is the actual bytes to store this record. if M * W &lt; 255, use one byte. if M * W &gt; 255 L &lt;&#x3D; 127 use one byte L &gt; 127 use two byte CHAR(M) column if its fixed encoding set, it will be seen as other fixed column. else, it will be add to variable list and restrain its length at least M bytes for later convenient expansion. Redundant Formatmain structure is as follow. Recorder HeaderIt take fixed 6 bytes. Compared to compact format, it add n_filed and 1byte_offs_flag and lose record_type Variable listIt’s use one byte or two bytes depends on total record size rather than single column size. It use offset rather than length to express its length, meaning that length is its difference. 1byte_offs_flag is used to express it. 1 means 1 byte. 0 means 2 bytes. set S as total record size. if S &lt;&#x3D; 127, it’s 1. if S &gt; 127 but S &lt; 32767, it’s 0. if S &gt; 32767, it’s overflow page, will explain it later. NULL listNull list is stored as a bit for every column, which is not declare NOT NULL. but this bit is moved to Variable list. every first byte’s last bit. Dynamic Format And Compressed FormatThese two are basically same as compact. But it is different in overflow page. compact format will a store part of data and a overflow page address in origin page. while Dynamic format will not store data, only overflow page address. and Compressed Format will compress data. Layout in Page Records are linked by a single forward linked list. A few records are seen as a ‘group’, every slot remember its group main record’s offset in page. Slot is used to binary search. Other information every slot is 2 bytes, enough to store offset in page(default 16 KB, less than 2^16). QuestionsWhy set record header in middle of record and set NULL list and variable list in reverse order ?when we reach a record, we want to parse it, read its information and data simultaneously. On the one hand, it better to code to parse it, read one column’s null value and length and move to get it .On the other hand, it’s make closed column get more possibility to be cached, increasing cache hit rate. Why there are at least two record in a page ?To make sure search more efficient. In a page, there are some slots store some record. About 7~8 records per page. Why page are double linked list ?for range traversal.","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://messenger1th.github.io/categories/MySQL/"}],"tags":[]},{"title":"Lock","slug":"MySQL/Lock","date":"2024-07-24T14:47:34.053Z","updated":"2024-07-24T14:47:34.054Z","comments":true,"path":"2024/07/24/MySQL/Lock/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/MySQL/Lock/","excerpt":"","text":"锁 一般规律MySQL的锁基本上都有X型（exclusive：独占）和S（share：共享）型之分，用于读的更高并发。 除了全局锁（只读）和插入意向锁（只有IX（intention exclusive）型，插入只能独占）。 MySQL 加锁时，是先生成锁结构，然后设置锁的状态，如果锁状态是等待状态，并不是意味着事务成功获取到了锁，只有当锁状态为正常状态时，才代表事务成功获取到了锁 。 全局锁命令如下 flush tables with read lock; // lock all tables; unlock tables; //unlock; 表级锁表锁lock tables table1 table2 ... read; lock tables table1 table2 ... write; unlock tables; 元数据锁MDL主要用于维护表结构。 关于表结构的锁。 在执行CRUD时，加的是MDL read lock。 在修改表结构时，加的是MDL write lock。 在执行命令时上锁，事务提交时释放。 由于MDL write lock具有更高优先级，更改结构的语句开始时（还没获得锁，但在等待锁），会阻塞后续的CRUD的操作。 意向锁表级别的意向锁是用于快速判断有没有更细粒度的锁，如行级别的锁。 在加行级锁时，会先在表级别加上对应的意向锁。如 在使用 InnoDB 引擎的表里对某些记录加上「共享锁」之前，需要先在表级别加上一个「意向共享锁」； 在使用 InnoDB 引擎的表里对某些纪录加上「独占锁」之前，需要先在表级别加上一个「意向独占锁」； 如下列语句，会先加表级意向锁，再加行级锁。 select ... for update; //先加表级意向独占锁，再加行级独占锁。 select ... lock in share mode; //先加表级意向共享锁，再加行级共享锁。 ATUO-INC锁AUTO-INC 锁用于插入记录时，控制分配自增主键的并发。 InnoDB 存储引擎提供了个 innodb_autoinc_lock_mode 的系统变量，是用来控制选择用 AUTO-INC 锁，还是轻量级的锁。 当 innodb_autoinc_lock_mode &#x3D; 0，就采用 AUTO-INC 锁，语句执行结束后才释放锁； 当 innodb_autoinc_lock_mode &#x3D; 2，就采用轻量级锁，申请自增主键后就释放锁，并不需要等语句执行后才释放。 当 innodb_autoinc_lock_mode &#x3D; 1： 普通 insert 语句，自增锁在申请之后就马上释放； 类似 insert … select 这样的批量插入数据的语句，自增锁还是要等语句结束后才被释放； 当 innodb_autoinc_lock_mode &#x3D; 2 是性能最高的方式，但是当搭配 binlog 的日志格式是 statement 一起使用的时候，在「主从复制的场景」中会发生数据不一致的问题。 因为binlogi记录的是statement（即原始命令），主从复制时，从库接受到statement之后，按顺序执行。 考虑如下场景 当 innodb_autoinc_lock_mode &#x3D; 2， 主库：session B的插入语句是插入了四条记录，每条记录之间都有可能执行sessionA的插入，拿到了对应的id。 从库：由于binlog中都是按顺序记录的，所以从库不能知道这俩其实是并发执行的。只是会顺序执行binlog。 所以这里sessionA插入的id只能是1或者5。出现了主从库数据不一致的情况。 总结来看，当 innodb_autoinc_lock_mode &#x3D; 2，事务的多条插入就不会被视为一个整体。可能被其他事务临门一脚。主库和从库会有数据不一致的情况。 解决上述问题的方法是，将binlog设置为row。这样在 binlog 里面记录的是主库分配的自增值，到备库执行的时候，主库的自增值是什么，从库的自增值就是什么。 所以，当 innodb_autoinc_lock_mode &#x3D; 2 时，并且 binlog_format &#x3D; row，既能提升并发性，又不会出现数据一致性问题。 行级锁Record LockRecord Lock称为记录锁，顾名思义就是锁住一个记录的。 Gap LockGap Lock称为间隙锁，顾名思义就是锁住一个区间，特指左开右开区间。 注：虽然Gap Lock也有X型（exclusive）和S型（share），但作用上没有区别，都是防止插入，与插入意向锁互斥。加X还是S，要看SQL语句是读还是写。 Next-Key LockNext-Key Lock称为临键锁，实际上是Record Lock + Gap Lock，锁住上一条记录（不含）到本条记录（含），即左开右闭区间。 由于含有Gap Lock，因此也有Gap Lock的作用。 插入意向锁顾名思义是用于插入的锁，与间隙锁、另外的插入意向锁互斥。 Insert 语句在正常执行时是不会生成锁结构的，它是靠聚簇索引记录自带的 trx_id 隐藏列来作为隐式锁来保护记录的。 当事务需要加锁的时，如果这个锁不发生冲突，InnoDB会跳过加锁环节，这种机制称为隐式锁。 隐式锁是 InnoDB 实现的一种延迟加锁机制，其特点是只有在可能发生冲突时才加锁，从而减少了锁的数量，提高了系统整体性能。 加锁分析MySQL实现的行级锁是加在每一个记录上的索引上的，要判断相应的地方是否上锁，需要查找到附近的记录上，根据记录的值和锁的范围、锁的类型，来判断是否能够上锁。 在加行级锁之前都会先加对应表级别的锁。 MySQL加行级锁都是先加next-key锁，再判断是否需要缩小加锁范围，变成间隙锁或者记录锁。 MySQL的加锁原则是 加锁范围只能大于等于请求范围。即加锁区域完全覆盖请求区域。 加锁加在具体的记录上，因此可能 “误伤”。可能加在并非当前查询的区域上。即加锁区域可能大于请求区域。 注：此部分存疑，实测聚簇索引在更新二级索引的情况下不会给该二级索引加锁。 由于加锁都是加在索引上的，有如下规则。 如果是二级索引, 还需要回表到聚簇索引给聚簇索引加相应的锁. 如果是聚簇索引, 并且更新了二级索引, 需要到相应二级索引上X锁. 为什么两边都要上锁呢? 考虑如下情况: 二级索引到聚簇索引的情况: 二级索引查询, 若仅对二级索引上锁, 第一次查到一个记录符合条件, 给二级索引上相应的锁 第二次查询之前, 有一个事务修改了上面符合条件的记录, 导致不符合条件. 第二次查询时, 就出现了问题. 聚簇索引到二级索引的情况: 根据聚簇索引更新记录, 更新了二级索引, 更新前后读到的二级索引不一致. 就出现了问题. 行级锁的分析，主要是分唯一索引和非唯一索引讨论，具体情况分析如下。 唯一索引等值查询 存在则加记录锁 记录不存在则加间隙锁 范围查询根据范围加next-key锁，如果临界点不是对应的范围边界，则会退化成记录锁或者间隙锁。 查询的是（a, b）或者 [a, b），则b处或其下一条记录会变为间隙锁。 查询的是 [a, b）或者 [a, b]，则a处可能可能变为记录锁（取决于是否存在a记录，存在则退化）。 举例，user表结构和表内容如下。 请求范围为(-∞, 5]：加锁为 (-∞, 5]，即：(-∞, 1] + (1, 2] + (2, 5]。 即都是next-key锁。 请求范围为(-∞, 5)：加锁为 (-∞, 5)，即：(-∞, 1] + (1, 2] + (2, 5)。 id&#x3D;5的记录处的next-key退化为了间隙锁。 请求范围为(6, +∞)：加锁为(5, +∞)。即：（5, 20] + (20, 30] + (30, +∞]。即都是next-key锁。 请求范围为[5, +∞)：加锁为[5, +∞)。即：5 (记录锁) + (5, 20] + (20, 30] + (30, +∞)。不难发现id&#x3D;5处的锁为记录锁。 非唯一索引由于是非唯一的，因此除了需要把整个查询区域都锁住外，还需要一部分冗余的加锁空间。 等值查询假设查询为X，实际加锁范围为(a, b)，且有a &lt; X &lt; b 注意，由于是非唯一索引，因此实际加锁范围一定是左开右开（当然如果边界是+-∞就无所谓开闭）。 范围查询范围查询类似上述非唯一索引等值查询。 假设查询范围[x, y]，查询区间可以是任意开闭。实际加锁范围为(a, b)，且有a &lt; x &lt;= y &lt; b 以上4种情况，如果更新了二级索引，也会给二级索引加上作用类似X型记录锁的隐式锁。 非索引查询如果是非索引查询的话，走的是全表查询，会将所有记录都加上next-key锁。相当于是锁全表。 insert加锁分析插入意向锁主要用于并发插入，是一种隐式锁。隐式锁就是在 Insert 过程中不加锁，只有在特殊情况下，才会将隐式锁转换为显示锁，这里我们列举两个冲突场景。 间隙锁冲突：如果记录之间加有间隙锁，为了避免幻读，此时是不能插入记录的； 唯一键冲突：如果 Insert 的记录和已有记录存在唯一键冲突，此时也不能插入记录； 外键检查：需要对有外键约束的进行加锁。 插入意向锁与间隙锁的冲突当下一条记录已有间隙锁，此时会生成一个插入意向锁，然后锁的状态设置为等待状态，现象就是 Insert 语句会被阻塞。 唯一键冲突 插入意向锁与其他插入意向锁的冲突：顾名思义仅有唯一性的冲突，发生在如下情况下。 主键索引重复和唯一二级索引：插入失败并，添加S型的next-key锁，防止幻读。 上述都是插入失败的情况，会加上S型的next-key锁防止记录被delete导致的幻读。 两个事务并发（不一定都是插入事务）的唯一键冲突：事务没有提交，但此时来了引发上述唯一性冲突的事务。此时，原事务会加上上述X型的锁。新来的事务会阻塞等待S型的锁。 但没有唯一键冲突、且没有间隙锁的话，多个insert命令的插入意向锁不会变成显式锁，可以并发运行。 外键加锁当外键能够在表中找到则加S型记录锁，找不到加S型Gap锁。 死锁MySQL有死锁检测机制。 死锁发生时 lnnoDB 会选择一个资源最少的事务进行回滚. 可以通过执行 SHOW ENGINE INNODB STATUS 语句来查看最近发生的一次死锁信息.","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://messenger1th.github.io/categories/MySQL/"}],"tags":[]},{"title":"Buffer Pool","slug":"MySQL/Buffer Pool","date":"2024-07-24T14:47:34.047Z","updated":"2024-07-24T14:47:34.047Z","comments":true,"path":"2024/07/24/MySQL/Buffer Pool/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/MySQL/Buffer%20Pool/","excerpt":"","text":"Buffer Pool由于CPU和硬盘的速度存在很大差异，类似如CPU Cache、Linux Page Buffer， 都是为了缓和速度差异，有了Buffer Pool 的概念。 有了缓冲池后： 当读取数据时，如果数据存在于 Buffer Pool 中，就会直接读取 Buffer Pool 中的数据，否则再去磁盘中读取。 当修改数据时，首先是修改 Buffer Pool 中数据所在的页，然后将其页设置为脏页，最后由后台线程将脏页写入到磁盘。 Buffer Pool 有多大？Buffer Pool 是在 MySQL 启动的时候，向操作系统申请的一片连续的内存空间，默认配置下 Buffer Pool 只有 128MB 。 可以通过调整 innodb_buffer_pool_size 参数来设置 Buffer Pool 的大小，一般建议设置成可用物理内存的 60%~80%。 Buffer Pool 缓存什么？InnoDB存储数据的单位是页, 默认16KB, 因此Buffer Pool也按页来划分. 当我们查询一条记录时，InnoDB 是会把整个页的数据加载到 Buffer Pool 中，因为，通过索引只能定位到磁盘中的页，而不能定位到页中的一条记录。将页加载到 Buffer Pool 后，再通过页里的页目录去定位到某条具体的记录。 管理 Buffer PoolBuffer Pool是启动时向操作系统申请一块连续的虚拟地址空间，按照页面进行管理，首先将其划分为空闲页，加入Free List进行管理。 管理空闲页面：Free List为了能够快速找到空闲的缓存页，可以使用链表结构，将空闲缓存页的「控制块」作为链表的节点，这个链表称为 Free 链表（空闲链表）。 Free 链表上除了有控制块，还有一个头节点，该头节点包含链表的头节点地址，尾节点地址，以及当前链表中节点的数量等信息。 Free 链表节点是一个一个的控制块，而每个控制块包含着对应缓存页的地址，所以相当于 Free 链表节点都对应一个空闲的缓存页。 有了 Free 链表后，每当需要从磁盘中加载一个页到 Buffer Pool 中时，就从 Free链表中取一个空闲的缓存页，并且把该缓存页对应的控制块的信息填上，然后把该缓存页对应的控制块从 Free 链表中移除。 管理脏页：Flush List设计 Buffer Pool 除了能提高读性能，还能提高写性能，也就是更新数据的时候，会操作LRU链表中的页面，不需要每次都要写入磁盘，而是将 LRU中对应的缓存页标记为脏页，然后再由后台线程将脏页写入到磁盘。 那为了能快速知道哪些缓存页是脏的，于是就设计出 Flush 链表，它跟 Free 链表类似的，链表的节点也是控制块，区别在于 Flush 链表的元素都是脏页。 有了 Flush 链表后，后台线程就可以遍历 Flush 链表，将脏页写入到磁盘。 实际上，Flush链表跟redo日志关联很大，redo文章中再提。 管理普通页：LRU List如何提高缓冲命中率， 最容易想到的是 LRU(Least recently used)算法. 但会出现一些问题 预读失败 Buffer Pool污染 针对以上两个问题，需要对普通的LRU进行一定的改进。 预读失败MySQL在加载数据页的时候, 由于程序的空间局部性的存在, 会将被访问数据的周围数据也加载进来, 以此减少磁盘I&#x2F;O, 但是有可能这些数据没有被访问到, 这就是预读失败. MySQL有两种预读策略，都是异步读取。 线性预读：如果读取该区的页面数量超过阈值，则预读下一个区的所有页面。 随机预读：如果在一个区读取一定量的热点页面，则读取该页面所在的整个区的所有页面。 预读成功了能加快速度，但失败就会冲刷热点页面。 所以MySQL改进LRU算法, 将LRU划分成两个区域, old区域和young区域 young在前, old在后优先被淘汰. 预读页加入到old区域的头部, 不影响young中高频使用的数据页，访问到了才加到young区域. 这样，预读失败也不会影响主要的热点页面。 Buffer Pool污染短时间内访问了大量数据页, 例如全表扫描，导致Buffer Pool被这些仅访问一次的数据冲刷. MySQL是这样处理的, 进入到yound区域的条件增加了一个停留在old区域的时间判断. 具体是这样做的，在对某个处在 old 区域的缓存页进行第一次访问时，就在它对应的控制块中记录下来这个访问时间： 如果后续的访问时间与第一次访问的时间在某个时间间隔内，那么该缓存页就不会被从 old 区域移动到 young 区域的头部； 如果后续的访问时间与第一次访问的时间不在某个时间间隔内，那么该缓存页移动到 young 区域的头部； 这个间隔时间是由 innodb_old_blocks_time 控制的，默认是 1000 ms。 也就说，只有同时满足「被访问」与「在 old 区域停留时间超过 1 秒」两个条件，才会被插入到 young 区域头部，这样就解决了 Buffer Pool 污染的问题 。 全表扫描两次访问同一页面一般不会超过1s，因此也不会影响young区域。 其他优化 针对 young 区域，为了防止 young 区域节点频繁移动到头部。young 区域前面 1&#x2F;4 被访问不会移动到链表头部，只有后面的 3&#x2F;4被访问了才会。 其他链表除了上面提到的Free、Flush、LRU链表外，还有一些其他页面的链表。如 unzip LRU：管理解压页面 zip clean ： 管理压缩页 zip free：每个元素都是一个链表 等等其他用于更好的管理Buffer Pool的数据结构。 脏页什么时候刷入磁盘?InnoDB的更新操作采用的是Write Ahead Log即先写日志, 再写入磁盘, 通过redo log让MySQL拥有了奔溃恢复能力 下面几种情况会触发脏页刷新 后台线程扫描LRU链表定时刷盘：BUF_FLUSH_LRU 后台线程刷新Flush一部分页面：BUF_FLUSH_LIST 用户线程需要读取一个磁盘页时，空间不够，由用户线程同步刷盘：BUF_FLUSH_SINGLE_PAGE redo log日志满了的情况 Buffer Pool空间不足, 会淘汰一部分数据页, 如果是脏页就同步到磁盘 MySQL认为空闲时 正常关闭时. 在我们开启了慢 SQL 监控后，如果你发现「偶尔」会出现一些用时稍长的 SQL，这可能是因为脏页在刷新到磁盘时可能会给数据库带来性能开销，导致数据库操作抖动。 如果间断出现这种现象，就需要调大 Buffer Pool 空间或 redo log 日志的大小。 优化Buffer Pool上述我们提到Buffer Pool是连续大内存块，增大需要完整复制，很耗时。为了动态调整该大小。后面Innodb的Buffer Pool由chunk组成，每个chunk都是连续的内存空间，可以动态增删chunk。 此外，后续的版本更新还支持多个Buffer Pool Instance，更具扩展性。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://messenger1th.github.io/categories/MySQL/"}],"tags":[]},{"title":"网络编程","slug":"Linux/网络编程","date":"2024-07-24T14:47:34.042Z","updated":"2024-07-24T14:47:34.042Z","comments":true,"path":"2024/07/24/Linux/网络编程/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Linux/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/","excerpt":"","text":"网络编程基本socket模型 IO多路复用I&#x2F;O多路复用实际上是将等待IO请求的责任交给了内核，内核管理所有已经建立连接的socket，当程序调用查询函数时返回给程序去处理。 select&#x2F;pollselect 实现多路复用的方式是，将已连接的 Socket 都放到一个文件描述符集合，然后调用 select 函数将文件描述符集合拷贝到内核里，让内核来检查是否有网络事件产生，检查的方式很粗暴，就是通过遍历文件描述符集合的方式，当检查到有事件产生后，将此 Socket 标记为可读或可写， 接着再把整个文件描述符集合拷贝回用户态里，然后用户态还需要再通过遍历的方法找到可读或可写的 Socket，然后再对其处理。 所以，对于 select 这种方式，需要进行 2 次「遍历」文件描述符集合，一次是在内核态里，一个次是在用户态里 ，而且还会发生 2 次「拷贝」文件描述符集合，先从用户空间传入内核空间，由内核修改后，再传出到用户空间中。 select 使用固定长度的 BitsMap，表示文件描述符集合，而且所支持的文件描述符的个数是有限制的，在 Linux 系统中，由内核中的 FD_SETSIZE 限制， 默认最大值为 1024，只能监听 0~1023 的文件描述符。 poll 不再用 BitsMap 来存储所关注的文件描述符，取而代之用动态数组，以链表形式来组织，突破了 select 的文件描述符个数限制，当然还会受到系统文件描述符限制。 但是 poll 和 select 并没有太大的本质区别，都是使用「线性结构」存储进程关注的 Socket 集合，因此都需要遍历文件描述符集合来找到可读或可写的 Socket，时间复杂度为 O(n)，而且也需要在用户态与内核态之间拷贝文件描述符集合，这种方式随着并发数上来，性能的损耗会呈指数级增长。 select poll 组织方式 固定长度的 BitsMap 动态数组 检查方式 遍历 遍历 时间复杂度 O(n) O(n) 文件描述符 最大1024 无限制 epollepoll的基本流程如下 int s = socket(AF_INET, SOCK_STREAM, 0); bind(s, ...); listen(s, ...) int epfd = epoll_create(...); epoll_ctl(epfd, ...); //将所有需要监听的socket添加到epfd中 while(1) &#123; int n = epoll_wait(...); for(接收到数据的socket)&#123; //处理 &#125; &#125; epoll 通过两个方面，很好解决了 select&#x2F;poll 的问题。 epoll 在内核里使用红黑树来跟踪进程所有待检测的文件描述字，把需要监控的 socket 通过 epoll_ctl() 函数加入内核中的红黑树里，红黑树是个高效的数据结构，增删改一般时间复杂度是 O(logn)。而 select&#x2F;poll 内核里没有类似 epoll 红黑树这种保存所有待检测的 socket 的数据结构，所以 select&#x2F;poll 每次操作时都传入整个 socket 集合给内核，而 epoll 因为在内核维护了红黑树，可以保存所有待检测的 socket ，所以只需要传入一个待检测的 socket，减少了内核和用户空间大量的数据拷贝和内存分配。 epoll 使用事件驱动的机制，内核里维护了一个链表来记录就绪事件，当某个 socket 有事件发生时，通过回调函数内核会将其加入到这个就绪事件列表中，当用户调用 epoll_wait() 函数时，只会返回有事件发生的文件描述符的个数，不需要像 select&#x2F;poll 那样轮询扫描整个 socket 集合，大大提高了检测的效率。 边缘触发和水平触发边缘触发模式时，当被监控的 Socket 描述符上有可读事件发生时，服务器端只会从 epoll_wait 中苏醒一次，即使进程没有调用 read 函数从内核读取数据，也依然只苏醒一次，因此我们程序要保证一次性将内核缓冲区的数据读取完； 水平触发模式时，当被监控的 Socket 上有可读事件发生时，服务器端不断地从 epoll_wait 中苏醒，直到内核缓冲区数据被 read 函数读完才结束，目的是告诉我们有数据需要读取； select和poll只能工作在水平触发模式。 epoll可以工作在水平触发和边缘触发，但处在边缘触发模式时，最好搭配非阻塞IO，否则可能阻塞在某一个连接上而无法处理其他连接。举一个例子，我们一般是通过epoll_wait获取当前需要业务处理的fd，用一个while循环读取数据，如果是非阻塞IO，读完数据会返回一个EAGIAIN错误，表示当前没有数据可以读取；如果是阻塞IO，没有数据也不会返回，而是阻塞等待到有数据可以读取，这样本来负责所有连接的线程现在只能阻塞等待一个连接的业务了。以上是read的情况，write同理。 所以，epoll处于边缘触发时，最好搭配非阻塞IO。 此外，Linux 手册关于 select 的内容中有如下说明： Under Linux, select() may report a socket file descriptor as “ready for reading”, while nevertheless a subsequent read blocks. This could for example happen when data has arrived but upon examination has wrong checksum and is discarded. There may be other circumstances in which a file descriptor is spuriously reported as ready. Thus it may be safer to use O_NONBLOCK on sockets that should not block. 即就算多路复用返回了事件，事件也不一定是可读写的，比如数据到达了，但经检查后发现数据错误丢弃。 如果使用阻塞 I&#x2F;O， 那么在调用 read&#x2F;write 时则会发生程序阻塞，因此最好搭配非阻塞 I&#x2F;O，以便应对极少数的特殊情况。 总的来说，使用IO多路复用时，尽量使用非阻塞IO。 select&#x2F;poll和epoll区别如下 select&#x2F;poll epoll 组织方式 线性结构 红黑树 检查方式 遍历 索引 时间复杂度 O(n) O(log n) 触发方式 仅水平触发 可水平触发可边缘触发 IO：阻塞\\非阻塞\\同步\\异步在前面我们知道了，I&#x2F;O 是分为两个过程的： 数据准备的过程 数据从内核空间拷贝到用户进程缓冲区的过程 阻塞和非阻塞都是同步IO，区别就在与是否在第一个步骤「数据准备」。 阻塞IO会在「数据准备」的过程中阻塞等待，无法执行。 非阻塞IO会在数据未准备时，返回一个特殊值，表示还未准备好，可以执行其他命令。 阻塞IO流程如下 非阻塞IO流程如下 如果 socket 设置了 O_NONBLOCK 标志，那么就表示使用的是非阻塞 I&#x2F;O 的方式访问，而不做任何设置的话，默认是阻塞 I&#x2F;O。 同步IO是在第二步骤「数据从内核空间拷贝到用户进程缓冲区的过程」阻塞，而异步 I&#x2F;O 是「内核数据准备好」和「数据从内核态拷贝到用户态」这两个过程都不用等待。 当我们发起 aio_read （异步 I&#x2F;O） 之后，就立即返回，内核自动将数据从内核空间拷贝到用户空间，这个拷贝过程同样是异步的，内核自动完成的，和前面的同步操作不一样，应用程序并不需要主动发起拷贝动作。 异步IO流程如下 高性能网络模式高性能网络模式都基于于epoll实现，搭配一定的多线程、多进程。 ReactorReactor就是使用epoll接受请求的线程，处理连接请求，当读写事件到来，通常会将具体操作分发给其他线程。 常用的架构有 单 Reactor 单线程 &#x2F; 多进程 单 Reactor 多线程 &#x2F; 多进程 多 Reactor 多线程 &#x2F; 多进程 单 Reactor 单线程 &#x2F; 多进程 在这个架构中，Reactor负责接收请求，同时接收请求后需要自己负责处理，并没有用到其他线程或进程。实际上就是接收后调用对应对象的成员函数。 优点：单 Reactor 单进程的方案因为全部工作都在同一个进程内完成，所以实现起来比较简单，不需要考虑进程间通信，也不用担心多进程竞争。 缺点 无法充分利用 多核 CPU 的性能 Handler 对象在业务处理时，整个进程是无法处理其他连接的事件的，如果业务处理耗时比较长，那么就造成响应的延迟 所以，单 Reactor 单进程的方案不适用计算机密集型的场景，只适用于业务处理非常快速的场景。 Redis 是由 C 语言实现的，在 Redis 6.0 版本之前采用的正是「单 Reactor 单进程」的方案，因为 Redis 业务处理主要是在内存中完成，操作的速度是很快的，性能瓶颈不在 CPU 上，所以 Redis 对于命令的处理是单进程的方案。 单 Reactor 多线程 &#x2F; 多进程鉴于单线程的缺点，便有了多线程的方案，单 Reactor 多线程的方案如下。 的Reactor负责接收请求，对于建立连接是需要自己完成的。 而对于具体业务的处理，是通过通知线程池，通知完就可以接着监听事务了。让线程池内的线程去处理具体的业务逻辑。 通知的方式可以是 需要处理的连接的信息发送给线程安全的队列，并使用条件变量通知一个线程，线程池中的一个线程拿到并执行。 每个线程一个线程安全的队列，通过哈希等分配函数进行具体的分配。 聊完单 Reactor 多线程的方案，接着来看看单 Reactor 多进程的方案。 事实上，单 Reactor 多进程相比单 Reactor 多线程实现起来很麻烦，主要因为要考虑子进程 &lt;-&gt; 父进程的双向通信，并且父进程还得知道子进程要将数据发送给哪个客户端。 而多线程间可以共享数据，虽然要额外考虑并发问题，但是这远比进程间通信的复杂度低得多，因此实际应用中也看不到单 Reactor 多进程的模式。 另外，「单 Reactor」的模式还有个问题，因为一个 Reactor 对象承担所有事件的监听和响应，而且只在主线程中运行，在面对瞬间高并发的场景时，容易成为性能的瓶颈的地方。 多 Reactor 多线程 &#x2F; 多进程要解决「单 Reactor」的问题，就是将「单 Reactor」实现成「多 Reactor」，这样就产生了第 多 Reactor 多线程 &#x2F; 进程的方案，架构图如下。 多Reactor实际上就是不同的Reactor承担不同的任务，有用与连接的Reactor，和两个负责业务处理的reactor。 对于连接请求，会在MainReactor处建立连接，连接建立完成则从MainReactor中移除，加入SubReactor，进行实际的业务处理。 大名鼎鼎的两个开源软件 Netty 和 Memcache 都采用了「多 Reactor 多线程」的方案。 采用了「多 Reactor 多进程」方案的开源软件是 Nginx，不过方案与标准的多 Reactor 多进程有些差异。 具体差异表现在主进程中仅仅用来初始化 socket，并没有创建 mainReactor 来 accept 连接，而是由子进程的 Reactor 来 accept 连接，通过锁来控制一次只有一个子进程进行 accept（防止出现惊群现象），子进程 accept 新连接后就放到自己的 Reactor 进行处理，不会再分配给其他子进程。 Proactor前面提到的 Reactor 是非阻塞同步网络模式，而 Proactor 是异步网络模式。 不仅仅数据准备的过程不需要等待，数据从内核拷贝到用户区也不用等待，这些过程都由内核管理。 Proactor模式流程如下 首先用户线程负责初始化Proactor并且创建对应的处理对象。 当有通知时，内核直接调用注册好的回调函数。 可惜的是，在 Linux 下的异步 I&#x2F;O 是不完善的， aio 系列函数是由 POSIX 定义的异步操作接口，不是真正的操作系统级别支持的，而是在用户空间模拟出来的异步，并且仅仅支持基于本地文件的 aio 异步操作，网络编程中的 socket 是不支持的，这也使得基于 Linux 的高性能网络程序都是使用 Reactor 方案。 而 Windows 里实现了一套完整的支持 socket 的异步编程接口，这套接口就是 IOCP，是由操作系统级别实现的异步 I&#x2F;O，真正意义上异步 I&#x2F;O，因此在 Windows 里实现高性能网络程序可以使用效率更高的 Proactor 方案。 API更详细的API介绍见每个函数的man手册。 大小端转换API: n: network 网络 h: host （本地）主机 l: unsigned long s: unsigned short uint32_t htonl(uint32_t hostlong); uint16_t htons(uint16_t hostshort); uint32_t ntohl(uint32_t netlong); uint16_t ntohs(uint16_t netshort); IP地址转换API 计算机认识到的是二进制（转换结果是无符号整型但会被计算机视作二进制），而更具可读性的是点分十进制。 因此存在两者之间的转换。 #include &lt;arpa/inet.h&gt; int inet_aton(const char* cp, struct in_addr* inp); //直接传inp的指针作为结果，返回值表示是否成功。 //（inp实际指向一个struct, struct中仅含一个in_addr_t(即uint32_t) 成员） in_addr_t inet_addr(const char* strptr); //将点分十进制转成二进制（in_addr_in实际上是一个unsigned int） char* inet_ntoa(struct in_addr in); //将网络字节序转化为address(IP字符串)。 //注意该函数返回的char*指向的是内部的静态资源，之前的指针会指向当前转换的结果。即，该函数不可重入。 //以上都是IPv4，以下是根据参数来转换IPv4还是IPv6。 int inet_pton(int af, const char* src, void* dst); const char* inet_ntop(int af, const void* src, char* dst, socklen_t cnt); 注意：由于是转换到网络字节序，因此转换时还存在大小端的转换。 Socket API int socket(int domain, int type, int protocol); //client part int connect(int sockfd, const struct sockaddr* addr, socklen_t addrlen); //server part int bind(int sockfd, const struct sockaddr* addr, socklen_t addrlen); int listen(int sockfd, int backlog); int accept(int sockfd, struct sockaddr* addr, socklen_t addrlen); 数据读写 //TCP part ssize_t recv(int sockfd, void* buf, size_t len, int flags); ssize_t send(int sockfd, const void* buf, size_t len, int flags); //UDP part ssize_t recvfrom(int sockfd, void* buf, size_t len, int flags, const struct sockaddr* src_addr, socklen_t addrlen); ssize_t sendto(int sockfd, const void* buf, size_t len, int flags, const struct sockaddr* dest_addr, socklen_t addrlen); TODO: Out of Band Socket设置 int getsockopt(int sockfd, int level, int optname,void *optval, socklen_t *optlen); int setsockopt(int sockfd, int level, int optname, const void *optval, socklen_t optlen); 相关参数： SO_REUSEADDR; //复用处于Time_Wait阶段的Socket，或者直接修改内核参数/proc/sys/ipv4/tcp_tw_reuse SO_RCVBUF; //设置receive buffer SO_SNDBUF; //设置send buff SO_RCVLOWAT; //缓冲大小到达该阈值才通知可读 SO_SNDLOWAD; //同上，但可写。 SO_LINGER； //控制TCP关闭时的行为。 网络信息API struct hostent *gethostbyname(const char *name); #include &lt;sys/socket.h&gt; /* for AF_INET */ struct hostent *gethostbyaddr(const void *addr, socklen_t len, int type); //可重入版本 int gethostent_r( struct hostent *ret, char *buf, size_t buflen, struct hostent **result, int *h_errnop); int gethostbyaddr_r(const void *addr, socklen_t len, int type, struct hostent *ret, char *buf, size_t buflen, struct hostent **result, int *h_errnop); //如下查询man手册即可。 getservbyname(); getservbyport(); getaddrinfo(); getnameinfo(); 错误信息 char* strerror(int errnum); //将错误码转成字符串。 const char *gai_strerror(int errcode); //getaddrinfo, getnameinfo的错误码转成字符串。 ... 参考 I&#x2F;O 多路复用：select&#x2F;poll&#x2F;epoll 高性能网络模式：Reactor 和 Proactor 《Linux高性能服务器编程》","categories":[{"name":"Linux","slug":"Linux","permalink":"https://messenger1th.github.io/categories/Linux/"}],"tags":[]},{"title":"Virtual Memory","slug":"Linux/Virtual Memory","date":"2024-07-24T14:47:33.989Z","updated":"2024-07-24T14:47:33.989Z","comments":true,"path":"2024/07/24/Linux/Virtual Memory/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Linux/Virtual%20Memory/","excerpt":"","text":"Linux虚拟内存每个用户进程都只能看到虚拟内存，操作虚拟内存。虚拟内存到物理内存的映射任务由操作系统完成。 每个用户进程看到的虚拟内存地址都是连续的，且具有一定布局规则。 每个用户的虚拟内存之间是相互隔离的，相互独立，无法感知其他进程虚拟内存的存在。 虚拟内存采用lazy loading机制，只有真正用到内存，才会将虚拟内存映射到物理内存。 用户空间32位Linux用户空间为3G，64下实际用到48位，为128T，布局类似，只是各段大小不同。 布局 每个段具有不同的作用 代码段：存放可执行的二进制文件，Linux系统下为elf格式的文件。 数据段：存放在代码中指定了初始值的全局变量和静态变量。 BSS段：没有指定初始值的全局变量和静态变量在虚拟内存空间中的存储区域我们叫做 BSS 段。这些未初始化的全局变量被加载进内存之后会被初始化为 0 值。 上面介绍的这些全局变量和静态变量都是在编译期间就确定的，但是我们程序在运行期间往往需要动态的申请内存，所以在虚拟内存空间中也需要一块区域来存放这些动态申请的内存，这块区域就叫做堆。 堆：动态分配空间 文件映射与匿名映射区：存放动态链接库中的代码段、数据段、BSS段以及通过mmap映射的共享内存区。 栈：存放函数的局部变量、函数参数。 描述在Linux下，用户进程用task_struck来描述，其中含有一个mm_struct来描述用户空间，而mm_struct描述整个用户空间，组织如下。 此外，由于各个段之间存在共性，面向对象思想，把各个段用一个vm_area_struct来描述，记录段开始、结束，属性，读写权限，行为规范vm_flags。 各个vm_area_struct按照管理地址从低到高连成双向链表，同时指回mm_struct。mm_struct的mmap指针指向第一个vm_area_struct，组织如下。 此外，为了快速查找，还将每个mm_struct加入到一颗红黑树中，从mm_struct的mm_rb中可以获取到其根节点，组织如下。 内核空间每个用户的虚拟内存空间相互独立，但内核空间是所有进程共享的，不同进程进入内核态看到的虚拟内存空间是一样的。 由于内核会涉及到物理内存的管理，所以很多人会想当然地认为只要进入了内核态就开始使用物理地址了，这就大错特错了，千万不要这样理解，进程进入内核态之后使用的仍然是虚拟内存地址，只不过在内核中使用的虚拟内存地址被限制在了内核态虚拟内存空间范围中。 32位布局直接映射区 虽然这块区域中的虚拟地址是直接映射到物理地址上，但是内核在访问这段区域的时候还是走的直接映射区中的映射关系是一比一映射。映射关系是固定的不会改变。 直接映射区中的映射关系是一比一映射。映射关系是固定的不会改变。 内核代码相关：代码段、数据段、BSS段在这段 896M 大小的物理内存中，前 1M 已经在系统启动的时候被系统占用，1M 之后的物理内存存放的是内核代码段，数据段，BSS 段（这些信息起初存放在 ELF格式的二进制文件中，在系统启动的时候被加载进内存）。 分配使用相关：各类结构描述符当我们使用 fork 系统调用创建进程的时候，内核会创建一系列进程相关的描述符，比如之前提到的进程的核心数据结构 task_struct，进程的内存空间描述符 mm_struct，以及虚拟内存区域描述符 vm_area_struct 等。这些进程相关的数据结构也会存放在物理内存前 896M 的这段区域中，当然也会被直接映射至内核态虚拟内存空间中的 3G – 3G + 896m 这段直接映射区域中。 内核栈：当进程被创建完毕之后，在内核运行的过程中，会涉及内核栈的分配，内核会为每个进程分配一个固定大小的内核栈（一般是64位两个页，32位一个页，依赖具体的体系结构），每个进程的整个调用链必须放在自己的内核栈中，内核栈也是分配在直接映射区。与进程用户空间中的栈不同的是，内核栈容量小而且是固定的，用户空间中的栈容量大而且可以动态扩展。内核栈的溢出危害非常巨大，它会直接悄无声息的覆盖相邻内存区域中的数据，破坏数据。 我们知道32位Linux物理内存分为ZONE_DMA、ZONE_NORMAL、ZONE_HIGHEM区域。而ZONE_DMA是0～16MB，而ZONE_NORMAL是16MB～896MB。即ZONE_DMA和ZONE_NORMAL都是直接映射区。 而剩下的内存都是ZONE_HIGHEM区，称为高端内存，由于32位下虚拟内存中内核空间仅仅为1GB，就剩下128M的内核虚拟空间，无法直接映射，只能是动态的一部分一部分的分批映射，先映射正在使用的这部分，使用完毕解除映射，接着映射其他部分。 内核虚拟内存空间中的 3G + 896M 这块地址在内核中定义为 high_memory，high_memory 往上有一段 8M 大小的内存空洞。空洞范围为：high_memory 到 VMALLOC_START 。 动态映射区：vmalloc接下来 VMALLOC_START 到 VMALLOC_END 之间的这块区域成为动态映射区。采用动态映射的方式映射物理内存中的高端内存。 和用户态进程使用 malloc 申请内存一样，在这块动态映射区内核是使用 vmalloc 进行内存分配。由于之前介绍的动态映射的原因，vmalloc 分配的内存在虚拟内存上是连续的，但是物理内存是不连续的。通过页表来建立物理内存与虚拟内存之间的映射关系，从而可以将不连续的物理内存映射到连续的虚拟内存上。 由于 vmalloc 获得的物理内存页是不连续的，因此它只能将这些物理内存页一个一个地进行映射，在性能开销上会比直接映射大得多。因此内核用的更多的是kmalloc直接映射。 永久映射区 PKMAP_BASE 到 FIXADDR_START 之间的这段空间称为永久映射区。在内核的这段虚拟地址空间中允许建立与物理高端内存的长期映射关系。比如内核通过 alloc_pages() 函数在物理内存的高端内存中申请获取到的物理内存页，这些物理内存页可以通过调用 kmap 映射到永久映射区中。 固定映射区内核虚拟内存空间中的下一个区域为固定映射区，区域范围为：FIXADDR_START 到 FIXADDR_TOP。 在固定映射区中的虚拟内存地址可以自由映射到物理内存的高端地址上，但是与动态映射区以及永久映射区不同的是，在固定映射区中虚拟地址是固定的，而被映射的物理地址是可以改变的。也就是说，有些虚拟地址在编译的时候就固定下来了，是在内核启动过程中被确定的，而这些虚拟地址对应的物理地址不是固定的。采用固定虚拟地址的好处是它相当于一个指针常量（常量的值在编译时确定），指向物理地址，如果虚拟地址不固定，则相当于一个指针变量。 那为什么会有固定映射这个概念呢 ? 比如：在内核的启动过程中，有些模块需要使用虚拟内存并映射到指定的物理地址上，而且这些模块也没有办法等待完整的内存管理模块初始化之后再进行地址映射。因此，内核固定分配了一些虚拟地址，这些地址有固定的用途，使用该地址的模块在初始化的时候，将这些固定分配的虚拟地址映射到指定的物理地址上去。 临时映射区主要用于数据拷贝。 64位布局由于64位虚拟内存空间足够的大，即便是内核要访问全部的物理内存，直接映射就可以了，不在需要用到ZONE_HIGHMEM 高端内存那样的动态映射方式。 64位和32位各段作用的大差不差，布局相似，不在赘述，布局如下。 整体布局32位 64位 加载ELF磁盘文件进程新创建时会把磁盘中的elf二进制文件的内容加载到内存。 elf文件中的 .text，.rodata 等一些只读的 Section，会被映射到内存的一个只读可执行的 Segment 里（代码段）。而 .data，.bss 等一些可读写的 Section，则会被映射到内存的一个具有读写权限的 Segment 里（数据段，BSS 段）。 Linux内核完成这个映射过程的函数是 load_elf_binary。 寻址寻址就是将虚拟内存转化为物理内存的过程。 Linux下有多级寻址：三四五级。 三级寻址：PGD（Page Global Directory）、PMD（Page Middle Directory）、PT（Page Table）。 四级寻址：PGD、PUD（Page Upper Directory）、PMD、PT。 五级寻址：PGD、P4D、PUD、PMD、PT。 每一级的寻址表除了提供寻址功能外，还有控制读写权限等页面所具有的功能，如果提前发现权限不足即可提前退出。 寻址需要借助硬件来完成，软件作为驱动，在硬件层面完成多级寻址的硬件模块叫做MMU。 通常是四级寻址，每一级用到9个二进制位，共$2^{36}$，而每一页是4Kb也就是$2^{12}$，即$2^{48}$的虚拟内存空间，如下图。 TLB由上述寻址过程不难发现，寻址是一个耗时的过程，也有了缓存机制， CPU 芯片中，加入了一个专门存放程序最常访问的页表项的 Cache，这个 Cache 我们称为TLB（Translation lookaside buffer）。TLB也由MMU访问。 同样的，TLB除了存储具体页面体数据外，还存有相关的权限信息。 malloc内存管理ptmalloc是glibc默认的内存管理器。我们常用的malloc和free就是由ptmalloc内存管理器提供的基础内存分配函数。这块主要讲的是ptmalloc分配的原理。 glic库也是操作系统之上的，因此底层还是调用的操作系统的接口，所以malloc&#x2F;free也是分配&#x2F;释放虚拟内存。 因为系统调用需要从用户态陷入内核态的缘故， 不是每调用一次malloc&#x2F;free都调用一次系统调用，C库对向操作系统申请来的虚拟内存进行一定的管理，来减少系统调用。 malloc 分配内存 &lt; DEFAULT_MMAP_THRESHOLD，走__brk，从内存池获取，失败的话走brk系统调用 分配内存 &gt; DEFAULT_MMAP_THRESHOLD，走__mmap，直接调用mmap系统调用 其中，DEFAULT_MMAP_THRESHOLD默认为128k，可通过mallopt进行设置。 free malloc 通过 brk() 方式申请的内存，free 释放内存的时候，并不会把内存归还给操作系统，而是缓存在 malloc 的内存池中，待下次使用； malloc 通过 mmap() 方式申请的内存，free 释放内存的时候，会把内存归还给操作系统，内存得到真正的释放。 我们重点关注内存池。 内存池数据结构Bins：管理空闲内存 fast bins：管理小块内存 unsorted bin small bins large bins malloc分配流程 获取分配区的锁，防止多线程冲突。 计算出需要分配的内存的chunk实际大小。 判断chunk的大小，如果小于max_fast（64b），则取fast bins上去查询是否有适合的chunk，如果有则分配结束。 chunk大小是否小于512B，如果是，则从small bins上去查找chunk，如果有合适的，则分配结束。 继续从 unsorted bins上查找。如果unsorted bins上只有一个chunk并且大于待分配的chunk，则进行切割，并且剩余的chunk继续扔回unsorted bins；如果unsorted bins上有大小和待分配chunk相等的，则返回，并从unsorted bins删除；如果unsorted bins中的某一chunk大小 属于small bins的范围，则放入small bins的头部；如果unsorted bins中的某一chunk大小 属于large bins的范围，则找到合适的位置放入。 从large bins中查找，找到链表头后，反向遍历此链表，直到找到第一个大小 大于待分配的chunk，然后进行切割，如果有余下的，则放入unsorted bin中去，分配则结束。 如果搜索fast bins和bins都没有找到合适的chunk，那么就需要操作top chunk来进行分配了（top chunk相当于分配区的剩余内存空间）。判断top chunk大小是否满足所需chunk的大小，如果是，则从top chunk中分出一块来。 如果top chunk也不能满足需求，则需要扩大top chunk。主分区上，如果分配的内存小于分配阀值（默认128k），则直接使用brk()分配一块内存；如果分配的内存大于分配阀值，则需要mmap来分配；非主分区上，则直接使用mmap来分配一块内存。通过mmap分配的内存，就会放入mmap chunk上，mmap chunk上的内存会直接回收给操作系统。 unsorted清除时机（放到samll bin或者large bin上）：fast bin 和 small bin， unsorted 都没查找到合适大小。 free释放流程 获取分配区的锁，保证线程安全。 如果free的是空指针，则返回，什么都不做。 判断当前chunk是否是mmap映射区域映射的内存，如果是，则直接munmap()释放这块内存。前面的已使用chunk的数据结构中，我们可以看到有M来标识是否是mmap映射的内存。 判断chunk是否与top chunk相邻，如果相邻，则直接和top chunk合并（和top chunk相邻相当于和分配区中的空闲内存块相邻）。转到步骤8 如果chunk的大小大于max_fast（64b），则放入unsorted bin，并且检查是否有合并，有合并情况并且和top chunk相邻，则转到步骤8；没有合并情况则free。 如果chunk的大小小于 max_fast（64b），则直接放入fast bin，fast bin并没有改变chunk的状态。没有合并情况，则free；有合并情况，转到步骤7 在fast bin，如果当前chunk的下一个chunk也是空闲的，则将这两个chunk合并，放入unsorted bin上面。合并后的大小如果大于64KB，会触发进行fast bins的合并操作，fast bins中的chunk将被遍历，并与相邻的空闲chunk进行合并，合并后的chunk会被放到unsorted bin中，fast bin会变为空。合并后的chunk和topchunk相邻，则会合并到topchunk中。转到步骤8 判断top chunk的大小是否大于mmap收缩阈值（默认为128KB），如果是的话，对于主分配区，则会试图归还top chunk中的一部分给操作系统。free结束。 参考资料 《深入Linux内核架构与底层原理》第七章 内存管理 《Linux内核设计与实现》第十二章 内存管理 《程序员的自我修养——链接、装载与库》 4.1 为什么要有内存管理 4.2 malloc是怎样分配内存的 4.6 深入理解Linux虚拟内存 glibc内存管理那些事儿 内存管理器ptmalloc glibc内存管理ptmalloc源码分析 问题页表的存放在哪里？内核里头？用户虚拟内存里头？具体在哪里段？页表存放在内核空间，每个进程拥有独立的页表，进程页表基地址的物理地址存放在mm_struct-&gt;pgd里。 当前正在处理的任务的页表根目录物理地址通常放在一个页表基址寄存器PTBR（page table base register ）中，比如X86_64的CR3寄存器。 上下文切换时，就会切换这个寄存器的值。从新进程的task_struct中的mm_struct中pgd的值读到CR3寄存器。 什么情况下需要遍历VMA链表？在查看进程内存情况的时候，采用遍历该链表比在红黑树一个一个查找来的快。当然可能还有其他应用场景。由于版本的不同，该链表可能是双向链表也可能是单向链表甚至可能没有。笔者在查看源码的时候，2.6版本存在该双向链表，但最新版本看不到prev和next指针了，可能是修改了架构也可能是移除了。 brk和mmap虚拟内存申请原理brk仅仅移动brk指针。 mmap首先判断是匿名映射（即申请虚拟内存）还是文件映射，判断空间是否足够、清楚旧的映射、校验内存可用性。都满足的话，创建出一块vm_area_struct并插入到红黑树进行管理。 以上都是分配虚拟内存，真正用到内存时才会发生缺页中断，建立虚拟内存到物理内存的映射。 TODO 反向映射 TLB淘汰策略 换入换出 缺页异常的处理","categories":[{"name":"Linux","slug":"Linux","permalink":"https://messenger1th.github.io/categories/Linux/"}],"tags":[]},{"title":"Slub","slug":"Linux/Slub","date":"2024-07-24T14:47:33.986Z","updated":"2024-07-24T14:47:33.986Z","comments":true,"path":"2024/07/24/Linux/Slub/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Linux/Slub/","excerpt":"","text":"SlubSlab是基于Buddy的分配器，也就是首先向Buddy分配对应的大内存，对这块内存进行管理，从而避免内部碎片。 具体的，Slab向Buddy申请特地大小的内存，这块内存的大小要求能被结构体大小整除，即正好能放下完整的对象，不会存在内部碎片。 Slab策略看起来像池的思想，但由于对象类型很多，不可能每个都分配一个池，Slab可以看成一个通用的拟内存池机制。 一个Slab包含一个或多个连续的物理页面，然后将这些页面均分成固定的大小的各等份，每一等份就是一个对象，各对象通过链表串起来。有关slab 的信息封装在 page 中，对应的字段如下 /* file: include/linux/mm_types.h */ struct page &#123; union &#123; struct &#123; /* slab, slob and slub */ union &#123; /* slab 列表，slab 可能在 partial */ struct list_head slab_list; struct &#123; /* Partial pages */ struct page *next; #ifdef CONFIG_64BIT int pages; /* Nr of pages left */ int pobjects; /* Approximate count */ #else short int pages; short int pobjects; #endif &#125;; &#125;; /* 使用该页作为 slab 的 kmem_cache, 通过文件 slub.c 中的函数 allocate_slab() 设置 */ struct kmem_cache *slab_cache; /* not slob */ /* 当页面用于 slab 缓存时，slab 的首页对应的 page 的该字段会指向整个 slab 的空闲对象列表。 * 但当 slab 当前正在被 kmem_cache_cpu 使用时，page 的该字段会设置为 NULL, 而 kmem_cache_cpu 中的 freelist 字段会指向 slab 的空闲对象列表 */ void *freelist; /* first free object */ union &#123; void *s_mem; /* slab: first object */ /* 因为 counters 与下面包含 inuse, objects, frozen 字段的结构体是 union 关系，所以很多时候需要新建 page 然后对后面三个字段赋值时，直接将 counters 的值付过去就 OK 了 */ unsigned long counters; /* SLUB */ struct &#123; /* SLUB */ /* 记录被使用的对象，但是初始值与 objects 相同 */ unsigned inuse : 16; /* 记录 slab 中包含 object 的总数，即为 kmem_cache 中 kmem_cache_order_objects 中低 15 位表示的值。该值在 slub.c 中的函数 allocate_slab 中设置 */ unsigned objects : 15; /* 标记该 slab 是否被某个 cpu “锁定”，如果处于 frozen 状态，那么只有对应的CPU 能够从该slab中分配对象，其他CPU 只能往该页面释放对象。初始值设置为 1 */ unsigned frozen : 1; &#125;; &#125;; &#125;; &#125; _struct_page_alignment; 如果页面被分配用于 slab, 那么这些字段就会被设置。其中 kmem_cache 与注释中提到的 kmem_cache_cpu 等是重点关注的结构。 Slub接口及使用struct kmem_cache *kmem_cache_create(const char *name, //kmem_cache的名称 size_t size, //slab管理对象的大小 size_t align, //slab分配器分配内存的对齐字节数(以align字节对齐) unsigned long flags, //分配内存掩码，实际会调用到buddy处执行。 void (*ctor)(void *)); //分配对象的构造回调函数 void kmem_cache_destroy(struct kmem_cache *); //销毁该cache void *kmem_cache_alloc(struct kmem_cache *cachep, int flags); //从该cache分配一块对象 void kmem_cache_free(struct kmem_cache *cachep, void *objp); //从该cache回收指定对象 使用步骤如下 mem_cache_create创建一个kmem_cache数据结构。 使用kmem_cache_alloc接口分配内存给buf 使用buf kmem_cache_free接口释放buf。 release第一步创建的kmem_cache数据结构。 代码如下 /* * This is a demo for how to use kmem_cache_create */ void slab_demo(void) &#123; /*1. create kmem_cache. */ struct kmem_cache *kmem_cache_16 = kmem_cache_create(&quot;kmem_cache_16&quot;, 16, 8, ARCH_KMALLOC_FLAGS, NULL); /*2. now you can alloc memory, the buf points to 16 bytes of memory*/ char *buf = kmeme_cache_alloc(kmem_cache_16, GFP_KERNEL); /*3. use buf...*/ /*4. and 5. don&#x27;t forget to release the memory after use */ kmem_cache_free(kmem_cache_16, buf); kmem_cache_destroy(kmem_cache_16); &#125; 创建slab内核创建一个slab的逻辑也很直观：首先向Buddy System申请一定数量的连续页面，然后初始化对象并构建好对象列表。代码如下 /* file: mm/slub.c */ static struct page *allocate_slab(struct kmem_cache *s, gfp_t flags, int node) &#123; struct page *page; /* 结构 kmem_cache_order_objects 中记录着一个 slab 应该申请的页面数量与总的对象数量，两个量封装在一个字段 unsigned int x 中，其中低16位表示对象总数，高位表示连续页面的阶，即需要分配2^(oo.x &gt;&gt; 16)个连续页面 */ struct kmem_cache_order_objects oo = s-&gt;oo; /* 传给Buddy System的各类Flag, 这里我们删掉了对该参数的初始化逻辑 */ gfp_t alloc_gfp; /* 初始化对象列表时使用的指针变量 */ void *start, *p, *next; int idx; bool shuffle; /* 分配连续 2^(oo.x&gt;&gt;OO_SHIFT) 个连续页面，其中 OO_SHIFT 为 16 */ page = alloc_slab_page(s, alloc_gfp, node, oo); if (unlikely(!page)) &#123; /* 如果 buddy system 没有足够的连续物理页，则减少 oo 的数值再尝试一次 */ oo = s-&gt;min; alloc_gfp = flags; page = alloc_slab_page(s, alloc_gfp, node, oo); /* s-&gt;min 是实例化一个 slab 所需要的最小的内存页数量，如果依旧无法满足的话就直接退出了 */ if (unlikely(!page)) goto out; stat(s, ORDER_FALLBACK); &#125; /* oo.x 的低 15 位表示该 slab 中可以存放的 object 总数 */ /* 函数oo_objects 就是取出 oo.x 的低16位的数字，即 oo.x&amp;(1&lt;&lt;16 -1) 的值*/ page-&gt;objects = oo_objects(oo); /* 将 kmem_cache 记录到第一个内存页中，kmem_cache 在下一节介绍 */ page-&gt;slab_cache = s; /* 设置 page 的标记位，标记该页面用于 slab */ __SetPageSlab(page); start = page_address(page); shuffle = shuffle_freelist(s, page); /* if block 中构建对象列表 */ if (!shuffle) &#123; /* 初始化第一个对象，因为 for 循环中处理的都是下一个对象 */ start = fixup_red_left(s, start); /* 如果为 slab 配置了对象的初始化函数，则会在函数 setup_object 调用，对每个对象进行初始化 */ start = setup_object(s, page, start); /* slab 中空闲对象列表的地址为第一个对象 */ page-&gt;freelist = start; /* 初始化 slab 中的空闲对象列表 */ for (idx = 0, p = start; idx &lt; page-&gt;objects - 1; idx++) &#123; /* s-&gt;size 表示每个对象的大小，这里计算出下一个对象的地址 */ next = p + s-&gt;size; /* 初始化下一个对象 */ next = setup_object(s, page, next); /* 建立空闲对象列表的单链表，其中 p 为当前对象，next 为下一个对象，将 next 的地址写入 p+s.offset 位置处 */ set_freepointer(s, p, next); p = next; &#125; /* 链表最后一个元素的next属性指向 NULL */ set_freepointer(s, p, NULL); &#125; page-&gt;inuse = page-&gt;objects; page-&gt;frozen = 1; out: if (!page) return NULL; return page; &#125; Slab管理空闲对象前文中我们提到过slab中的对象就是一个固定大小的连续内存块，通过对象列表的构建逻辑我们可以对此有更深刻的理解，内核并没有单独定义一个结构体来封装对象信息，在构建对象列表时，指向下一个空闲对象的指针也是直接存放在该对象的内存地址内部，因为对象还没有被分配出去时内存是不会被使用的，而被分配之后也不需要该指针了，这是一个比较精巧的设计。 页面的freelist 总是指向slab 中第一个空闲对象，也是 slab 分配与释放对象的入口点。 首先一个slab缓存池包含的页数是由oo决定的。oo拆分为两部分，低16位代表一个slab缓存池中object的数量，高16位代表包含的页数。使用kmem_cache_create()接口创建kmem_cache的时候需要指出obj的size和对齐align。也就是传入的参数。kmem_cache_create()主要是就是填充kmem_cache结构体成员。既然从伙伴系统得到(2^(oo &gt;&gt; 16)) pages大小内存，按照size大小进行平分。一般来说都不会整除，因此剩下的就是图中灰色所示。由于每一个object的大小至少8字节，当然可以用来存储下一个object的首地址。就像图中所示的，形成单链表。图中所示下个obj地址存放的位置位于每个obj首地址处，在内核中称作指针内置式。同时，下个obj地址存放的位置和obj首地址之间的偏移存储在kmem_cache的offset成员。两外一种方式是指针外置式，即下个obj的首地址存储的位置位于obj尾部，也就是在obj尾部再分配sizeof(void *)字节大小的内存。对于外置式则offset就等于kmem_cache的inuse成员。 整体组织我们把每次向Buddy申请的那块内存，称为slab。每个slab的第一个页面会存储本slab的管理信息。页面内的对象以链表组织。页面与页面之间以单链表组织。 不同slab大小由不同的kmem_cache管理。每种kmem_cache的名称、大小等属性有所不同，但管理方式一致。 CPU一般是多核心的，为了减少锁的开小，为每一个CPU核心都创建一个缓存。整体组织如下 所有的、不同大小的 kmem_cache 保留在全局变量 kmalloc_caches 中。由slub的接口可知，具体请求哪一个kmem_cache内的对象，是由内核开发者函数传参决定的。 per cpu freelist针对每一个cpu都会分配一个struct kmem_cache_cpu的结构体。可以称作是本地缓存池。当内存申请的时候，优先从本地cpu缓存池申请。在分配初期，本地缓存池为空，自然要从伙伴系统分配一定页数的内存。内核会为每一个物理页帧创建一个struct page的结构体。kmem_cacche_cpu中page就会指向正在使用的slab的页帧。freelist成员指向第一个可用内存obj首地址。处于正在使用的slab的struct page结构体中的freelist会置成NULL，因为没有其他地方使用。struct page结构体中inuse代表已经使用的obj数量。full slab就像无人看管的孩子，没有任何链表来管理。释放完全由内核开发者手动。 per cpu partial当full slab释放obj的时候，首先就会将slab挂入per cpu partial链表管理。通过struct page中next成员形成单链表。per cpu partial链表指向的第一个page中会存放一些特殊的数据。例如：pobjects存储着per cpu partial链表中所有slab可供分配obj的总数，如图所示。当然还有一个图中没有体现的pages成员存储per cpu partial链表中所有slab缓存池的个数。pobjects到底有什么用呢？我们从full slab中释放一个obj就添加到per cpu partial链表，总不能无限制的添加吧！因此，每次添加的时候都会判断当前的pobjects是否大于kmem_cache的cpu_partial成员，如果大于，那么就会将此时per cpu partial链表中所有的slab移送到kmem_cache_node的partial链表，然后再将刚刚释放obj的slab插入到per cpu partial链表。如果不大于，则更新pobjects和pages成员，并将slab插入到per cpu partial链表。 per node partialper node partia链表类似per cpu partial，区别是node中的slab是所有cpu共享的，而per cpu是每个cpu独占的。假如现在的slab布局如上图所示。假如现在如红色箭头指向的obj将会释放，那么就是一个empty slab，此时判断kmem_cache_node的nr_partial是否大于kmem_cache的min_partial，如果大于则会释放该slab的内存。 Slub内存分配流程由创建cache的流程，不难发现cache会记录对象大小和构造函数。 struct kmem_cache *kmem_cache_create(const char *name, //kmem_cache的名称 size_t size, //slab管理对象的大小 size_t align, //slab分配器分配内存的对齐字节数(以align字节对齐) unsigned long flags, //分配内存掩码，实际会调用到buddy处执行。 void (*ctor)(void *)); //分配对象的构造回调函数 创建时，仅仅需要传递kmem_cache和标志信息flags。 void *kmem_cache_alloc(struct kmem_cache *cachep, int flags); //从该cache分配一块对象 深入原理，分配顺序是 cpu的freelist cpu的partial 各核心共享的node 首先从cpu 本地缓存池分配，如果freelist不存在，就会转向per cpu partial分配，如果per cpu partial也没有可用对象，继续查看per node partial，如果很不幸也不没有可用对象的话，就只能从伙伴系统分配一个slab了，并挂入per cpu freelist。 流程图如下 我们详细看一下这几种情况。 kmem_cache刚刚建立，还没有任何对象可供分配，此时只能从伙伴系统分配一个slab，如下图所示。 如果正在使用的slab有free obj，那么就直接分配即可，这种是最简单快捷的。如下图所示。 随着正在使用的slab中obj的一个个分配出去，最终会无obj可分配，此时per cpu partial链表中有可用slab用于分配，那么就会从per cpu partial链表中取下一个slab用于分配obj。如下图所示。 随着正在使用的slab中obj的一个个分配出去，最终会无obj可分配，此时per cpu partial链表也为空，此时发现per node partial链表中有可用slab用于分配，那么就会从per node partial链表中取下一个slab用于分配obj。如下图所示。 走到这一步，说明node_partial也没有可用对象，就只能从伙伴系统分配一个slab了。 Slub内存释放流程通过void kmem_cache_free()回收指定对象，具体签名如下 void kmem_cache_free(struct kmem_cache *cachep, void *objp); //从该cache回收指定对象 释放流程图如下 如果释放的obj就是属于正在使用cpu上的slab，那么直接释放即可，非常简单；如果不是的话，首先判断所属slub是不是full状态，因为full slab是没妈的孩子，释放之后就变成partial empty，急需要找个链表领养啊！这个妈就是per cpu partial链表。如果per cpu partial链表管理的所有slab的free object数量超过kmem_cache的cpu_partial成员的话，就需要将per cpu partial链表管理的所有slab移动到per node partial链表管理；如果不是full slab的话，继续判断释放当前obj后的slab是否是empty slab，如果是empty slab，那么在满足kmem_cache_node的nr_partial大于kmem_cache的min_partial的情况下，则会释放该slab的内存。其他情况就直接释放即可。 即，min_cpu_partial保证CPU有一定数量的缓存对象，而min_partial保证node有一定数量的缓存对象。 具体情况分析如下 释放该对象后，整个slab都空闲，则回收整个slab；释放完该对象，所属slab不全空闲，则移动该对象到空闲链表，如下图。 假设下图左边的情况下释放obj，如果满足kmem_cache_node的nr_partial大于kmem_cache的min_partial的话，释放情况如下图所示。 假设下图左边的情况下释放obj，如果不满足kmem_cache_node的nr_partial大于kmem_cache的min_partial的话，释放情况如下图所示。即min_partial保证该kmem_cache有最低数量的slab。 假设下图从full slab释放obj的话，如果满足per cpu partial管理的所有slab的free object数量大于kmem_cache的cpu_partial成员的话的话，将per cpu partial链表管理的所有slab移动到per node partial链表管理，释放情况如下图所示。 假设下图从full slab释放obj的话，如果不满足per cpu partial管理的所有slab的free object数量大于kmem_cache的cpu_partial成员的话的话，释放情况如下图所示。 kmalloc和vmalloc看起来Slab只能分配固定大小的的内存，实际上，Linux的Slab实现了kmalloc和vmalloc，可以提供不同大小的可分配内存。 kmalloc、vmalloc对于常用的大小，创建了对应大小的的高速缓存组，部分如下。分配时找到第一个大于等于请求值的那个缓存组分配即可。 kmalloc和vmalloc接口void * kmalloc(size_t size, gfp_t flags); void * vmalloc(unsigned long size); void kfree(const void* ptr); void vfree(const void* addr); kmallo和vmalloc具体实现原理就在是创建多个不同大小的kmem_cache，可以通过cat /proc/slabinfo查看所有的kmem_cache，其中含kmalloc就是用于分配不固定大小的内存。 root:/ # cat /proc/slabinfo | grep &quot;kmalloc&quot; kmalloc-8k 407 416 8192 4 8 : tunables 0 0 0 : slabdata 104 104 0 kmalloc-4k 3189 3256 4096 8 8 : tunables 0 0 0 : slabdata 407 407 0 kmalloc-2k 2647 2800 2048 16 8 : tunables 0 0 0 : slabdata 175 175 0 kmalloc-1k 4177 4256 1024 32 8 : tunables 0 0 0 : slabdata 133 133 0 kmalloc-512 22044 55360 512 32 4 : tunables 0 0 0 : slabdata 1730 1730 0 kmalloc-256 20964 23168 256 32 2 : tunables 0 0 0 : slabdata 724 724 0 kmalloc-192 20440 22638 192 21 1 : tunables 0 0 0 : slabdata 1078 1078 0 kmalloc-128 3427 4192 128 32 1 : tunables 0 0 0 : slabdata 131 131 0 kmalloc-96 5628 5628 96 42 1 : tunables 0 0 0 : slabdata 134 134 0 kmalloc-64 26512 27584 64 64 1 : tunables 0 0 0 : slabdata 431 431 0 kmalloc-32 60345 61568 32 128 1 : tunables 0 0 0 : slabdata 481 481 0 kmalloc-16 24109 27136 16 256 1 : tunables 0 0 0 : slabdata 106 106 0 kmalloc-8 12800 12800 8 512 1 : tunables 0 0 0 : slabdata 25 25 0 假如通过kmalloc(17, GFP_KERNEL)申请内存，系统会从名称“kmalloc-32”管理的slab缓存池中分配一个对象。即使浪费了15Byte。 通过slab接口分配的最大内存是8192 bytes。那么通过kmalloc接口申请的内存大于8192 bytes该怎么办呢？ 其实kmalloc会判断申请的内存是否大于8192 bytes，如果大于的话就会通过伙伴系统的alloc_pages接口申请内存。 kmalloc和vmalloc区别kmalloc分配的内存是物理连续的，而vmalloc是不一定是物理连续的。当然它们都是逻辑连续的。 vmalloc通过分配非连续的物理内存块，再修正页表，实现逻辑连续。由于需要建立页表项，同时一个一个地进行映射，导致分配慢、TLB抖动，都会影响效率。因此，内核在不得已才使用，如分配大块内存的情况下，比如加载模块。 参考 图解slub slub分配器 3.2.5 SLAB&#x2F;SLUB&#x2F;SLOB","categories":[{"name":"Linux","slug":"Linux","permalink":"https://messenger1th.github.io/categories/Linux/"}],"tags":[]},{"title":"Process","slug":"Linux/Process","date":"2024-07-24T14:47:33.983Z","updated":"2024-07-24T14:47:33.983Z","comments":true,"path":"2024/07/24/Linux/Process/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Linux/Process/","excerpt":"","text":"Linux进程进程状态进程创建进程创建可以通过3个函数 fork：拷贝当前进程，创建出一个子进程。 vfork：类似fork，但不复制父进程的页表项。但由于copy on write技术的出现，这个函数的相对于fork的优势越来越小。 clone：最基本的函数，根据各种标志位指定父子进程需要共享的资源，比如虚拟内存。共享虚拟内存的话就是常说的线程。 实际上，fork和vfork的实现都是调用的clone，并指定特定的标志指定父子进程需要共享的资源。 clone函数的核心是do_fork函数，该函数执行流程如下。 其中，copy_process函数为进程创建一个内核栈、thread_info结构和task_struct结构，根据传递给clone的参数，拷贝对应的资源。 创建新程序问题来了，这三个函数只能拷贝父进程，运行的代码都是一样的，那怎么创建别的程序呢？ execve()函数可以读取其他可执行文件，并加载到内存运行。此外，还有execve()的封装函数execlp(), execle(),execv(),execvp()，exec()。我们称为exec函数族。 那么创建新进程的就只需要调用fork&#x2F;vfork&#x2F;clone之后再调用exec函数即可。 Shell上调用其他命令就是这样实现的。 首先使用fork创建出一个子进程，然后子进程调用exec执行其他进程。 如果有重定向号&gt;则在exec前关闭标准输出，打开新文件的描述符。 Copy On WriteCopy On Write顾名思义仅在写的时候才会复制出一个副本，也是属于懒加载的技术。 fork之后再exec的频率是很高的，复制的页表项相当于白白复制了，所以之前vfork就比fork要高效。 但出现了copy on write技术后，页表项仅仅在需要修改时才会复制，vfork就和fork一样了，基本上很少用了。 Linux的线程Linux下的进程和线程没有本质区别，都是由task_struct描述，由clone产生，本质只是是否共享内存。通过下面这句即可创建线程。 clone(CLONE_VM | CLONE_FS | CLONE_FILES | CLONE_SIGHAND, 0) 进程结束根据创建进程的过程不难发现，新进程都会有一个父进程。子进程需要结束时，首先做一些能做的操作，但自己总不能回收自己吧，就留下一些资源等待父进程调用wait回收。 Linux的第一个进程就是init进程，其他进程都是其后代，在一定情况下负责后代的回收。 一般来说，进程结束发生在调用exit()时候，既可能是程序手动调用，也可能是隐形式地被添加这个调用。（C语言编译器在main()的返回点后面放置调用exit()的代码）。也能是接受到无法处理且无法忽略的信号，被动终止。 不管怎么终结，都会调用do_exit()。之后，它占有的内存就只有内核栈，thread_info和task_struct了。 然后父进程调用wait()，就完成了子进程的回收。 过程 子进程终止，调用do_exit(). 父进程调用wait()，挂起自己，并等待自己的一个子进程的状态改变。 可能出现的问题孤儿进程孤儿（orphan）进程是指父进程先退出但自己还未退出的子进程 如果父进程先退出，未wait子进程，子进程do_exit()会查找新的父进程。如果现场组内没有其他进程，则该回收任务交由init进程执行，其pid为1。init进程例行调用wait()检查子进程。 僵尸进程僵尸（zombie）进程是已经退出但未经过wait的子进程。 unix提供了一种机制可以保证只要父进程想知道子进程结束时的状态信息。 这种机制就是: 在do_exit释放大部分资源后，仍然为其保留一定的信息(内核栈，thread_info和task_struct)。直到父进程通过wait &#x2F; waitpid来取时才释放。 但这样就导致了问题，如果进程不调用wait &#x2F; waitpid的话， 那么保留的那段信息就不会释放，其进程号就会一直被占用，但是系统所能使用的进程号是有限的，如果大量的产生僵死进程，将因为没有可用的进程号而导致系统不能产生新的进程. 此即为僵尸进程的危害，应当避免。 可以通过以下方式解决 kill父进程，使子进程成为孤儿进程。 父进程重写信号处理函数，接收到信号就wait子进程。 fork两次，中间的进程直接退出。孙子进程成为孤儿进程。 进程调度核心概念调度实体为了简化调度器模型，内核单独抽象出了一个概念叫“调度实体”，用来封装调度对象， struct task_struct 与调度实体相关的字段包括： /* file: include/linux/sched.h */ struct task_struct &#123; /* 调度实体，调度器的调度对象，该字段用于 CFS */ struct sched_entity se; /* 该字段用于 RT 调度器 */ struct sched_rt_entity rt; #ifdef CONFIG_CGROUP_SCHED struct task_group *sched_task_group; #endif /* 该字段用于 DL 调度器 */ struct sched_dl_entity dl; &#125; 三个表示调度实体的字段 se, rt, dl 分别用于不同的调度策略。 调度类Linux 在 2.6 版本中引入了“调度类（Sched Class）”的概念，意在将调度逻辑模块化，内核通过 struct sched_class 抽象出了调度类的通用行为。这个结构体基本都是函数声明，这对于有 OO 编程经验的同学而言是很熟悉的： struct sched_class 实际上定义了一个接口（Interface），而各个调度类来负责具体的实现。 Linux 总共实现了5种调度类，按照优先级有高到底排序依次为： stop_sched_class Stop 是特殊的调度类，内核使用该调度类来停止 CPU. 该调度类用来强行停止CPU 上的其他任务，由于该调度类的优先级最高，因此一旦生效就将抢占任何当前正在运行的任务，并且在运行过程中自己不会被抢占。 该调度类只有在SMP架构的系统中存在，内核使用该调度类来完成负载均衡与CPU热插拔等工作。 dl_sched_class 有些任务必须在指定时间窗口内完成。例如视频的编码与解码，CPU 必须以特定频率完成对应的数据处理； 这类任务是优先级最高的用户任务，CPU 应该首先满足。 Deadline 调度类用来调度这类任务，dl 便是单词 Deadline 的缩写，因此该调度类的优先级仅仅低于 Stop 调度类。 rt_sched_class 实时任务（Real-time Task）对响应时间要求更高，例如编辑器软件，它可能由于等待用户输入长期处于睡眠之中，但一旦用户有输入动作，我们就期望编辑器能够立马响应，而不是等系统完成其它任务之后才开始反应，这一点对用户体验十分重要。 RT 调度类用来调度这类任务，该调度类的优先级低于 DL. fair_sched_class Fair 调度类用来调度绝大多数用户任务，CFS 实现的就是这种调度类，其核心逻辑是根据任务的优先级公平地分配 CPU 时间。我们会在后续章节中详细讨论 CFS 的实现细节。 idle_sched_class 与 Stop 类似，Idle 调度类也是仅供内核使用的特殊调度类，其优先级最低，只有在没有任何用户任务时才会用到。内核会为每个 CPU 绑定一个内核线程（kthread）来完成该任务，该线程会在队列无事可做的情况下启动该任务，并将 CPU 的功耗降到最低。 我们说调度类有优先级，具体怎么体现呢？ 每一个CPU的rq在选择下一个进程来运行，要调用pick_next_task()，该函数的定义如下 static inline struct task_struct * pick_next_task(struct rq *rq, struct task_struct *prev, struct rq_flags *rf) &#123; const struct sched_class *class; struct task_struct *p; for_each_class(class) &#123; p = class-&gt;pick_next_task(rq); if (p) return p; &#125; /* The idle class should always have a runnable task: */ BUG(); &#125; 从上述代码不难发现，对调度类的遍历通过宏 for_each_class 完成。而该宏展开的之后，各调度类的顺序就是我们上述提到的优先级。每一个调度类都实现了pick_next_task，用于选择下一个调度的进程。先便利高优先级的调度类，如果有进程可调度，则直接返回。 在相同优先级调度类中可能管理多个进程的调度，因此调度类有会对应的调度策略。 调度策略 Stop 调度类 Stop 调度类中只有一个任务可供执行，不需要定义任何调度策略。 DL （Deadline）调度类 DL 只实现了一种调度策略：SCHED_DEADLINE, 用来调度优先级最高的用户任务。 RT （Real-Time） RT 提供了两种调度策略：SCHED_FIFO 与 SCHED_RR,对于使用 SCHED_FIFO 的任务，其会一直运行到主动放弃CPU; 而对于 SCHED_RR 的任务，如果多个任务的优先级相同，则大家会按照一定的时间配额来交替运行，即使一个任务一直处于可运行状态，在使用完自己的时间切片之后也会被抢占，然后被放入队列的尾巴等待下次机会。 Fair CFS 实现了三种调度策略： SCHED_NORMAL: 被用于绝大多数用户进程 SCHED_BATCH: 适用于没有用户交互行为的后台进程，用户对该类进程的响应时间要求不高，但对吞吐量要求较高，因此调度器会在完成所有 SCHED_NORMAL 的任务之后让该类任务不受打扰地跑上一段时间，这样能够最大限度地利用缓存。 SCHED_IDLE: 这类调度策略被用于系统中优先级最低的任务，只有在没有任何其他任务可运行时，调度器才会将运行该类任务。 Idle 同 Stop 一样，Idle 调度类也没有实现调度策略，注意不要将这类调度类与 CFS 中的 SCHED_IDLE 混淆。 每个进程在创建时都会指定一个调度策略，从而自动归结到某个调度类下。 调度策略的定义如下： #define SCHED_NORMAL 0 #define SCHED_FIFO 1 #define SCHED_RR 2 #define SCHED_BATCH 3 /* SCHED_ISO: reserved but not implemented yet */ #define SCHED_IDLE 5 #define SCHED_DEADLINE 6 可以通过 /proc/&lt;pid&gt;/sched 中的内容来查看进程的调度策略，例如 epoch@Ubuntu:~ $ cat /proc/130/sched | grep policy policy : 0 运行队列运行队列（run queue）rq 是系统可运行任务的容器，调度器的很多工作都是围绕着 rq 来进行的，调度类 struct sched_class 所申明的函数中，绝大多数函数都与 rq 相关。在系统中，每个 CPU 都有一个自己的 rq, 这样可以避免多个 CPU 访问同一个 rq 时产生的并发问题，提升调度器效率。 /* file: kernel/sched/sched.h */ struct rq &#123; unsigned int nr_running; u64 nr_switches; /* * runqueue 采用的模块化的实现方式，各个不同的 Scheduling Class 都有自己的 runqueue 实现。不同的 runqueue 的数据结构保存在如下属性之中 */ struct cfs_rq cfs; /* CFS runqueue 的实现 */ struct rt_rq rt; /* RT runqueue 的实现 */ struct dl_rq dl; /* Deadline runqueue 的实现 */ struct task_struct __rcu *curr; /* 当前 runqueue 中正在运行的进程 */ struct task_struct *idle; /* Idle 调度类的任务 */ struct task_struct *stop; /* Stop 调度类的任务 */ struct mm_struct *prev_mm; atomic_t nr_iowait; #ifdef CONFIG_SMP struct root_domain *rd; struct sched_domain __rcu *sd; unsigned long cpu_capacity; unsigned long cpu_capacity_orig; #endif /* CONFIG_SMP */ #ifdef CONFIG_SCHEDSTATS /* latency stats */ struct sched_info rq_sched_info; unsigned long long rq_cpu_time; /* could above be rq-&gt;cfs_rq.exec_clock + rq-&gt;rt_rq.rt_runtime ? */ /* sys_sched_yield() stats */ unsigned int yld_count; /* schedule() stats */ unsigned int sched_count; unsigned int sched_goidle; #endif &#125;; 此处删除了该结构体的大多数字段，仅仅保留了一些主要的字段一探究竟，这些字段涉及如下几个方面： 具体调度类的运行队列。不同的调度类选择下一个任务的逻辑是不同的，因此不同的调度类会有不同的调度队列实现方式，例如字段 struct cfs_rq cfs 就是 CFS 的调度队列 当前正在运行的进程，以及 stop 与 idle 这种特殊任务 如果是 SMP 架构，则 rq 中还会包含调度域的字段，调度器使用调度域中的信息来做负载均衡 一些统计信息 进程优先级 每一个调度类都实现了pick_next_task，用于选择下一个调度的进程。而该函数选择的依据，跟进程的优先级密不可分。 在Linux下，用户能通过系统调用设置优先级，分别是nice与sched_setscheduler，其中nice仅仅设置优先级，而sched_setscheduler还能改普通进程为实时进程。 站在用户的角度，用户只能接触到一类优先级，取值为[-20, 19]。 而站在内核的角度，能看到三种优先级，都在task_struct中。 /* file: include/linux/sched.h */ struct task_struct &#123; int prio; //动态优先级 int static_prio; //静态优先级 int normal_prio; //将三种优先级归一化，否则无法比较优先级。 unsigned int rt_priority; // 实时优先级 .... &#125; static_prio: 静态优先级。当用户通过 nice 与 sched_setscheduler 两个系统调用修改优先级时，改变的就是该字段。前文提到 nice 值的范围是[-20, 19], 而实时优先级的有效范围是[1, 99], 二者的重叠部分如何处理呢？内核在处理 nice 时会加上120, 完成 nice 值与静态优先级之间的转换。新进程创建时该值从父进程继承，静态优先级在进程执行过程中是不会改变的，而当其值发生改变的时候，其他相关优先级也需要重新计算（例如动态优先级）。 rt_priority：实时优先级。可通过系统调用chrt修改，有效范围是 [1, 99], 数字越大优先级越高，用于实时调度，所以当数值是0时表示该进程是普通进程。 prio: 动态优先级。为了调优IO密集和计算密集进程，动态优先级是在静态优先级动态调整而来，可调整的范围是+-5，可通过函数 effective_prio() 得到，具体实现如下。在$O(1)$调度器使用，CFS替代了$O(1)$调度器，在CFS中并为使用。 static int effective_prio(struct task_struct *p) &#123; p-&gt;normal_prio = normal_prio(p); /* 判断是否为实时优先级：如果 p.prio 的值小于 100(MAX_RT_PRIO的值), 则返回 1, 否则返回 0*/ if (!rt_prio(p-&gt;prio)) return p-&gt;normal_prio; return p-&gt;prio; &#125; normal_prio: 归一化优先级。 我们使用了不同的方式来刻画同一个概念，那么势必会带来管理上的麻烦，所谓归一化，就是设计一种转换方式，将这些不同的方法统一到同一种方法上去，从而简化问题的模型。内核设计了一种归一化算法，将所有的优先级统一到 [-1, 139] 这个区间上，并且数字越小优先级越大，该优先级就叫做归一化优先级。转换算法如下 static inline int __normal_prio(struct task_struct *p) &#123; return p-&gt;static_prio; &#125; static inline int normal_prio(struct task_struct *p) &#123; int prio; if (task_has_dl_policy(p)) /* MAX_DL_PRIO为0, 因此Deadline的优先级永远为-1 */ prio = MAX_DL_PRIO - 1; else if (task_has_rt_policy(p)) /* MAX_RT_PRIO为100, 而rt_priority的范围是[1,99]且数字越大对应的优先级越高，下面的算法实现了优先级反转，高优先级将对应小的数字。 */ prio = MAX_RT_PRIO - 1 - p-&gt;rt_priority; else /* 对于普通进程，直接返回静态优先级static_prio */ prio = __normal_prio(p); return prio; &#125; CFS为什么引入有CFS？传统的处理是将nice值映射到时间片，比如[ -20 … 0 … 19 ]的普通进程其缺省时间片为[800ms … 100ms … 5ms]。 传统基于优先级和时间片的算法有几点问题 问题1：nice值映射到处理器绝对时间，进程切换无法最优化进行。 问题2：即使相对nice值相同，运行时间差距也可能很大。 问题3：由于是映射到时间片，所以时间片是定时器周期的整数倍。 问题4：为了交互进程，可能需要临时提高交互进程优先级，打破了公平规则。 分别举例说明一下1、2、3。 问题1问题1：nice值映射到处理器绝对时间，公平性难以把握。 假设现在存在两个活跃进程，nice值分别为0和19，时间片分别是100ms和5ms。即105ms一个周期，进行两次上下文切换。 但如果是两个nice值为19的进程，时间片就是5ms和5ms，10ms内进行两次上下文切换。 通常来说，我们希望后台进程优先级低，交互进程优先级高，后台能够获得更长的运行时间，交互进程能够尽快响应用户操作。 这样分配的话，会导致交互进程分配较长的时间片，交互进程大部分时间在阻塞，后台进程时间片短，后台进程也无法充分运行。 问题2问题2：即使相对nice值相同，运行时间差距也可能很大。 假设现在存在两个活跃进程，nice值分别为0和1，时间片分别是100ms和95ms。差距不大。 但对于nice值为18和19的进程，时间片为10ms和5ms。前者是后者两倍运行时间。 问题3由于nice值到时间片的绝对映射，所以时间片一定是定时器周期的整数倍。 假设定时器周期为1ms，则时间片差距至少为1ms。 思路公平性CFS，completely fair scheduler，即完全公平调度器。顾名思义，公平是CFS的核心。 理想情况下，公平就是CPU的时间均分给每一个进程，如果时间为T，共N个进程在运行，那么每一个进程的时间就是$\\frac{T}{N}$。但现实是，系统无法知道T的具体值，而N也总是动态变化。前的调度逻辑都是基于时间片，绝对的公平几乎不可能实现。 CFS不再使用时间片，它的核心逻辑是以进程当前的实际运行时间为度量单位，记为runtime, 调度器每次调度时都选择runtime最小的进程。 优先级与权重实际上，进程之间存在着优先级的差异，上面提到的runtime的完全公平是不符合实际需求的。所以引入优先级的概念，这个优先级就是我们常说的nice值。优先级越高，获得运行时间的比例也就应该越高，也就是这个进程的权重越高。 为了实现优先级的需求，但又保留公平性处理逻辑的简洁。CFS的做法是，调度仍然是选择运行时间最小的那个进程，不过这个时间是虚拟时间。在物理时间相同的情况下，进程的权重越高，它的虚拟时间流逝的就越快。 这样，调度就只需要选择虚拟时间vruntime最小的进程进行调度。进程运行时，将真实时间经过权重的放缩之后计算到虚拟时间。 公平性、优先级与权重我们从公平角度来说，希望每一个进程都在CPU上运行相同的时间，但考虑到不同进程是有优先级的，比如说一个编辑器进程，我们希望他能够立刻响应，而一个跑深度学习的进程，我们倒是希望能够在后台运行，没有快速响应，慢几分钟几秒钟到是无所谓。这两种进程同时运行时，我们希望让编辑器进程优先响应，即编辑器进程优先级更高。 CFS的公平性本质上是对CPU时间的公平分配，而优先级的加入并没有改变这一点，优先级本质上是为了区分不同进程的重要性，只要调度器能够根据每个进程的重要性的比例来分配时间，那么它就依然是公平的。例如我们有三个进程 A, B, C, 其中B与C的重要性相等，而A的重要性是他们的两倍，那么在公平的分配策略下，三个进程得到的CPU时间比例应该是： A: 50% B: 25% C: 25% 假设系统已经运行了100ms, 三个任务均分了该时间片： A: 33.3ms, 实际比例1&#x2F;3, 期望比例为1&#x2F;2, 差值为：1&#x2F;6 B: 33.3ms, 实际比例1&#x2F;3, 期望比例为1&#x2F;4, 差值为：1&#x2F;12 C: 33.3ms, 实际比例1&#x2F;3, 期望比例为1&#x2F;4, 差值为：1&#x2F;12 此时A的比例差值最大，说明A所分配到的时间比例偏少，调度器应该选择A作为下一个任务来执行。整个过程略显复杂，需要每个任务都记录下自己的时间比例与权重比例，而CPU还需要计算出每一个进程的差值，选取插值最大的，有没有一种方式，让CPU看来，每一个进程运行的时间都相同，这样满足公平性且编码逻辑更加简洁，而进程运行的实际时间却具有权重之分？有， 那就是虚拟时间vruntime。 因此，逻辑就清晰了。CPU保证每个进程运行的逻辑时间相等，以保证公平性；将虚拟时间与物理时间按照权重进行一定的换算，以保证优先级的机制。 虚拟时间vruntime计算运行的虚拟时间权重和优先级有一定映射关系，公式如下$$weight &#x3D; \\frac{1024}{1.25^{nice}}$$ nice是之前提到的用户能够设置的静态优先级，当nice&#x3D;0时，任务权重weight为1024，而1024作为权重的一个基准，内核中用宏NICE_0_LOAD表示，其他所有的权重都是在该基准上伸缩得来。 因此，计算虚拟时间vruntime就很简单了，公式如下$$vruntime &#x3D; \\frac{wall_time * NICE_0_LOAD}{weight}$$其中wall_time代表物理时间（墙上时间，钟一般是挂在墙上的嘛）。 为了避免浮点运算，程序先进行放大后再缩小，代码为vruntime = (wall_time * ((NICE_0_LOAD * 2^32) / weight)) &gt;&gt; 32。而其中$\\frac{2^{32}}{weight}$被称为inv_weight，由于频繁使用，因此以打表缓存的形式存在。$$inv_weight &#x3D; \\frac{2^{32}}{weight}$$ const u32 sched_prio_to_wmult[40] = &#123; /* -20 */ 48388, 59856, 76040, 92818, 118348, /* -15 */ 147320, 184698, 229616, 287308, 360437, /* -10 */ 449829, 563644, 704093, 875809, 1099582, /* -5 */ 1376151, 1717300, 2157191, 2708050, 3363326, /* 0 */ 4194304, 5237765, 6557202, 8165337, 10153587, /* 5 */ 12820798, 15790321, 19976592, 24970740, 31350126, /* 10 */ 39045157, 49367440, 61356676, 76695844, 95443717, /* 15 */ 119304647, 148102320, 186737708, 238609294, 286331153, &#125;; 具体实现的计算函数是__calc_delta(delta, NICE_0_LOAD, &amp;se-&gt;load)。delta即墙上时间，&amp;se-&gt;load即权重。 接下来我们再来看一下系统如何更新任务的vruntime以及其他的时间信息的，完成该任务的是函数 update_curr(): /* file: kernel/sched/fair.c */ static void update_curr(struct cfs_rq *cfs_rq) &#123; struct sched_entity *curr = cfs_rq-&gt;curr; /* 获取当前时间 */ u64 now = rq_clock_task(rq_of(cfs_rq)); u64 delta_exec; if (unlikely(!curr)) return; /* 本次更新vruntime与上次更新vruntime之间的时间差，即任务本次的运行时间，该值为墙上时间 */ delta_exec = now - curr-&gt;exec_start; if (unlikely((s64)delta_exec &lt;= 0)) return; /* 记录这次更新的时间 */ curr-&gt;exec_start = now; /* 更新总的运行时间 */ curr-&gt;sum_exec_runtime += delta_exec; /* 更新vruntime, 通过函数calc_delta_fair计算出墙上时间delta_exec对应的虚拟时间 */ curr-&gt;vruntime += calc_delta_fair(delta_exec, curr); /* 更新队列的 min_vruntime */ update_min_vruntime(cfs_rq); /* 下面的逻辑可以暂时不管 */ if (entity_is_task(curr)) &#123; struct task_struct *curtask = task_of(curr); trace_sched_stat_runtime(curtask, delta_exec, curr-&gt;vruntime); cgroup_account_cputime(curtask, delta_exec); account_group_exec_runtime(curtask, delta_exec); &#125; account_cfs_rq_runtime(cfs_rq, delta_exec); &#125; 任务的vruntime就靠函数 update_curr 来维护，系统在很多情况下都会调用该方法，包括任务在入队、出队时，调度中断函数也会周期性地调用该方法，以确保任务的各种时间信息随时都是最新的状态。 调整睡眠的进程和新进程的vruntime除了为运行的任务计算vruntime之外，调度器还需要调整新创建的任务及久睡方醒的任务的vruntime, 否则他们的vruntime将远远落后于一直在执行的任务，从而导致长久的霸占CPU. 该任务通过函数 place_entity 完成 该函数总是为目标任务加上一定的vruntime, 因此事实上是一个“惩罚函数”。 /* file: kernel/sched/fair.c */ static void place_entity(struct cfs_rq *cfs_rq, struct sched_entity *se, int initial) &#123; /* 以队列的min_vruntime为基础进行调整 */ u64 vruntime = cfs_rq-&gt;min_vruntime; /* 对新创建的进程（initial=1）适当的惩罚，为其加上一定的 vruntime, * 函数sched_vslice将任务在一个调度周期内应当分配到的墙上时间换算成虚拟时间，调度周期会在下一节介绍 */ if (initial &amp;&amp; sched_feat(START_DEBIT)) vruntime += sched_vslice(cfs_rq, se); if (!initial) &#123; /* 如果进程睡眠了很久，那么其 vruntime 可能远远小于队列中其他任务的vruntime, * 我们也需要对其vruntime * 进行惩罚，但进程被唤醒（initial=0）说明它所等待的事件已经得到了满足，需要马上干活，所以这里减去一定的vruntime作为补偿。*/ unsigned long thresh = sysctl_sched_latency; if (sched_feat(GENTLE_FAIR_SLEEPERS)) thresh &gt;&gt;= 1; vruntime -= thresh; &#125; /* 确保不要因为 vruntime -=thresh 导致 se.vruntime 的值越来越小了 */ se-&gt;vruntime = max_vruntime(se-&gt;vruntime, vruntime); &#125; 如何选择下一个进程通过前文对于公平性的讨论，我们知道对于CFS所管理的任务而言，vruntime相等就是公平的，CFS的工作职责就是维持所有任务的vruntime尽可能相等。总结起来，CFS的工作原理如下：CFS为每个任务维护一个虚拟时间vruntime, 每次调度时都从runqueue中挑选vruntime最小的任务来执行，并将任务执行时所耗费的墙上时间根据任务的权重换算成虚拟时间累计起来；随着时间的消耗，当当前任务的vruntime数值不再是runqueue中最小的时，调度器将其放回runqueue, 重新选择下一个任务。 调度周期从CFS的调度原理来考虑的话，CFS似乎不需要调度周期的概念，因为CFS并不是预先给任务分配时间片，而是根据大家当前的运行时间来判断谁应该是下一个该执行的任务，这样所有任务都随着时间的推进齐头并进。但为了用来调度延迟，CFS也需要引入调度周期。 什么是调度延迟呢？CFS不仅需要保证时间分配的公平，还要保证各个任务每隔一段时间就能够执行一次，一个任务在两次被调度到的时间间隔就是调度延迟。相反，调度器还需要保证任务在每次得到机会执行时，除了任务主动放弃CPU, 尽量不要太快地被踢出来，因为太频繁的上下文切换会导致系统的总体性能降低。所以 CFS 没有使用固定的时间长度作为调度周期，而是根据当前队列中的任务数量动态计算出调度周期的长度，该逻辑由函数 __sched_period 实现 /* file: kernel/sched/fair.c */ /* 参数 nr_running 表示当前 cfs_rq 中的任务总数 */ static u64 __sched_period(unsigned long nr_running) &#123; /* sched_nr_latency: 8 */ if (unlikely(nr_running &gt; sched_nr_latency)) /* sysctl_sched_min_granularity: 0.75ms */ return nr_running * sysctl_sched_min_granularity; else /* sysctl_sched_latency: 6ms*/ return sysctl_sched_latency; &#125; 当队列中所有的任务超过8个时，CFS的调度周期为任务总数乘以0.75ms，否则调度周期为固定的6ms, 这样可以保证任务的切换频率比较合理。 算出调度周期之后，系统还需要为任务计算其在一个调度周期内的时间配额，函数 sched_slice 用来实现该逻辑： /* file: kernel/sched/fair.c */ static u64 sched_slice(struct cfs_rq *cfs_rq, struct sched_entity *se) &#123; unsigned int nr_running = cfs_rq-&gt;nr_running; u64 slice; /* 调度周期 */ slice = __sched_period(nr_running + !se-&gt;on_rq); /* 暂时不考虑组调度，此处的循环只会执行一次 */ for_each_sched_entity(se) &#123; struct load_weight *load; struct load_weight lw; cfs_rq = cfs_rq_of(se); /* 整个运行队列 cfs_rq 的总权重 */ load = &amp;cfs_rq-&gt;load; /* se-&gt;load.weight为se的权重，调用函数__calc_delta得到slice*se-&gt;load.weight/load.weight, * 即根据 se 在整个队列中的权重比例分配时间 */ slice = __calc_delta(slice, se-&gt;load.weight, load); &#125; if (sched_feat(BASE_SLICE)) slice = max(slice, (u64)sysctl_sched_min_granularity); return slice; &#125; 当任务在当前调度周期内的耗时超过自己的配额时，调度器就会将其踢出去，换其他任务来执行，这个值的检查的频率是由调度节拍决定的。调度节拍中将会详细讨论该逻辑。 调度节拍计算机系统随着时钟节拍需要周期性地做很多事情，例如刷新屏幕、数据落盘等，而进程调度是众多任务中最重要的之一。周期性调度也叫调度节拍，它的入口是函数 scheduler_tick(), 该函数最终会调用调度类的 task_tick() 方法完成操作： /* file: kernel/sched/core.c */ void scheduler_tick(void) &#123; int cpu = smp_processor_id(); struct rq *rq = cpu_rq(cpu); struct task_struct *curr = rq-&gt;curr; /* 调用当前任务的调度类的 task_tick 方法 */ curr-&gt;sched_class-&gt;task_tick(rq, curr, 0); #ifdef CONFIG_SMP /* SMP 架构下触发负载均衡 */ rq-&gt;idle_balance = idle_cpu(cpu); trigger_load_balance(rq); #endif &#125; CFS 中实现 task_tick 方法的是函数 task_tick_fair: /* file: kernel/sched/fair.c */ static void task_tick_fair(struct rq *rq, struct task_struct *curr, int queued) &#123; struct cfs_rq *cfs_rq; struct sched_entity *se = &amp;curr-&gt;se; /* 在不考虑组调度的情况下，此处的循环只会迭代一次，处理的就是当前任务 */ for_each_sched_entity(se) &#123; cfs_rq = cfs_rq_of(se); entity_tick(cfs_rq, se, queued); &#125; &#125; 实际的逻辑都在函数 entity_tick 中，删除无关代码及与组调度相关的逻辑，主要逻辑如下： /* file: kernel/sched/fair.c */ static void entity_tick(struct cfs_rq *cfs_rq, struct sched_entity *curr, int queued) &#123; /* 首先更新当前任务及队列的各种时间信息，详见 vruntime 一节 */ update_curr(cfs_rq); if (cfs_rq-&gt;nr_running &gt; 1) /* 检查是否需要抢占当前任务 */ check_preempt_tick(cfs_rq, curr); &#125; 该函数的主要任务有两个，一个是更新任务的各种时间信息；另一个是检查当前任务是否已经执行地足够久了，如果是的话就需要对其进行抢占，换其它任务来执行。关于抢占的概念将在下一节中介绍。 进程抢占所谓抢占，就是停止当前正在执行的任务，换另一个任务来执行。导致这种情况发生的原因很多，例如当前任务已经运行了太长时间，需要让出CPU; 用户修改了任务优先级，导致当前任务应该被换下；或者优先级更高的任务被唤醒，需要立刻开始运行。但当这种情况发生时，调度器并不会真的立刻切换任务，而是调用 resched_curr() 函数为当前任务设置一个叫着 TIF_NEED_RESCHED 的标记位，该函数的主要逻辑如下 /* file: kernel/sched/core.c */ void resched_curr(struct rq *rq) &#123; struct task_struct *curr = rq-&gt;curr; int cpu; lockdep_assert_held(&amp;rq-&gt;lock); /* 如果当前任务已经设置了 TIF_NEED_RESCHED 标记位，则返回 */ if (test_tsk_need_resched(curr)) return; cpu = cpu_of(rq); if (cpu == smp_processor_id()) &#123; /* 设置标记位 */ set_tsk_need_resched(curr); set_preempt_need_resched(); return; &#125; &#125; TIF_NEED_RESCHED 位被设置之后，调度器在下一次调度发生时就会进行真正的调度，将任务换下，进行上下文切换，运行新任务。具体的调度入口和调度时机在后文讨论。 调用resched_curr()的地方非常多，这里主要介绍两个典型场景： 调度节拍中检测到任务运行时间耗尽 任务状态切换为可运行时，判断是否可以调用，例如创建新进程、任务苏醒。 运行时间耗尽前面提到每个调度周期内都有一定的时间配额，当任务耗尽了该时间片之后就需要让出CPU, 以便给其它任务提供运行的机会。在调度节拍一节中，提到 entity_tick 最后调用了check_preempt_tick，后者就是检查时间是否耗尽的函数，实现如下。 /* file: kernel/sched/fair.c */ static void check_preempt_tick(struct cfs_rq *cfs_rq, struct sched_entity *curr) &#123; unsigned long ideal_runtime, delta_exec; struct sched_entity *se; s64 delta; /* 计算出当前任务在一个调度周期内的时间配额 */ ideal_runtime = sched_slice(cfs_rq, curr); /* 计算出当前任务已经运行了多长时间 */ delta_exec = curr-&gt;sum_exec_runtime - curr-&gt;prev_sum_exec_runtime; if (delta_exec &gt; ideal_runtime) &#123; /* 如果运行时长已经超过了任务自己的时间配额，则对任务进行抢占 */ resched_curr(rq_of(cfs_rq)); return; &#125; /* 避免任务抢占发生得太过频繁 */ if (delta_exec &lt; sysctl_sched_min_granularity) return; /* 从cfs_fq中挑出vruntime最小的任务，即红黑树中最左子节点；并计算出当前任务与该任务的vruntime的差值 */ se = __pick_first_entity(cfs_rq); delta = curr-&gt;vruntime - se-&gt;vruntime; /* 如果当前任务的vruntime依然小于红黑树中所有任务的vruntime, 则不发生抢占 */ if (delta &lt; 0) return; /* 如果已经多除了相当部分，则可以抢占当前任务了 */ if (delta &gt; ideal_runtime) resched_curr(rq_of(cfs_rq)); &#125; 可以看到最后一行，情况符合的话，就会调用resched_curr。 创建新任务新任务创建后可能需要立即运行，就可能会调用到resched_curr函数。创建完毕后，在wake_up_new_task检查是否需要调用resched_curr。 调度入口调度入口就是真正执行调度的地方，由schedule()执行，保留核心代码，实现如下 /* file: kernel/sched/core.c */ asmlinkage __visible void __sched schedule(void) &#123; struct task_struct *tsk = current; do &#123; preempt_disable(); /* 调用函数 __schedule 来做具体的工作 */ __schedule(false); sched_preempt_enable_no_resched(); /* need_resched用来判断当前任务是否应该被抢占，此时的当前任务就是函数__schedule最新选择的任务，如果是的话那么继续调用函数__schedule以便调用下一个合适的任务。*/ &#125; while (need_resched()); &#125; static void __sched notrace __schedule(bool preempt) &#123; struct task_struct *prev, *next; unsigned long *switch_count; unsigned long prev_state; struct rq_flags rf; struct rq *rq; int cpu; /* 获取到当前CPU序号，进而获取到其runqueue */ cpu = smp_processor_id(); rq = cpu_rq(cpu); /* rq-&gt;curr 是当前正在执行的任务 */ prev = rq-&gt;curr; prev_state = prev-&gt;state; if (!preempt &amp;&amp; prev_state) &#123; if (signal_pending_state(prev_state, prev)) &#123; prev-&gt;state = TASK_RUNNING; &#125; else &#123; /* preempt 如果为false, 则说明此次调度不是由于任务抢占导致的，那么导致调度发生的原因就是任务主动要求让出CPU, 对于由于IO事件进入睡眠的任务而言，需要先将其从运行队列中踢出去。该函数最终会调用调度类（sched_class）的 dequeue_task 方法完成具体工作。*/ deactivate_task(rq, prev, DEQUEUE_SLEEP | DEQUEUE_NOCLOCK); &#125; &#125; /* 从队列中选择下一个任务，该函数最终会调用调度类（sched_class的函数pick_next_task方法。对于CFS而言，就是选择vruntime最小的任务 */ next = pick_next_task(rq, prev, &amp;rf); /* 清除 prev 任务的TIF_NEED_RESCHED标记，因为此时它已经被抢占了 */ clear_tsk_need_resched(prev); if (likely(prev != next)) &#123; /* 完成上下文切换，CPU将开始执行刚刚挑出来的任务next了 */ rq = context_switch(rq, prev, next, &amp;rf); &#125; &#125; 其中next = pick_next_task(rq, prev, &amp;rf);就是前文提到的全局的pick_next_task，根据优先级遍历所有的调度类。 函数 schedule() 最后调用 context_switch() 完成上下文切换，至此，整个调度工作就完成了！ 接下来讨论调度的时机，即什么时候调用schedule()。 调度时机用户抢占在以下情况会检查TIF_NEED_RESCHED标志位， 从系统调用返回用户空间时 从中断处理程序返回用户空间时 检查到了则会调用schedule，进行任务调度。 内核抢占在以下情况可能发生内核抢占，检测到TIF_NEED_RESCHED标志位，或者显式调用 中断处理程序正在执行，且返回内核空间之前 内核代码再一次具有可抢占性的时候 内核代码显示调用schedule() 内核中的任务阻塞（同样导致调用schedule） 前面提到，周期性调度会按照调度节拍检查当前任务是否超时，而该周期性调度程序是由中断实现的，返回时即会检查TIF_NEED_RESCHED标志位。 重新调度所谓抢占，就是停止当前正在执行的任务，换另一个任务来执行。导致这种情况发生的原因很多，例如当前任务已经运行了太长时间，需要让出CPU; 用户修改了任务优先级，导致当前任务应该被换下；或者优先级更高的任务被唤醒，需要立刻开始运行。但当这种情况发生时，调度器并不会真的立刻切换任务，而是调用 resched_curr() 函数为当前任务设置一个叫着 TIF_NEED_RESCHED 的标记位，等下一个调度节拍来执行实际的调度。 上下文切换调度函数 schedule() 最后调用 context_switch() 完成上下文切换，context_switch()完成两项基本的工作 进程地址空间切换：声明在&lt;sam/mmu_context.h&gt;中的switch_mm：切换大部分虚拟内存。由于虚拟内存与MMU有关，具体的工作细节取决于处理器，主要包括 加载页表：即修改页表基址寄存器成新的task_struct-&gt;mm_struct-&gt;pgd。 刷新TLB（有些体系会优化这个步骤，用到才刷新） 向MMU提供信息… 处理器状态切换：声明在&lt;asm/system.h&gt;中的swtich_to：保存、恢复内核栈信息（用户栈在上一步已经被切换）和PC、SP等寄存器信息，还有其他任何于体系结构相关的信息。 由于与具体体系关系紧密，因此上下文切换代码通常使用汇编语言编写。 内核的mm_struct指向NULL。 进程组、组调度为什么要有进程组的概念呢？考虑如下情况，一个系统有100个进程，CFS会保证每个进程都获得1%的CPU时间，但实际上系统中的这100个进程可能隶属于两个用户A与B, 其中用户A拥有10个进程，用户B拥有90个进程，这种实现造成的结果是用户A只获得了10%的CPU时间，而用户B获得了90%的时间。如果用户B了解CFS的调度原理，那么他可以肆无忌惮地fork出更多的进程以攫取更多的CPU时间。可见CFS在进程层面上的公平，却导致了系统在用户层面上的不公平，甚至是漏洞。对于这种情况，一种更合理的策略是系统首先保证每个用户获得相同的时间，然后再对隶属于同一个用户的所有进程公平地分配该用户的时间。 将该概念进一步抽象，我们就得到了进程组的概念。进程组的引入实际上是增加了一个调度层级，调度器首先完成进程组的时间分配，再处理组内进程之间的时间分配，前文提到的用户分组只是进程组的一个特例。 负载均衡一个CPU有很多核心嘛，为了效率肯定需要做负载均衡的，每一个核心都需要做负载记账，当核心之间的负载不均衡时，需要进行任务迁徙，这个过程就是负载均衡。当然负载均衡需要考虑很多问题，比如这个CPU是什么架构是SMP还是NUMA，不同核心处理能力不同，迁移时vruntime又怎么处理等等。 抽象层面Linux为了更方便地扩展，抽象出了很多概念。举几个例子 调度类：每一个调度类都需要实现调度的通用函数，即对调度相关的函数声明进行实现。这其实就是一种面向对象的思想。 调度实体：进程就是一种调度实体，线程也是。在Linux下的进程和线程都是task_struct表示，区别只是是否共享虚拟地址空间。这其实是一种抽象，而Linux的task_struct就是一种可调度的实体）。 调度组：进程组的引入实际上是增加了一个调度层级，调度器首先完成进程组的时间分配，再处理组内进程之间的时间分配，前文提到的用户分组只是进程组的一个特例。 参考资料 《Linux内核设计与实现》第三版 《深入Linux内核架构》 Linux核心概念详解 TODO 调度域 调度实体 负载记账 负载均衡","categories":[{"name":"Linux","slug":"Linux","permalink":"https://messenger1th.github.io/categories/Linux/"}],"tags":[]},{"title":"Physical Memory","slug":"Linux/Physical Memory","date":"2024-07-24T14:47:33.980Z","updated":"2024-07-24T14:47:33.981Z","comments":true,"path":"2024/07/24/Linux/Physical Memory/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Linux/Physical%20Memory/","excerpt":"","text":"Linux物理内存架构Linux使用节点(node)，区域(zone)，页(page)三级结构来描述整个物理内存。 一个物理内存分为好几个node，每个node存在好几个zone，每个zone中细分为page大小。 一个内存zone中包含该zone中所有可用的内存页。 struct zone &#123; struct free_area free_area[MAX_ORDER]; ... &#125; struct free_area &#123; struct list_head free_list[MIGRATE_TYPES]; unsigned long nr_free; &#125; 不同大小的内存块，即order不同的块，挂载在不同的链表上，内存不够时，从更大order的链表中取一块下来，并切分到合适的大小，由Buddy分配器管理。 节点（node）目前计算机系统有两种体系结构： 非一致性内存访问 NUMA（Non-Uniform Memory Access）意思是内存被划分为各个node，访问一个node花费的时间取决于CPU离这个node的距离。每一个cpu内部有一个本地的node，访问本地node时间比访问其他node的速度快 一致性内存访问 UMA（Uniform Memory Access）也可以称为SMP（Symmetric Multi-Process）对称多处理器。意思是所有的处理器访问内存花费的时间是一样的。也可以理解整个内存只有一个node。 NUMA通常用在服务器领域，可以通过CONFIG_NUMA来配置是否开启 区（zone）为了一些特殊需求，如DMA，Linux内存分区zone。 ZOME_DMA ZOME_DMA32 ZOME_NORMAL ZOME_HIGHEM：高端内存，用于32位下访问超过4GB的内存。由于64位的空间足够，故64位不含该区。 页（page） 分配的基本单位是页，每一个页都对应一个struct page结构体。 其他概念页框\\页帧（page frame）为了描述一个物理page，内核使用struct page结构来表示一个物理页。假设一个page的大小是4K的，内核会将整个物理内存分割成一个一个4K大小的物理页，而4K大小物理页的区域我们称为page frame。 Page Frame Num(PFN)将物理地址分成一块一块的大小，就比如大小是4K的话，将一个物理页的区域我们称为page frame, 而对每个page frame的编号就称为PFN. 物理地址和pfn的关系是：物理地址&gt;&gt;PAGE_SHIFT &#x3D; pfn 内存分配与释放Linux物理内存分配是以页为单位，x86架构下，每页4Kb，即$2^{12}$bit。 以下以x86为例，即每页4Kb，$2^{12}$bit。 Linux的内存分配策略是Buddy策略+Slab策略 内存的管理主要是处理外部碎片和内部碎片。 Buddy分配$2^{n}$为单位的内存页，不存在外部碎片。 Slab先获取合适大小的Buddy内存，这块内存可以被对象大小整除，也就不存在内部碎片。 Buddy分配器Buddy System是最基本的分配器，从 zone 中分配内存，zone 中使用一个数组来管理不同大小的Buddy, 该字段定义如下： /* file: include/linux/mmzone.h */ struct zone &#123; /* free areas of different sizes */ struct free_area free_area[MAX_ORDER]; &#125; 在同一个free_area中的空闲空间大小相同，free_area[i]存储的的是$2^{i}$个页面的空闲的、物理连续的内存块，即每块$2^{i} × 2^{12}$bit大小。 MAX_ORDER为11，即最多分配$2^{10} &#x3D; 1024$个页面。 struct free_area &#123; struct list_head free_list[MIGRATE_TYPES]; unsigned long nr_free; &#125; free_area 中的空闲分组按照 MIGRATE_TYPES 进行了分组，每种类型都保存在一个双向链表中，这里我们将关注点放在Buddy System算法的实现上，不展开讨论 MIGRATE_TYPES. 分配流程内存不够时，从更大order的链表中取一块下来，并切分到合适的大小，每次切分时按一半来切，另一半放到对应下标的位置进行管理。即切分后不用的内存块会依旧切分为2的整数倍的内存块，加入到对应order的链表中进行管理。 此外，人们发现系统对于 order&#x3D;0 的内存分配请求是出现频次最高的，为了提升性能，系统就为每个CPU 建立了一个“缓存池”，避免了互斥的开销。 函数的逻辑根据 order 的大小分为两部分： 当order &#x3D; 0, 即申请的内存页数等于1时，系统会从每个CPU的缓存页面中分配内存，如果没有，从buddy system分配。 当order &gt; 0, 即申请的内存页数大于1时，系统会从 zone 中分配内存，如果没有，从buddy system分配。 当order &#x3D; 0, 即申请的内存页数等于1时，系统会从每个CPU的缓存页面中分配内存。“缓存池”，也就是zone 中的字段 struct per_cpu_pageset __percpu *pageset;, 内核将其称为 pcplist, 即 per cpu pages list, 从 pcplist 分配内存的函数是 rmqueue_pcplist: /* file: mm/page_alloc.c */ static struct page *rmqueue_pcplist(struct zone *preferred_zone, struct zone *zone, gfp_t gfp_flags, int migratetype, unsigned int alloc_flags) &#123; struct per_cpu_pages *pcp; struct list_head *list; struct page *page; unsigned long flags; local_irq_save(flags); /* 获取到当前CPU 的 pageset */ pcp = &amp;this_cpu_ptr(zone-&gt;pageset)-&gt;pcp; /* 拿到 pageset 中对应类型的内存列表 */ list = &amp;pcp-&gt;lists[migratetype]; page = __rmqueue_pcplist(zone, migratetype, alloc_flags, pcp, list); if (page) &#123; __count_zid_vm_events(PGALLOC, page_zonenum(page), 1); zone_statistics(preferred_zone, zone); &#125; local_irq_restore(flags); return page; &#125; static struct page *__rmqueue_pcplist(struct zone *zone, int migratetype, unsigned int alloc_flags, struct per_cpu_pages *pcp, struct list_head *list) &#123; struct page *page; do &#123; /* 如果目标列表为空，则通过 Buddy System 为该列表补充内存，然后再进行分配 */ if (list_empty(list)) &#123; pcp-&gt;count += rmqueue_bulk(zone, 0, READ_ONCE(pcp-&gt;batch), list, migratetype, alloc_flags); if (unlikely(list_empty(list))) return NULL; &#125; /* 将对应内存列表的第一个内存页作为结果返回 */ page = list_first_entry(list, struct page, lru); list_del(&amp;page-&gt;lru); pcp-&gt;count--; &#125; while (check_new_pcp(page)); return page; &#125; 如果 order&gt;0, 则通过函数 __rmqueue_smallest 从 zone 中分配内存，Buddy System 的算法实现也包含在该函数中： /* file: mm/page_alloc.c */ static __always_inline struct page * __rmqueue_smallest(struct zone *zone, unsigned int order, int migratetype) &#123; unsigned int current_order; struct free_area *area; struct page *page; /* Find a page of the appropriate size in the preferred list */ for (current_order = order; current_order &lt; MAX_ORDER; ++current_order) &#123; area = &amp;(zone-&gt;free_area[current_order]); /* include/linux/mmzone.h: 作用是从 area-&gt;free_list[migratetype] 列表中拿到第一个元素，也就是一个连续 2^order 个物理页面 */ page = get_page_from_free_area(area, migratetype); /* 如果没有对应大小的free list, 则尝试下一个 order 的列表 */ if (!page) continue; del_page_from_free_list(page, zone, current_order); /* 如果 order ！= current_order, 则需要按照Buddy Algorithm将更大的连续内存劈开成更小的Buddy并插入到对应的 free area 列表中，该逻辑在 expand 函数中完成 */ expand(zone, page, order, current_order, migratetype); set_pcppage_migratetype(page, migratetype); return page; &#125; return NULL; &#125; 函数通过 for 循环遍历 zone-&gt;free_area, 找到能够满足请求的最小的Buddy并从中分配内存，如果实际的Buddy 列表大小大于请求的 order, 则通过 expand 对其进行拆分并将未分配的内存存入对应 order 的Buddy列表中，整个算法思路与前文讨论的一样。 回收流程回收时，如果对应大小的另一块的内存是空闲的，则会进行合并，这个过程是循环进行的，直到不能合并为止。 要找到另一个块，只需要将内存块的地址与内存块的大小做异或操作即可。找到另一块，判断是否空闲，即判断另一块的位图是否为0，为0则循环向上合并，重复这个合并过程。 如果只有Buddy分配器的话，可能导致大量内存块的浪费，比如申请65KB的内存，分配64KB是不够的，只能分配128KB，但只用到65KB，就会造成63KB的浪费，导致了内部碎片。Slab就是解决这类问题的。 Slab分配器Slab是基于Buddy的分配器，也就是首先向Buddy分配对应的大内存，对这块内存进行管理，从而避免内部碎片。 具体的，Slab向Buddy申请特地大小的内存，这块内存的大小要求能被结构体大小整除，即正好能放下完整的对象，不会存在内部碎片。 Slab策略看起来像池的思想，但由于对象类型很多，不可能每个都分配一个池，Slab可以看成一个通用的拟内存池机制。 一个Slab包含一个或多个连续的物理页面，然后将这些页面均分成固定的大小的各等份，每一等份就是一个对象，各对象通过链表串起来。 Slub分配略复杂，更详细的介绍在Linux分类下的Slub文章中。 看起来Slab只能分配固定大小的的内存，实际上，Linux的Slab实现了kmalloc和vmalloc，可以提供不同大小的可分配内存。 kmalloc、vmallockmalloc、vmalloc对于常用的大小，创建了对应大小的的高速缓存组，部分如下。分配时找到第一个大于等于请求值的那个缓存组分配即可。 kmalloc分配的内存是物理连续的，而vmalloc是不一定是物理连续的。当然它们都是逻辑连续的。 vmalloc通过分配非连续的物理内存块，再修正页表，实现逻辑连续。由于需要建立页表项，同时一个一个地进行映射，导致分配慢、TLB抖动，都会影响效率。因此，内核在不得已才使用，如分配大块内存的情况下，比如加载模块。 kmalloc、vmalloc对于常用的大小，创建了对应大小的的高速缓存组，部分如下。分配时找到第一个大于等于请求值的那个缓存组分配即可。 root:/ # cat /proc/slabinfo | grep &quot;kmalloc&quot; kmalloc-8192 644 663 8704 3 8 : tunables 0 0 0 : slabdata 221 221 0 kmalloc-4096 2250 2254 4608 7 8 : tunables 0 0 0 : slabdata 322 322 0 kmalloc-2048 6767 6780 2560 12 8 : tunables 0 0 0 : slabdata 565 565 0 kmalloc-1024 2374 2436 1536 21 8 : tunables 0 0 0 : slabdata 116 116 0 kmalloc-512 7034 7296 1024 32 8 : tunables 0 0 0 : slabdata 228 228 0 kmalloc-256 17285 17640 768 21 4 : tunables 0 0 0 : slabdata 840 840 0 kmalloc-128 301624 303775 640 25 4 : tunables 0 0 0 : slabdata 12151 12151 0 回收策略内核检查页面回收分为周期性检查和内存不足时的阻塞检查。 周期性检查由守护进程kswapd完成，定时检查内存使用情况，在少于特定阈值就会发起回收。主要有3个阈值 pages_min： zone 的预留页面数量，如果小于该阈值，则压力比较大。 pages_low：控制页面回收的最小阈值，小于该阈值则进行页面回收。 pages_high：控制进行页面回收的最大阈值。 如果操作系统进行内存回收之后，仍然无法回收到足够多的页面，则启动OOM Killer，挑选一个最合适的进程并kill，释放其内存。 分配和释放APIBuddystruct page* alloc_pages(gfp_t gft_mask, unsigned int order); // 分配2^order个**连续的物理页**，返回指向首地址，失败则为NULL。 void * page_address(struct page* page); //用该函数转化为对应的逻辑地址。 //其他封装函数 struct page* alloc_page(gfp_mask); // struct page* alloc_pages(gfp_mask, order); unsigned long __get_free_page(gfp_t gfp_mask); unsigned long __get_free_pages(gfp_t gfp_mask, unsigned int order); // 作用与alloc_pages()相同，不过只返回第一个页的逻辑地址。 unsigned long get_zeroed_page(unsigned int gfp_mask); // 同_get_free_page(gfp_t gfp_mask), 但初始化为0. void __free_pages(struct page* page, unsigned int order); void free_pages(unsigned long addr, unsigned int order); void free_page(unsigned long addr) 分配参数 分配内存时还需要很多标记类参数，例如指定目标 zone （是从 DMA 请求内存还是 NORMAL)、分配到的内存是否要全部置零、如果内存不足，是否可以触发内存回收机制等等，这些标记都定义在 include/linux/gfp.h 中，例如： /* file: include/linux/gfp.h */ #define ___GFP_DMA 0x01u #define ___GFP_HIGHMEM 0x02u #define ___GFP_DMA32 0x04u #define ___GFP_MOVABLE 0x08u #define ___GFP_RECLAIMABLE 0x10u #define ___GFP_HIGH 0x20u #define ___GFP_IO 0x40u #define ___GFP_FS 0x80u #define ___GFP_ZERO 0x100u #define ___GFP_ATOMIC 0x200u /* 通过位运算将不同的标记组合起来 */ #define GFP_ATOMIC (__GFP_HIGH|__GFP_ATOMIC|__GFP_KSWAPD_RECLAIM) #define GFP_KERNEL (__GFP_RECLAIM | __GFP_IO | __GFP_FS) #define GFP_KERNEL_ACCOUNT (GFP_KERNEL | __GFP_ACCOUNT) #define GFP_NOWAIT (__GFP_KSWAPD_RECLAIM) 源文件中对每个标记位的作用都有详细的说明，这里不再一一讨论。特别指出的是，GFP是Get Free Page的简称，这些标记叫着GFP Flags, 他们控制着Buddy System分配内存时的行为。 Slab、kmalloc和vmalloc分配至少为size的内存块。 struct kmem_cache *kmem_cache_create(const char *name, //kmem_cache的名称 size_t size, //slab管理对象的大小 size_t align, //slab分配器分配内存的对齐字节数(以align字节对齐) unsigned long flags, //分配内存掩码，实际会调用到buddy处执行。 void (*ctor)(void *)); //分配对象的构造回调函数 void kmem_cache_destroy(struct kmem_cache *); //销毁该cache void *kmem_cache_alloc(struct kmem_cache *cachep, int flags); //从该cache分配一块对象 void kmem_cache_free(struct kmem_cache *cachep, void *objp); //从该cache回收指定对象 //kmalloc和vmalloc void * kmalloc(size_t size, gfp_t flags); void * vmalloc(unsigned long size); void kfree(const void* ptr); void vfree(const void* addr); 参考 3.2.4 Buddy System(伙伴系统) Buddy详细计算过程","categories":[{"name":"Linux","slug":"Linux","permalink":"https://messenger1th.github.io/categories/Linux/"}],"tags":[]},{"title":"Ext File System","slug":"Linux/Ext File System","date":"2024-07-24T14:47:33.967Z","updated":"2024-07-24T14:47:33.967Z","comments":true,"path":"2024/07/24/Linux/Ext File System/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Linux/Ext%20File%20System/","excerpt":"","text":"Ext文件系统综述通过我们都是通过系统调用read、write等操作文件，实际上，这是一类统一的接口，具体操作是需要底层的文件系统来实现的。在Linux下，这层抽象就是VFS（Virtual File System），而Linux默认的文件系统是Ext文件系统，从Ext2到Ext4，处在迭代之中。当然由于VFS的存在，也可以操作其他文件系统，比如XFS，NTFS等，甚至LInux的内存中有一个proc的文件系统，实现了VFS的接口，这也是Linux一切皆文件思想的体现。整体布局如下。 本文主要讲讲Linux默认的Ext文件系统。在说到Ext文件系统前，先说一下操作系统的引导区在硬盘中的布局。 引导分区Boot Sector引导分区的格式通常不是Ext文件系统，而采用FAT32等兼容性更强的文件系统。 操作系统是存在于硬盘上的，从硬盘启动。现在有两种分区格式，MBR（Master Boot Recorder）和GPT（GUID Partition Table）。这两种分区格式分别对应Legacy和UEFI引导模式。分区格式是对于硬盘来说的，引导模式是针对主板来说的。因此，分区是GPT格式，也得主板支持UEFI引导模式才行。 GPT分区格式逐渐取代了MBR，原因如下。 支持更大的磁盘容量：MBR分区表只支持最大2TB的磁盘容量，而GPT分区表最大支持9.4ZB（1ZB&#x3D;1024EB）的磁盘容量。这意味着GPT分区表可以支持更大的硬盘、RAID阵列和SAN存储设备。 支持更多的分区：MBR分区表最多支持4个主分区或3个主分区和1个扩展分区，而GPT分区表最多支持128个分区。这意味着GPT分区表可以更灵活地分割磁盘空间，以满足更多的应用场景。 更好的数据完整性：GPT分区表使用CRC校验和来检测和修复分区表损坏的情况，可以更好地保护磁盘数据的完整性。而MBR分区表没有这种保护机制，一旦分区表损坏，就可能导致磁盘数据的丢失。 更好的兼容性：GPT分区表可以被多个操作系统兼容，包括Windows、Linux、Mac OS等，而MBR分区表则受到一些操作系统的限制，例如Windows操作系统只支持MBR分区表的引导方式。 MBR分区MBR分区布局如下。 其中，分区表的内容如下。 GPT分区GPT布局如下 其中LBA 0是为了兼容老设备，还保留了MBR的信息。 一个Entry描述一个分区的信息。最多128个Entry，因此最多不超过128个分区。 此外，GPT的信息尤为重要，所以会备份到磁盘的末尾的34LBA中。 布局说完了磁盘的引导部分，我们说说Ext文件系统的详细的布局，整体的布局如下。 分区Parition不同分区可以是不同的文件系统，比如引导区是FAT32文件系统，而Linux通常含有一个swap分区。 例如，在Linux系统下， 可以通过fdisk 来查看一个硬盘信息。 可以通过ntfs-3g或者mkfs.ntfs将一个分区格式化为ntfs文件系统。 /dev目录有硬盘和分区信息，根据硬盘的协议有/dev/sd*，/dev/nvme*。例如，/dev/nvme0n1p1代表nvme协议，设备编号n1，该分区为p1。 块组Block Group前面我们说一个分区就相当于是一个文件系统，相互隔离开。 一个分区中含有多个Block Group，其中含有Super Block和Group description table等信息。 但Super Block和Group description table都是全局信息，而且这些数据很重要。如果这些数据丢失了，整个文件系统都打不开了，这比一个文件的一个块损坏更严重。所以，这两部分我们都需要备份，但是采取不同的策略。 默认策略：在每个块中均保存一份超级块和块组描述表的备份 sparse_super策略：采取稀疏存储的方式，仅在块组索引为 0、3、5、7 的整数幂里存储。 Meta Block Groups策略：我们将块组分为多个元块组（Meta Block Groups)，每个元块组里面的块组描述符表仅仅包括自己的内容，一个元块组包含 64 个块组，这样一个元块组中的块组描述符表最多 64 项。这种做法类似于merkle tree，可以在很大程度上优化空间。 Super Block超级块(Super Block)描述整个分区的文件系统信息，如inode&#x2F;block的大小、总量、使用量、剩余量，以及文件系统的格式与相关信息。超级块在每个块组的开头都有一份拷贝（第一个块组必须有，后面的块组可以没有，取决于备份策略）。 为了保证文件系统在磁盘部分扇区出现物理问题的情况下还能正常工作，就必须保证文件系统的super block信息在这种情况下也能正常访问。所以一个文件系统的super block会在多个block group中进行备份，这些super block区域的数据保持一致。 超级块记录的信息有： block 与 inode 的总量（分区内所有Block Group的block和inode总量）； 未使用与已使用的 inode &#x2F; block 数量； block 与 inode 的大小 (block 为 1, 2, 4K，inode 为 128 bytes)； filesystem 的挂载时间、最近一次写入数据的时间、最近一次检验磁盘 (fsck) 的时间等文件系统的相关信息； 一个 valid bit 数值，若此文件系统已被挂载，则 valid bit 为 0 ，若未被挂载，则 valid bit 为 1 。 对于ext2&#x2F;3&#x2F;4文件系统，以上介绍的这些inode bitmap, data block bitmap和inode table，都可以通过一个名为”dumpe2fs”的工具来查看其在磁盘上的具体位置 格式每一个块组都含有inode Table和inode bitmap、Data Block和Block Bitmap来管理索引节点和数据节点。 inodeinode即index node，用来索引文件，跟踪一个文件（Linux下目录也是一种文件）所有的块，即跟踪所有的Data Block。 一个文件必须对应一个inode。 具体的inode信息存放在inode table里头。 inode bitmap &amp; Block bitmapbitmap用一个bit位来描述inode和data node的空闲状态，可以大幅节省空间。 目录文件在Linux中，目录也被视为一种文件，文件内容是文件。 对于每一个文件，存储如下内容，有两个版本的存储方式。第二个版本 ext4_dir_entry_2 是将一个 16 位的 name_len，变成了一个 8 位的 name_len 和 8 位的 file_type。 struct ext4_dir_entry &#123; __le32 inode; /* Inode number */ __le16 rec_len; /* Directory entry length */ __le16 name_len; /* Name length */ char name[EXT4_NAME_LEN]; /* File name */ &#125;; struct ext4_dir_entry_2 &#123; __le32 inode; /* Inode number */ __le16 rec_len; /* Directory entry length */ __u8 name_len; /* Name length */ __u8 file_type; char name[EXT4_NAME_LEN]; /* File name */ &#125;; 最简单的保存格式是列表，就是一项一项地将 ext4_dir_entry_2 列在哪里。每一项都会保存这个目录的下一级的文件的文件名和对应的 inode，通过这个 inode，就能找到真正的文件。第一项是“.”，表示当前目录，第二项是“…”，表示上一级目录，接下来就是一项一项的文件名和 inode。 这样的存储方式，查找的复杂度为$O(n)$，如果在 inode 中设置 EXT4_INDEX_FL 标志，则会采用哈希表来存储。目录文件的内容如下。 struct dx_root &#123; struct fake_dirent dot; char dot_name[4]; struct fake_dirent dotdot; char dotdot_name[4]; struct dx_root_info &#123; __le32 reserved_zero; u8 hash_version; u8 info_length; /* 8 */ u8 indirect_levels; u8 unused_flags; &#125; info; struct dx_entry entries[]; &#125;; 其中，每一个文件的索引信息是dx_entry。 struct dx_entry &#123; __le32 hash; __le32 block; &#125;; 大文件存储在ext2和ext3格式的文件系统中，我们用前12个块存放对应的文件数据，每个块4KB，如果文件较大放不下，则需要使用后面几个间接存储块来保存数据，下图很形象的表示了其存储原理。 该存储结构带来的问题是对于大型文件，我们需要多次调用才可以访问对应块的内容，因此访问速度较慢。为此，ext4提出了新的解决方案：Extents。简单的说，Extents以一个树形结构来连续存储文件块，从而提高访问速度，只有叶子节点才存放数据，大致结构如下图所示。 软链接和硬链接硬链接创建一个硬链接文件，指向了另一个文件的inode，由于inode是Ext文件系统的特有格式，所以是无法跨文件系统的。由于多个目录项都是指向一个 inode，那么只有删除文件的所有硬链接以及源文件时，系统才会彻底删除该文件。相当与是建立了引用，引用计数，为0才删除。 实际上，有一些注意事项 目录不允许硬链接：因为如果允许，会造成死循环。 不同分区不允许硬链接：由于inode在不同的分区是独立编号的，所以可能会重复，检索时会出现矛盾。 软链接创建一个软链接文件，保存另一个文件的完整路径和文件名。由于路径和文件名是独立于每一种文件系统的，所以软链接是可以跨文件系统的。甚至目标文件被删除了，链接文件还是在的，只不过指向的文件找不到了而已。 可以通过ln来创建链接文件。 文件操作结合上面的布局，说一说每一个操作的步骤。 文件新建 读取GDT（Group Description Table），找到各个块组中未使用的inode号，并分配。 在inode table中完善该inode号所在行的记录。 在目录的data block中添加一条该记录的目录信息。 将数据填充到data block中，并标记对应的data block的bitmap中的bit位。 文件删除删除文件分为普通文件和目录文件，知道了这两种类型的文件的删除原理，就知道了其他类型特殊文件的删除方法。 删除普通文件 找到文件的inode和data block。 首先判断文件类型，做一些特殊处理。比如如果是硬链接文件，就减一下引用计数。 从inode table中将该inode记录中的data block指针删除。 在inode bitmap中标记该inode未使用。 在对应的目录的数据部分，删除该文件的目录信息。 设置在bitmap中设置该文件的data block的未使用。 删除目录文件 找到目录和目录下所有文件、子目录、子文件和inode和data block。 在inode bitmap中将这些inode号标记为未使用；在block bitmap标记这些块未使用。 在该目录的父目录的data block中将该目录名的信息删除。需要注意的是，删除父目录是最后一步，如果该步骤提前，将报目录非空的错误，因为该目录中还有文件占用。 文件搜索例如，执行cat /etc/vimrc 命令。 找到根目录/对应的inode，并找到对应的目录数据。 在该目录数据中找到etc目录的inode。 在/etc/目录下找到vimrc的inode。最终读取数据 文件移动在相同的文件系统下（不同分区也行？），执行移动就是修改目录和inode对应的指针，不需要额外拷贝数据。 否则不同文件系统下，就需要拷贝后删除。 文件挂载挂在实际上就是inode指向了其他文件系统上的目录。 在挂载时，会新建一个inode，这个inode指向新挂载的文件系统。 同时将父目录中的旧目录信息改为这个新inode。 此外，还会将旧inode标记为不可见。 取消挂载就是删除旧inode，并设置父目录信息为旧inode，同时修改旧inode可见。 文件描述符文件描述符FD（file descriptor）在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。在程序设计中，一些涉及底层的程序编写往往会围绕着文件描述符展开。 所以，文件描述符就是用来索引一个文件的，可以通过文件描述符来操作文件。 使用 可以通过lsof查看一个文件被哪些进程打开，也可以查看当前进程打开了哪些文件。 基于Linux一切皆文件的思想，文件描述符除了可以描述普通的文件和目录，还有 管道 socket 输入输出源 其他Unix文件类型 每一个进程中，通常会有3个已经设置好的FD FD号0：标准输入 Standard input 标准输入 用于程序接受数据 FD号1：标准输出 Standard output 标准输出 用于程序输出数据 FD号2：标准错误(输出) Standard error 标准错误 用于程序输出错误或者诊断信息 输出重定向可以通过1&gt;来实现，这个1也可以不制定；错误重定向可以通过2&gt; 如，ls . &gt; info.txt 或者 ls &lt;FileThatNoExist&gt; 2&gt; error.txt 此外还可以将错误信息重定向到标准输出，如2&gt;&amp;1。 ls -al &lt;notExistFile&gt; 2&gt;&amp;1 会将错误输出作为标准输出。 对于每一个进程来说，都会维护一个文件描述符表。除此之外，系统也会维护两个表 打开文件表 inode表 整体的布局如下 注意，为什么一个进程描述符表中的不同文件指针可能指向打开文件表的同一个位置呢？因为 可能是一个线程同时先后打开一个文件。 不同线程之间共享文件描述符表，不同线程打开同一个文件。 为什么不同进程的文件描述符和文件指针完全相同呢？ 这两个进程是父子进程。 此外，为什么打开文件表不同inode指针可能指向inode表中同一个位置呢？ 因为不同进程可能打开同一个文件。 此外，注意到文件偏移量是系统表记录的，所以进程内的线程是共享文件偏移量的。 所以系统级别的打开文件表隔离出了每一个进程打开的文件和其文件偏移量，线程之间共享文件和偏移量。 代码分析在Linux下的PCB的具体化是task_struct，用来描述一个进程或者线程。其中含有两个fs_struct和files_struct的指针与文件系统联系紧密。 fs_structtask_struct中的fs指针指向fs_struct描述了当进程\\线程的可执行文件的目录信息。 struct fs_struct &#123; atomic_t count; rwlock_t lock; int umask; struct dentry * root, * pwd, * altroot; struct vfsmount * rootmnt, * pwdmnt, * altrootmnt; &#125;; count：共享这个表的进程个数 lock：用于表中字段的读&#x2F;写自旋锁 umask：当打开文件设置文件权限时所使用的位掩码 root：根目录的目录项 pwd：当前工作目录的目录项 files_structtask_strcut中的files指向了files_struct结构体，描述了当前线程\\进程打开的文件，即上面我们提到的用户级别的文件描述符表。这是每一个进程私有的，进程内的线程共享。 struct files_struct &#123; atomic_t count; struct fdtable *fdt; struct fdtable fdtab; int next_fd; struct embedded_fd_set close_on_exec_init; struct embedded_fd_set open_fds_init; struct file * fd_array[NR_OPEN_DEFAULT]; &#125;; 限制ulimit命令可以查看当前shell下的文件描述符的数量。 ulimit用于限制shell启动进程所占用的资源，作为临时限制，ulimit 可以作用于通过使用其命令登录的 shell 会话，在会话终止时便结束限制，并不影响于其他 shell 会话。而对于长期的固定限制，ulimit 命令语句又可以被添加到由登录 shell 读取的文件中，作用于特定的 shell 用户。。 用法如下 [root@Centos ~]# ulimit -a core file size (blocks, -c) 0 #core文件的最大值为100 blocks。 data seg size (kbytes, -d) unlimited #进程的数据段可以任意大。 scheduling priority (-e) 0 file size (blocks, -f) unlimited #文件可以任意大。 pending signals (-i) 3794 #最多有98304个待处理的信号。 max locked memory (kbytes, -l) 64 #一个任务锁住的物理内存的最大值为32KB。 max memory size (kbytes, -m) unlimited #一个任务的常驻物理内存的最大值。 open files (-n) 1024 #一个任务最多可以同时打开1024的文件。 pipe size (512 bytes, -p) 8 #管道的最大空间为4096字节。 POSIX message queues (bytes, -q) 819200 #POSIX的消息队列的最大值为819200字节。 real-time priority (-r) 0 stack size (kbytes, -s) 10240 #进程的栈的最大值为10240字节。 cpu time (seconds, -t) unlimited #进程使用的CPU时间。 max user processes (-u) 1024 #当前用户同时打开的进程（包括线程）的最大个数为98304。 virtual memory (kbytes, -v) unlimited #没有限制进程的最大地址空间。 file locks (-x) unlimited #所能锁住的文件的最大个数没有限制。 Linux默认的文件打开数是1024,现在设置打开数为2048. [root@Centos ~]# ulimit -n --查看打开数为1024 1024 [root@Centos ~]# ulimit -n 2048 --设置打开数为2048 [root@Centos ~]# ulimit -n --再次查看 2048 管道使用系统操作执行命令的时候，经常有需求要将一个程序的输出交给另一个程序进行处理，这种操作可以使用输入输出重定向加文件搞定，比如： epoch@Ubuntu:~ $ ls /etc/ &gt; etc.txt epoch@Ubuntu:~ $ wc -l etc.txt 这样的操作是频繁的，所以有必要简化一下。就引入了管道的概念。 可以使用“|”连接两个命令，shell会将前后两个进程的输入输出用一个管道相连，以便达到进程间通信的目的。上述两个步骤即可合并成一句。 epoch@Ubuntu:~ $ ls -l /etc/ | wc -l Linux系统直接把管道实现成了一种文件系统，借助VFS给应用程序提供操作接口。 虽然实现形态上是文件，但是管道本身并不占用磁盘或者其他外部存储的空间。在Linux的实现上，它占用的是内存空间。所以，Linux上的管道就是一个操作方式为文件的内存缓冲区。 创建过程如下 类型Linux上的管道分两种类型： 匿名管道\\无名管道 命名管道\\有名管道 匿名管道：最常见的形态就是我们在shell操作中最常用的”|”。它的特点是只能在父子进程中使用，父进程在产生子进程前必须打开一个管道文件，然后fork产生子进程，这样子进程通过拷贝父进程的进程地址空间获得同一个管道文件的描述符，以达到使用同一个管道通信的目的。 命名管道：由于匿名管道只能在父子进程中使用，为了扩展使用，出现了命名管道。 mkfifo或mknod命令来创建一个命名管道，这跟创建一个文件没有什么区别 原理及实现在Linux中，管道的实现并没有使用专门的数据结构，而是借助了文件系统的file结构和VFS的索引节点inode。通过将两个file结构指向同一个临时的inode节点，而这个inode又指向一个物理页面而实现的。如下图有两个 file 数据结构，但它们定义文件操作例程地址是不同的，其中一个是向管道中写入数据的例程地址而另一个是从管道中读出数据的例程地址。 当然，读写是需要互斥的，为此，内核使用了锁、等待队列和信号。 写之前需要判断，管道未加锁，并且内存中有足够空间存储写入的数据；写前加锁，写入后，解锁，而所有休眠在索引节点的读取进程会被唤醒。 这样，用户程序的系统调用仍然是通常的文件操作，而内核却利用这种抽象机制实现了管道这一特殊操作。 管道默认是阻塞的，如果数据会阻塞等待数据的到来；可以设置非阻塞，通过设置管道的打开模式。 可以通过pstree -p &lt;pid&gt; 命令查看进程的父子关系。 通过这个命令可以找到匿名管道的两头的进程pid。举例如下 首先创建一个匿名管打并阻塞，阻塞方便打开另一个shell查看信息。 [lizhipeng@CentOS7 ~]$ &#123; echo $BASHPID; read x ; &#125; | &#123; cat ; echo $BASHPID; read y; &#125; [lizhipeng@CentOS7 ~]$ pstree -p ... ─sshd(36387)───bash(36388)─┬─bash(37057+ │ │ └─bash(37058+ │ └─sshd(36713)───sshd(36717)───bash(36718)───pstree(370+ ... 查看这两个父子进程的fd信息。 [lizhipeng@CentOS7 fd]$ ls -alt /proc/37057/fd 总用量 0 lrwx------. 1 lizhipeng lizhipeng 64 11月 17 13:33 0 -&gt; /dev/pts/4 l-wx------. 1 lizhipeng lizhipeng 64 11月 17 13:33 1 -&gt; pipe:[253711] lrwx------. 1 lizhipeng lizhipeng 64 11月 17 13:33 2 -&gt; /dev/pts/4 lrwx------. 1 lizhipeng lizhipeng 64 11月 17 13:33 255 -&gt; /dev/pts/4 dr-x------. 2 lizhipeng lizhipeng 0 11月 17 13:33 . dr-xr-xr-x. 9 lizhipeng lizhipeng 0 11月 17 13:30 .. [lizhipeng@CentOS7 fd]$ ls -alt /proc/37058/fd 总用量 0 lr-x------. 1 lizhipeng lizhipeng 64 11月 17 13:34 0 -&gt; pipe:[253711] lrwx------. 1 lizhipeng lizhipeng 64 11月 17 13:34 1 -&gt; /dev/pts/4 lrwx------. 1 lizhipeng lizhipeng 64 11月 17 13:34 2 -&gt; /dev/pts/4 lrwx------. 1 lizhipeng lizhipeng 64 11月 17 13:34 255 -&gt; /dev/pts/4 dr-x------. 2 lizhipeng lizhipeng 0 11月 17 13:34 . dr-xr-xr-x. 9 lizhipeng lizhipeng 0 11月 17 13:30 .. 不难发现，37057 通过重定向 1 号文件描述符来讲管道 重定向到了 37058 的0号描述符。这就是匿名管道。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://messenger1th.github.io/categories/Linux/"}],"tags":[]},{"title":"prefix","slug":"LeetCode/prefix","date":"2024-07-24T14:47:33.965Z","updated":"2024-07-24T14:47:33.965Z","comments":true,"path":"2024/07/24/LeetCode/prefix/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/LeetCode/prefix/","excerpt":"","text":"前缀和应用场景：不变区间, 区间求和. 一维: 数组 325. 和等于 k 的最长子数组长度 523. 连续的子数组和 560. 和为 K 的子数组 写下来不难发现, 这几个题目都是取左闭右开的区间, 即 (prev, i]. 对于统计长度的题目, 需要初始化哈希表prefix[0] = -1; 对于统计个数的题目, 需要初始为prefix[0] = 1 此外, 也可以是特殊的区间和, 比如: 权值为1-次数. 1248. 统计「优美子数组」 525. 连续数组 1371. 每个元音包含偶数次的最长子字符串 并且, 可以搭配一些定理来使用, 如: 同余定理 974. 和可被 K 整除的子数组 二维: 矩阵 304. 二维区域和检索 - 矩阵不可变 1314. 矩阵区域和 以上两个题目都是二维前缀和, 除此之外, 可以将二维和压缩为一维, 当成数组前缀和来做 85. 最大矩形 1074. 元素和为目标值的子矩阵数量 363. 矩形区域不超过 K 的最大数值和 面试题 17.24. 最大子矩阵 推广: 前缀异或-前缀乘积 1310. 子数组异或查询 除了上述题目的左开右闭区间, (prev, i], 还有左闭右开[prev, i), 具体取决于题意. 此时, 就不需要进行prefix[0] = **的预处理. 1442. 形成两个异或相等数组的三元组数目 1352. 最后 K 个数的乘积","categories":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://messenger1th.github.io/categories/LeetCode/"}],"tags":[]},{"title":"常用算法","slug":"LeetCode/常用算法","date":"2024-07-24T14:47:33.965Z","updated":"2024-07-24T14:47:33.965Z","comments":true,"path":"2024/07/24/LeetCode/常用算法/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/LeetCode/%E5%B8%B8%E7%94%A8%E7%AE%97%E6%B3%95/","excerpt":"","text":"常用算法二分查找 三种： 普通 lower_bound upper_bound 找到 &#x3D; 第一个 &gt;&#x3D; 第一个 &gt; 模板题：34. 在排序数组中查找元素的第一个和最后一个位置 300. 最长递增子序列 354. 俄罗斯套娃信封问题 1996. 游戏中弱角色的数量 进阶 满足二段性即可使用二分查找 不满足时候考虑恢复二段性 判断结果时,可用一个res直接接收,或者让闭区间的那边是属于结果的. 153. 寻找旋转排序数组中的最小值 154. 寻找旋转排序数组中的最小值 II 33. 搜索旋转排序数组 81. 搜索旋转排序数组 II 1482. 制作 m 束花所需的最少天数 1011. 在 D 天内送达包裹的能力 540. 有序数组中的单一元素 875. 爱吃香蕉的珂珂 1231. Divide Chocolate 前缀和+二分查找 根据元素大于等于0，前缀和数组符合单调不减性， 可以使用二分。 有序集合+二分查找 当元素存在非正时， 可以使用有序集合来二分。 1099. 小于 K 的两数之和 729. My Calendar I 363. 矩形区域不超过 K 的最大数值和 1606. Find Servers That Handled Most Number of Requests 456. 132 Pattern 2034. Stock Price Fluctuation 219. Contains Duplicate II 220. Contains Duplicate III 数学数组\\字符串左移\\右移 剑指 Offer 58 - II. 左旋转字符串 189. 轮转数组 先局部后整体是左移，先整体后局部是右移。其实也可以都先整体，只不过左移就需要调整右边长度为n 二分查找博客总结的很好, 我也分享一下我了解的吧.除了楼主提到的模板题, 模板题还有(即C++中的lower_bound和upper_bound函数实现) 34. 在排序数组中查找元素的第一个和最后一个位置 1. 直接定义res获取答案 可以避免陷入结果究竟是取l, l+1下标对应地元素等细节问题, 如29. 两数相除 class Solution &#123; public: bool mul(int x, int n, int comp) &#123; int res = 0; while (n) &#123; if (n &amp; 1) &#123; if (res &lt; comp - x) &#123; return false; &#125; res = res + x; &#125; n &gt;&gt;= 1; if (n == 0) break; else if (x &lt; comp - x) return false; x += x; &#125; return true; &#125; int divide(int a, int b) &#123; if (a == INT_MIN) &#123; if (b == -1) &#123; return INT_MAX; &#125; else if (b == 1) &#123; return INT_MIN; &#125; &#125; bool rev = false; if (a &gt; 0) &#123; a = -a; rev = !rev; &#125; if (b &gt; 0) &#123; b = -b; rev = !rev; &#125; int l = 0, r = INT_MAX; int res = 0; while (l &lt;= r) &#123; int mid = ((r - l) &gt;&gt; 1) + l; if (mul(b, mid, a)) &#123; res = mid; //直接在符合条件的mid处, 设置为res if (mid == INT_MAX) &#123; break; &#125; l = mid + 1; &#125; else &#123; r = mid - 1; &#125; &#125; return rev ? -res : res; &#125; &#125;; 题解本身有点复杂, 理解用res接收答案即可.当然, 理解到底是哪个下标取答案是很有必要的, 对于二分查找的深入理解必不可少. 2. 二分查找的应用不止于单调性, 符合二段性即可 满足二段性即可使用二分查找不满足时候可以考虑恢复二段性 通常来说, 需要定义一个check(mid)函数来判断移动left还是right, 如例题 1482. 制作 m 束花所需的最少天数 1011. 在 D 天内送达包裹的能力 875. 爱吃香蕉的珂珂 1231. Divide Chocolate 3. 拓展 这部分对二分查找的应用需要对二分查找有一个很深的理解, 给出题目 153. 寻找旋转排序数组中的最小值 154. 寻找旋转排序数组中的最小值 II 33. 搜索旋转排序数组 81. 搜索旋转排序数组 II","categories":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://messenger1th.github.io/categories/LeetCode/"}],"tags":[]},{"title":"求职笔试题目","slug":"LeetCode/求职笔试题目","date":"2024-07-24T14:47:33.965Z","updated":"2024-07-24T14:47:33.965Z","comments":true,"path":"2024/07/24/LeetCode/求职笔试题目/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/LeetCode/%E6%B1%82%E8%81%8C%E7%AC%94%E8%AF%95%E9%A2%98%E7%9B%AE/","excerpt":"","text":"笔试常见题目2023年 秋招 滴滴 第二场笔试 9.15 1552. 两球之间的磁力 2290. 到达角落需要移除障碍物的最小数目","categories":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://messenger1th.github.io/categories/LeetCode/"}],"tags":[]},{"title":"常见题目系列","slug":"LeetCode/常见题目系列","date":"2024-07-24T14:47:33.965Z","updated":"2024-07-24T14:47:33.965Z","comments":true,"path":"2024/07/24/LeetCode/常见题目系列/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/LeetCode/%E5%B8%B8%E8%A7%81%E9%A2%98%E7%9B%AE%E7%B3%BB%E5%88%97/","excerpt":"","text":"常见题目系列括号 判断是否有效：计数即可 最长有效：双向遍历、计数重置 括号生成：回溯 移除：Stack、set记录删除位置 最小移除次数：BFS 20. 有效的括号 32. 最长有效括号 678. 有效的括号字符串 22. 括号生成 1249. 移除无效的括号 301. 删除无效的括号 后缀表达式 224. 基本计算器 227. 基本计算器 II 772. 基本计算器 III 394. 字符串解码 150. 逆波兰表达式求值 排列组合 31. 下一个排列 TopK 703. 数据流中的第 K 大元素 215. 数组中的第K个最大元素 347. 前 K 个高频元素 前缀树 Trie回文串214. 最短回文串","categories":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://messenger1th.github.io/categories/LeetCode/"}],"tags":[]},{"title":"Not Sorted","slug":"LeetCode/Not Sorted","date":"2024-07-24T14:47:33.964Z","updated":"2024-07-24T14:47:33.964Z","comments":true,"path":"2024/07/24/LeetCode/Not Sorted/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/LeetCode/Not%20Sorted/","excerpt":"","text":"Not Sorted1825. Finding MK Average","categories":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://messenger1th.github.io/categories/LeetCode/"}],"tags":[]},{"title":"SQL","slug":"LeetCode/SQL","date":"2024-07-24T14:47:33.964Z","updated":"2024-07-24T14:47:33.964Z","comments":true,"path":"2024/07/24/LeetCode/SQL/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/LeetCode/SQL/","excerpt":"","text":"MySQL执行顺序 from on join where group by(开始使用select中的别名，后面的语句中都可以使用) avg,sum…. having select distinct order by limit 流程控制判断语句 IF CASE WHEN LeetCode 627. Swap Salary 聚合函数CountSumgroup_concat 1484. 按日期分组销售产品 API日期DATE_FORMAT(date, format) ：用于以不同的格式显示日期&#x2F;时间数据。date 参数是合法的日期，format 规定日期&#x2F;时间的输出格式。 DATE_FORMAT(trans_date, &#x27;%Y-%m-%d&#x27;) -- 其中%Y m d 都是占位符号，分别代表年月日 1193. 每月交易 I 精度Round(value, digit) ：对value，保留digit位小数，四舍五入。round(1.555, 2) = 1.56 1211. 查询结果的质量和占比 横竖表转换查询联结 左联结：1378. 使用唯一标识码替换员工ID 175. 组合两个表 右联结：其实和左联结类似，都可以通过 内联结 子查询 1581. Customer Who Visited but Did Not Make Any Transactions 窗口函数 534. Game Play Analysis III dense_rank()：185. 部门工资前三高的所有员工 问题 两个表联结后，为什么可以删原表？196. Delete Duplicate Emails 待分类 1661. 每台机器的进程平均运行时间 一列中的种元素，需要拼到不同的列。 176. 第二高的薪水","categories":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://messenger1th.github.io/categories/LeetCode/"}],"tags":[]},{"title":"Others","slug":"LeetCode/Others","date":"2024-07-24T14:47:33.964Z","updated":"2024-07-24T14:47:33.964Z","comments":true,"path":"2024/07/24/LeetCode/Others/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/LeetCode/Others/","excerpt":"","text":"Others原地哈希 448. 找到所有数组中消失的数字 442. 数组中重复的数据 41. 缺失的第一个正数 细节处理 4. 寻找两个正序数组的中位数 7. 整数反转 8. 字符串转换整数 (atoi) 29. 两数相除 65. 有效数字 模拟 54. 螺旋矩阵 59. 螺旋矩阵 II 885. 螺旋矩阵 III 6. Z 字形变换 技巧 26. 删除有序数组中的重复项 80. 删除有序数组中的重复项 II 括号问题 32. Longest Valid Parentheses 301. Remove Invalid Parentheses 扫描线问题 759. Employee Free Time 218. The Skyline Problem 391. Perfect Rectangle","categories":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://messenger1th.github.io/categories/LeetCode/"}],"tags":[]},{"title":"SlidingWindow","slug":"LeetCode/SlidingWindow","date":"2024-07-24T14:47:33.964Z","updated":"2024-07-24T14:47:33.964Z","comments":true,"path":"2024/07/24/LeetCode/SlidingWindow/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/LeetCode/SlidingWindow/","excerpt":"","text":"滑动窗口 Sliding Window 滑动窗口一定是连续的，因此子数组类题目才能用。也有在数组两头的，一头变长一头减短。 移动窗口时变动的值最好是与两头的数据直接相关的，像是239. 滑动窗口最大值中取的是最大值，因此需要花$O(k)$的时间去获取最大值，总体为$O（n*k)$时间复杂度，对于Hard题是TEL的。 一般滑动窗口都是对容器内元素的__个数或者种类__进行限制，例如窗口内不能出现重复元素，元素种类只能有$k$种等。 固定大小滑动窗口 这种是最简单的，只需要对窗口进出元素进行简单运算即可 643. 子数组最大平均数 I 1052. 爱生气的书店老板 1423. 可获得的最大点数 1151. 最少交换次数来组合所有的 1 对窗口内元素的个数、种类、和或乘积等进行限制 __最大最长__，因此每次增长时，窗口内可能不满足条件，要缩小窗口到满足条件才能收集$res$. 3. 无重复字符的最长子串 1695. 删除子数组的最大得分 1208. 尽可能使字符串相等 1493. 删掉一个元素以后全为 1 的最长子数组 487. 最大连续1的个数 II 1004. 最大连续1的个数 III 904. 水果成篮 159. 至多包含两个不同字符的最长子串 340. 至多包含 K 个不同字符的最长子串 2024. 考试的最大困扰度 424. 替换后的最长重复字符 713. 乘积小于K的子数组 子串“匹配” 通常用一个计数器$differentNum$来判断是否匹配，不用每次都遍历子串来$check$ 字符限定时，可以用静态数组来充当哈希表。 567. 字符串的排列 438. 找到字符串中所有字母异位词 76. 最小覆盖子串 求满足条件的最小值 窗口内是要求满足条件的，但要求最小值，因此在缩小窗口时收集$res$. 209. 长度最小的子数组 76. 最小覆盖子串 995. K 连续位的最小翻转次数30. 串联所有单词的子串","categories":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://messenger1th.github.io/categories/LeetCode/"}],"tags":[]},{"title":"Stack&Queue","slug":"LeetCode/Stack&Queue","date":"2024-07-24T14:47:33.964Z","updated":"2024-07-24T14:47:33.964Z","comments":true,"path":"2024/07/24/LeetCode/Stack&Queue/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/LeetCode/Stack&Queue/","excerpt":"","text":"栈和队列 20. 有效的括号 232. 用栈实现队列 225. 用队列实现栈 1047. 删除字符串中的所有相邻重复项 445. 两数相加 II 150. 逆波兰表达式求值 946. 验证栈序列 224. 基本计算器 227. 基本计算器 II 772. 基本计算器 III 394. 字符串解码 单调栈 如果需要找到左边或者右边第一个比当前位置的数大或者小，则可以考虑使用单调栈 739. 每日温度 496. 下一个更大元素 I 503. 下一个更大元素 II 1673. 找出最具竞争力的子序列 1996. 游戏中弱角色的数量 42. 接雨水 84. 柱状图中最大的矩形 2104. 子数组范围和 901. 股票价格跨度 找到左边第一个小于该元素的元素的下标。 402. 移掉 K 位数字 316. 去除重复字母 456. 132 Pattern 单调队列 单调双端队列 239. 滑动窗口最大值 剑指 Offer 59 - II. 队列的最大值 918. 环形子数组的最大和 优先队列 应用场景：多次快速取最值 239. 滑动窗口最大值 295. 数据流的中位数 230. 二叉搜索树中第K小的元素 253. 会议室 II 23. 合并K个升序链表 215. 数组中的第K个最大元素 347. 前 K 个高频元素 973. 最接近原点的 K 个点","categories":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://messenger1th.github.io/categories/LeetCode/"}],"tags":[]},{"title":"Sort","slug":"LeetCode/Sort","date":"2024-07-24T14:47:33.964Z","updated":"2024-07-24T14:47:33.964Z","comments":true,"path":"2024/07/24/LeetCode/Sort/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/LeetCode/Sort/","excerpt":"","text":"数组排序 148. 排序链表 冒泡排序 选择排序 堆排序 插入排序 希尔排序 归并排序 快速排序 &#x3D;&#x3D;时交换好处是避免了很多没用的交换。坏处是移动到中间的机会减小了。 当数据规模小时，可以直接调用普通排序，定义一个阈值cutoff。 桶排序计数排序适用于数据有范围的情况。数据大效果明显。 基数排序 记得要clear。 快速选择Parition 堆排 时间$n$. 第几大的元素，仅适用静态元素 时间:$n\\log{n}$.可适用于动态元素 215. 数组中的第K个最大元素 外排序以上都是内部排序。 外排序（External sorting）是指能够处理极大量数据的排序算法。通常来说，外排序处理的数据不能一次装入内存，只能放在读写较慢的外存储器（通常是硬盘）上。外排序通常采用的是一种“排序-归并”的策略。在排序阶段，先读入能放在内存中的数据量，将其排序输出到一个临时文件，依此进行，将待排序数据组织为多个有序的临时文件。而后在归并阶段将这些临时文件组合为一个大的有序文件，也即排序结果。 常用的外排序有外归并排序，原理和内归并排序一样，不过每一轮结果写入到文件，还有外分配排序，其原理类似于内排序中的桶排序。","categories":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://messenger1th.github.io/categories/LeetCode/"}],"tags":[]},{"title":"Template","slug":"LeetCode/Template","date":"2024-07-24T14:47:33.964Z","updated":"2024-07-24T14:47:33.964Z","comments":true,"path":"2024/07/24/LeetCode/Template/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/LeetCode/Template/","excerpt":"","text":"Frequent TemplateShortest Path最短路径Dijkstraclass Solution &#123; public: vector&lt;int&gt; getPath(vector&lt;int&gt;&amp; path, int src, int tar) &#123; //nodes from 1 -&gt; n; vector&lt;int&gt; nodeSeq; int cur = tar; while (path[cur] != -1) &#123; nodeSeq.emplace_back(cur); cur = path[cur]; &#125; nodeSeq.emplace_back(src); reverse(nodeSeq.begin(), nodeSeq.end()); return nodeSeq; &#125; int networkDelayTime(vector&lt;vector&lt;int&gt;&gt;&amp; times, int n, int src) &#123; //nodes from 1 -&gt; n; const int Inf = INT_MAX / 2; vector&lt;vector&lt;int&gt;&gt; graph(n, vector&lt;int&gt; (n, Inf)); for (const auto&amp; edge: times) &#123; int from = edge[0] - 1, to = edge[1] - 1, cost = edge[2]; graph[from][to] = cost; &#125; for (int i = 0; i &lt; n; ++i) &#123; graph[i][i] = 0; &#125; priority_queue&lt;pair&lt;int, int&gt;, vector&lt;pair&lt;int, int&gt;&gt;, greater&lt;pair&lt;int, int&gt;&gt;&gt; pq; vector&lt;int&gt; dist(n, Inf); vector&lt;bool&gt; visited(n, false); vector&lt;int&gt; path(n, -1); pq.emplace(0, src - 1); dist[src - 1] = 0; while (!pq.empty()) &#123; pair&lt;int, int&gt; p = pq.top(); pq.pop(); int cur = p.second; if (visited[cur]) &#123;//add visited array to avoid useless traversal continue; &#125; visited[cur] = true; for (int i = 0; i &lt; n; ++i) &#123; if (dist[i] &gt; dist[cur] + graph[cur][i]) &#123; dist[i] = dist[cur] + graph[cur][i]; pq.emplace(dist[i], i); path[i] = cur; &#125; &#125; &#125; vector&lt;int&gt; pathNodes = getPath(path, src - 1); for (auto node: pathNodes) cout &lt;&lt; node + 1 &lt;&lt; &#x27; &#x27;; int maxDistance = *max_element(dist.begin(), dist.end()); return maxDistance == Inf ? -1 : maxDistance; &#125; &#125;; Floydvector&lt;int&gt; getPath(); int Floyd(vector&lt;vector&lt;int&gt;&gt;&amp; times, int n, int src) &#123; //nodes from 1 -&gt; n; const int Inf = INT_MAX / 2; vector&lt;vector&lt;int&gt;&gt; graph(n, vector&lt;int&gt; (n, Inf)); for (int i = 0; i &lt; n; ++i) &#123; graph[i][i] = 0; &#125; for (const auto&amp; edge: times) &#123; int from = edge[0] - 1, to = edge[1] - 1, cost = edge[2]; graph[from][to] = cost; &#125; for (int k = 0; k &lt; n; ++k) &#123; for (int i = 0; i &lt; n; ++i) &#123; for (int j = 0; j &lt; n; ++j) &#123; graph[i][j] = min(graph[i][j], graph[i][k] + graph[k][j]); &#125; &#125; &#125; int maxDistance = *max_element(graph[src - 1].begin(), graph[src - 1].end()); return maxDistance == Inf ? -1 : maxDistance; &#125; SPFAint SPFA(vector&lt;vector&lt;int&gt;&gt;&amp; edges, int n, int src) &#123; //nodes from 1 -&gt; n; const int Inf = INT_MAX / 2; vector&lt;vector&lt;int&gt;&gt; graph(n, vector&lt;int&gt; (n, Inf)); for (int i = 0; i &lt; n; ++i) &#123; graph[i][i] = 0; &#125; for (const auto&amp; edge: edges) &#123; int from = edge[0] - 1, to = edge[1] - 1, cost = edge[2]; graph[from][to] = cost; &#125; vector&lt;int&gt; dist(n, Inf); vector&lt;bool&gt; inQ(n, false); dist[src - 1] = 0; inQ[src - 1] = true; queue&lt;int&gt; Q; Q.emplace(src - 1); while (!Q.empty()) &#123; int cur = Q.front(); Q.pop(); inQ[cur] = false; for (int i = 0; i &lt; n; ++i) &#123; if (dist[i] &gt; dist[cur] + graph[cur][i]) &#123; dist[i] = dist[cur] + graph[cur][i]; if (!inQ[i]) &#123; Q.emplace(i); inQ[i] = true; &#125; &#125; &#125; &#125; int maxDistance = *max_element(dist.begin(), dist.end()); return maxDistance == Inf ? -1 : maxDistance; &#125; ``` ## Minimum Spanning Tree最小生成树 ### Prim ```cpp int Prim(vector&lt;vector&lt;int&gt;&gt;&amp; edges, int n) &#123; const int Inf = INT_MAX / 2; vector&lt;vector&lt;int&gt;&gt; graph(n, vector&lt;int&gt; (n, Inf)); for (int i = 0; i &lt; n; ++i) &#123; graph[i][i] = 0; &#125; for (const auto&amp; edge: edges) &#123; int p1 = edge[0] - 1, p2 = edge[1] - 1, cost = edge[2]; graph[p1][p2] = graph[p2][p1] = cost; &#125; vector&lt;bool&gt; visited(n, false); vector&lt;int&gt; dist(n, Inf); dist[0] = 0; priority_queue&lt;pair&lt;int, int&gt;, vector&lt;pair&lt;int, int&gt;&gt;, greater&lt;pair&lt;int, int&gt;&gt;&gt; pq; pq.emplace(0, 0); int res = 0; int connectedNum = 0; while(!pq.empty()) &#123; pair&lt;int, int&gt; p = pq.top(); pq.pop(); int cur = p.second; if (visited[cur]) &#123; continue; &#125; ++connectedNum; res += p.first; visited[cur] = true; for (int i = 0; i &lt; n; ++i) &#123; if (dist[i] &gt; graph[cur][i]) &#123; dist[i] = graph[cur][i]; pq.emplace(dist[i], i); &#125; &#125; &#125; return n == connectedNum ? res : - 1; &#125; UnionFind并查集class UnionFind &#123; public: UnionFind(int n): rank(n, 1) &#123; parent.reserve(n); for (int i = 0; i &lt; n; ++i) &#123; parent.emplace_back(i); &#125; &#125; bool IsConnected(int x, int y) &#123; return find(x) == find(y); &#125; bool Unite(int x, int y) &#123; int rootX = find(x), rootY = find(y); if (rootX == rootY) &#123; return false; &#125; if (rank[rootX] &lt; rank[rootY]) &#123; parent[rootX] = rootY; &#125; else if (rank[rootX] &gt; rank[rootY]) &#123; parent[rootY] = rootX; &#125; else &#123; parent[rootX] = rootY; ++rank[rootY]; &#125; return true; &#125; private: int find(int x) &#123; if (x != parent[x]) &#123; parent[x] = find(parent[x]); &#125; return parent[x]; &#125; vector&lt;int&gt; parent; vector&lt;int&gt; rank; &#125;; Kruskalclass UnionFind &#123; public: UnionFind(int n) &#123; parent.resize(n); rank.resize(n); for (int i = 0; i &lt; n; ++i) &#123; parent[i] = i; rank[i] = 1; &#125; &#125; int find(int i) &#123; if (i != parent[i]) &#123; parent[i] = find(parent[i]); &#125; return parent[i]; &#125; bool unite(int x, int y) &#123; int rootX = find(x); int rootY = find(y); if (rootX != rootY) &#123; if (rank[rootX] &lt;= rank[rootY]) &#123; if (rank[rootX] == rank[rootY]) &#123; ++rank[rootY]; &#125; parent[rootX] = rootY; &#125; else &#123; parent[rootY] = rootX; &#125; return true; &#125; return false; &#125; private: vector&lt;int&gt; parent; vector&lt;int&gt; rank; &#125;; int Kruskal(vector&lt;vector&lt;int&gt;&gt;&amp; edges, int n) &#123; sort(edges.begin(), edges.end(), [](const vector&lt;int&gt;&amp; edge1, const vector&lt;int&gt;&amp; edge2) &#123; return edge1[2] &lt; edge2[2]; &#125;); int connectedNum = 1; int res = 0; UnionFind uf(n); for (const auto&amp; edge: edges) &#123; int p1 = edge[0] - 1, p2 = edge[1] - 1, cost = edge[2]; if (uf.unite(p1, p2)) &#123; res += cost; ++connectedNum; &#125; &#125; return connectedNum == n ? res : -1; &#125; int SPFA(vector&lt;vector&lt;int&gt;&gt;&amp; edges, int n, int src) &#123; //nodes from 1 -&gt; n; const int Inf = INT_MAX / 2; vector&lt;vector&lt;int&gt;&gt; graph(n, vector&lt;int&gt; (n, Inf)); for (int i = 0; i &lt; n; ++i) &#123; graph[i][i] = 0; &#125; for (const auto&amp; edge: edges) &#123; int from = edge[0] - 1, to = edge[1] - 1, cost = edge[2]; graph[from][to] = cost; &#125; vector&lt;int&gt; dist(n, Inf); vector&lt;bool&gt; inQ(n, false); dist[src - 1] = 0; inQ[src - 1] = true; queue&lt;int&gt; Q; Q.emplace(src - 1); while (!Q.empty()) &#123; int cur = Q.front(); Q.pop(); inQ[cur] = false; for (int i = 0; i &lt; n; ++i) &#123; if (dist[i] &gt; dist[cur] + graph[cur][i]) &#123; dist[i] = dist[cur] + graph[cur][i]; if (!inQ[i]) &#123; Q.emplace(i); inQ[i] = true; &#125; &#125; &#125; &#125; int maxDistance = *max_element(dist.begin(), dist.end()); return maxDistance == Inf ? -1 : maxDistance; &#125; Segment Tree线段树区间加法 tag[]表示加法懒标记 //add to the interval block #include&lt;bits/stdc++.h&gt; using namespace std; int n, m; typedef long long ll; const int MAXN = 1e5 + 10; ll arr[MAXN], sum[MAXN&lt;&lt;2], tag[MAXN&lt;&lt;2]; inline int lc(int p) &#123; return p &lt;&lt; 1; &#125; inline int rc(int p) &#123; return p &lt;&lt; 1 | 1; &#125; void pushUp(int p) &#123; sum[p] = sum[lc(p)] + sum[rc(p)]; &#125; void build(int p, int l, int r) &#123; if (l == r) &#123; sum[p] = arr[l]; return; &#125; int mid = ((r - l) &gt;&gt; 1) + l; build(lc(p), l, mid); build(rc(p), mid + 1, r); pushUp(p); &#125; void lazy(int p, ll val, int l, int r) &#123; tag[p] += val; sum[p] += val * (r - l + 1); &#125; void pushDown(int p, int l, int r) &#123; int mid = ((r - l) &gt;&gt; 1) + l; lazy(lc(p), tag[p], l, mid); lazy(rc(p), tag[p], mid + 1, r); tag[p] = 0; &#125; void update(int p, ll val, int updateL, int updateR, int l, int r) &#123; if (updateL &lt;= l &amp;&amp; r &lt;= updateR) &#123; lazy(p, val, l, r); return; &#125; int mid = ((r - l) &gt;&gt; 1) + l; if (tag[p] != 0) &#123; pushDown(p, l, r); &#125; if (updateL &lt;= mid) update(lc(p), val, updateL, updateR, l, mid); if (updateR &gt; mid) update(rc(p), val, updateL, updateR, mid + 1, r); pushUp(p); &#125; ll query(int p, int queryL, int queryR, int l, int r) &#123; if (queryL &lt;= l &amp;&amp; r &lt;= queryR) &#123; return sum[p]; &#125; int mid = ((r - l) &gt;&gt; 1) + l; if (tag[p] != 0) &#123; pushDown(p, l, r); &#125; ll res = 0; if (queryL &lt;= mid) res += query(lc(p), queryL, queryR, l, mid); if (queryR &gt; mid) res += query(rc(p), queryL, queryR, mid + 1, r); return res; &#125; int main() &#123; int l, r; ll val; cin &gt;&gt; n &gt;&gt; m; for (int i = 1; i &lt;= n; ++i) &#123; scanf(&quot;%lld&quot;, &amp;arr[i]); &#125; build(1, 1, n); while (m--) &#123; int choice; cin &gt;&gt; choice; if (choice == 1) &#123; scanf(&quot;%d%d%lld&quot;, &amp;l, &amp;r, &amp;val); update(1, val, l, r, 1, n); &#125; else if (choice == 2) &#123; scanf(&quot;%d%d&quot;, &amp;l, &amp;r); printf(&quot;%lld\\n&quot;,query(1, l, r, 1, n)); &#125; &#125; return 0; &#125; 区间乘法和加法 mul[]和add[] #include&lt;bits/stdc++.h&gt; using namespace std; int n, m, mod; typedef long long ll; const int MAXN = 1e5 + 10; ll arr[MAXN], sum[MAXN&lt;&lt;2], add[MAXN&lt;&lt;2], mul[MAXN&lt;&lt;2]; inline int lc(int p) &#123; return p &lt;&lt; 1; &#125; inline int rc(int p) &#123; return p &lt;&lt; 1 | 1; &#125; void pushUp(int p) &#123; sum[p] = (sum[lc(p)] + sum[rc(p)]) % mod; &#125; void build(int p, int l, int r) &#123; mul[p] = 1; if (l == r) &#123; sum[p] = arr[l]; return; &#125; int mid = ((r - l) &gt;&gt; 1) + l; build(lc(p), l, mid); build(rc(p), mid + 1, r); pushUp(p); &#125; void pushDown(int p, int l, int r) &#123; int mid = ((r - l) &gt;&gt; 1) + l; sum[lc(p)] = (sum[lc(p)] * mul[p] + add[p] * (mid - l + 1)) % mod; sum[rc(p)] = (sum[rc(p)] * mul[p] + add[p] * (r - mid)) % mod; mul[lc(p)] = (mul[p] * mul[lc(p)]) % mod; mul[rc(p)] = (mul[p] * mul[rc(p)]) % mod; add[lc(p)] = (add[p] + add[lc(p)] * mul[p]) % mod; add[rc(p)] = (add[p] + add[rc(p)] * mul[p]) % mod; add[p] = 0; mul[p] = 1; &#125; void updateMul(int p, ll k, int updateL, int updateR, int l, int r) &#123; if (updateL &lt;= l &amp;&amp; r &lt;= updateR) &#123; add[p] = (add[p] * k) % mod; mul[p] = (mul[p] * k) % mod; sum[p] = (sum[p] * k) % mod; return; &#125; int mid = ((r - l) &gt;&gt; 1) + l; if (add[p] != 0 || mul[p] != 1) &#123; pushDown(p, l, r); &#125; if (updateL &lt;= mid) updateMul(lc(p), k, updateL, updateR, l, mid); if (updateR &gt; mid) updateMul(rc(p), k, updateL, updateR, mid + 1, r); pushUp(p); &#125; void updateAdd(int p, ll val, int updateL, int updateR, int l, int r) &#123; if (updateL &lt;= l &amp;&amp; r &lt;= updateR) &#123; add[p] = (add[p] + val) % mod; sum[p] = (sum[p] + val * (r - l + 1)) % mod; return; &#125; int mid = ((r - l) &gt;&gt; 1) + l; if (add[p] != 0 || mul[p] != 1) &#123; pushDown(p, l, r); &#125; if (updateL &lt;= mid) updateAdd(lc(p), val, updateL, updateR, l, mid); if (updateR &gt; mid) updateAdd(rc(p), val, updateL, updateR, mid + 1, r); pushUp(p); &#125; ll query(int p, int queryL, int queryR, int l, int r) &#123; if (queryL &lt;= l &amp;&amp; r &lt;= queryR) &#123; return sum[p]; &#125; int mid = ((r - l) &gt;&gt; 1) + l; if (add[p] != 0 || mul[p] != 1) &#123; pushDown(p, l, r); &#125; ll res = 0; if (queryL &lt;= mid) res += query(lc(p), queryL, queryR, l, mid) % mod; if (queryR &gt; mid) res += query(rc(p), queryL, queryR, mid + 1, r) % mod; return res % mod; &#125; int main() &#123; int l, r; ll val; cin &gt;&gt; n &gt;&gt; m &gt;&gt; mod; for (int i = 1; i &lt;= n; ++i) &#123; scanf(&quot;%lld&quot;, &amp;arr[i]); &#125; build(1, 1, n); while (m--) &#123; int choice; cin &gt;&gt; choice; if (choice == 1) &#123; scanf(&quot;%d%d%lld&quot;, &amp;l, &amp;r, &amp;val); updateMul(1, val, l, r, 1, n); &#125; else if (choice == 2) &#123; scanf(&quot;%d%d%lld&quot;, &amp;l, &amp;r, &amp;val); updateAdd(1, val, l, r, 1, n); &#125; else if (choice == 3) &#123; scanf(&quot;%d%d&quot;, &amp;l, &amp;r); printf(&quot;%lld\\n&quot;,query(1, l, r, 1, n)); &#125; &#125; return 0; &#125; Binary Indexed Tree数状数组class BIT &#123; public: BIT(int n) &#123; tree.resize(n + 1, 0); &#125; static int lowBit(int x) &#123; return x &amp; (-x); &#125; void add(int x, int val) &#123; while (x &lt; tree.size()) &#123; tree[x] += val; x += lowBit(x); &#125; &#125; int query(int x) &#123; // sum from tree[1] to tree[x]. int res = 0; while (x &gt; 0) &#123; res += tree[x]; x -= lowBit(x); &#125; return res; &#125; int query(int l, int r) &#123; // [l, r]; return query(r) - query(l - 1); &#125; private: vector&lt;int&gt; tree; //tree index from 1 -&gt; n &#125;; Quick Power&#x2F;Multiply快速幂、快速乘Quick Power double binaryExponentiation(double x, long long n) &#123; if (n == 0) &#123; return 1.0; &#125; double half = binaryExponentiation(x, n &gt;&gt; 1); return n &amp; 1? half * half * x : half * half; &#125; double iteration(double x, long long n) &#123; double res = 1.0; double xContribution = x; while (n &gt; 0) &#123; if (n &amp; 1) &#123; res *= xContribution; &#125; xContribution *= xContribution; n &gt;&gt;= 1; &#125; return res; &#125; Quick Multiply long long quickMul(long long x, long long y) &#123; long long res = 0; while (y != 0) &#123; if (y &amp; 1) &#123; res += x; &#125; x += x; y &gt;&gt;= 1; &#125; return res; &#125; 数组排序 插入排序 选择排序 冒泡排序 快速排序 归并排序 void insertSort(vector&lt;int&gt;&amp; nums) &#123; for (int i = 0; i &lt; nums.size() - 1; ++i) &#123; int val = nums[i + 1]; int j = i + 1; while (j &gt; 0 &amp;&amp; nums[j - 1] &gt; val) &#123; nums[j] = nums[j - 1]; --j; &#125; nums[j] = val; &#125; &#125; void selectSort(vector&lt;int&gt;&amp; nums) &#123; for (int i = 0; i &lt; nums.size() - 1; ++i) &#123; int minIndex = i; for (int j = i + 1; j &lt; nums.size(); ++j) &#123; if (nums[j] &lt; nums[minIndex]) &#123; minIndex = j; &#125; &#125; swap(nums[minIndex], nums[i]); &#125; &#125; void bubbleSort(vector&lt;int&gt;&amp; nums) &#123; for (int i = nums.size() - 1; i &gt;= 0; --i) &#123; bool isSorted = true; for (int j = 0; j &lt; i; ++j) &#123; if (nums[j] &gt; nums[j + 1]) &#123; swap(nums[j], nums[j + 1]); isSorted = false; &#125; &#125; if (isSorted) &#123; break; &#125; &#125; &#125; // 快速排序 int partiion(vector&lt;int&gt;&amp; nums, int l, int r) &#123; int pivotValue = nums[r]; int p = l; //保证p左边的值都小于pivotValue for (int i = l; i &lt; r; ++i) &#123; if (nums[i] &lt; pivotValue) &#123; swap(nums[i], nums[p++]); &#125; &#125; //将pivotValue放到中间的位置，此时 左边都小于，右边都大于。 swap(nums[p], nums[r]); return p; &#125; // find pivot, divide and conqure recursively void quickSort(vector&lt;int&gt;&amp; nums, int l, int r) &#123; if (l &gt;= r) &#123; return ; &#125; int pivotIndex = rand() % (r - l + 1) + l; swap(nums[r], nums[pivotIndex]); int m = partiion(nums, l, r); quickSort(nums, l, m); quickSort(nums, m + 1, r); &#125; vector&lt;int&gt; quickSort(vector&lt;int&gt;&amp; nums) &#123; quickSort(nums, 0, nums.size() - 1); return nums; &#125; // 归并排序 // 递归向下，保证左右两部分l、r数组有序，再进行归并。 // 和quickSort不同的是，这个先递归。利用 // 归并，要用到一个临时数组temp void headSort(vector&lt;int&gt;&amp; nums, vector&lt;int&gt;&amp; temp, int l, int r) &#123; if (l &gt;= r) &#123; return; &#125; int m = (r - l) / 2 + l; headSort(nums, temp, l, m); headSort(nums, temp, m + 1, r); int ptr = l; int lPtr = l, rPtr = m + 1; while (lPtr &lt;= m &amp;&amp; rPtr &lt;= r) &#123; if (nums[lPtr] &lt; nums[rPtr]) &#123; temp[ptr++] = nums[lPtr++]; &#125; else &#123; temp[ptr++] = nums[rPtr++]; &#125; &#125; while (lPtr &lt;= m) &#123; temp[ptr++] = nums[lPtr++]; &#125; while (rPtr &lt;= r) &#123; temp[ptr++] = nums[rPtr++]; &#125; copy(temp.begin() + l, temp.begin() + r + 1, nums.begin() + l); &#125; vector&lt;int&gt; sortArray(vector&lt;int&gt;&amp; nums) &#123; vector&lt;int&gt; temp(nums.size()); headSort(nums, temp, 0, nums.size() - 1); return nums; &#125; 链表排序 归并排序 堆排序：但需要指定比较器，稍麻烦。 // mergeSort // 1. 找中点 // 2. 划分l、r两部分链表，设置middle的next为nullptr // 3. 递归分割l、r两部分，直到l、r两部分有序 // 4. 向上归并 ListNode* findMiddle(ListNode* head) &#123; if (head == nullptr || head-&gt;next == nullptr) &#123; return head; &#125; ListNode dummy(0, head); ListNode* fast = &amp;dummy; ListNode* slow = &amp;dummy; while (fast-&gt;next != nullptr &amp;&amp; fast-&gt;next-&gt;next != nullptr) &#123; fast = fast-&gt;next-&gt;next; slow = slow-&gt;next; &#125; return slow; &#125; ListNode* merge(ListNode* head1, ListNode* head2) &#123; ListNode dummy; ListNode* tail = &amp;dummy; while (head1 != nullptr &amp;&amp; head2 != nullptr) &#123; if (head1-&gt;val &lt; head2-&gt;val) &#123; tail-&gt;next = head1; head1 = head1-&gt;next; &#125; else &#123; tail-&gt;next = head2; head2 = head2-&gt;next; &#125; tail = tail-&gt;next; &#125; if (head1 != nullptr) &#123; tail-&gt;next = head1; &#125; else &#123; tail-&gt;next = head2; &#125; return dummy.next; &#125; ListNode* mergeSort(ListNode* head) &#123; if (head == nullptr || head-&gt;next == nullptr) &#123; return head; &#125; // 找中点，并划分l、r两部分 ListNode* middle = findMiddle(head); ListNode* left = head, *right = middle-&gt;next; middle-&gt;next = nullptr; // 让l、r两部分有序 left = mergeSort(left); right = mergeSort(right); // 有序后，进行归并 return merge(left, right); &#125; Heap、堆、堆排序核心操作是heapify，分为在数组最后的heapifyUp和在数组0下标进行的heapifyDown； Add时，插入到尾部，再heapifyUp delete时，将头部和尾部置换，为新的头部进行heapifyDown class MinHeap &#123; private: std::vector&lt;int&gt; heap; // 从指定位置开始向上递归调整堆，维护小顶堆性质 void heapifyUp(int index) &#123; if (index == 0) &#123; return; &#125; int parent = getParent(index); if (heap[index] &lt; heap[parent]) &#123; std::swap(heap[index], heap[parent]); heapifyUp(parent); // 递归调整 &#125; &#125; // 从指定位置开始向下递归调整堆，维护小顶堆性质 void heapifyDown(int index) &#123; int leftChild = getLeftChild(index); int rightChild = getRightChild(index); int smallest = index; if (leftChild &lt; heap.size() &amp;&amp; heap[leftChild] &lt; heap[smallest]) &#123; smallest = leftChild; &#125; if (rightChild &lt; heap.size() &amp;&amp; heap[rightChild] &lt; heap[smallest]) &#123; smallest = rightChild; &#125; if (smallest != index) &#123; std::swap(heap[index], heap[smallest]); heapifyDown(smallest); // 递归调整 &#125; &#125; inline int getParent(int index) &#123; return (index - 1) / 2; &#125; inline int getLeftChild(int index) &#123; return 2 * index + 1; &#125; inline int getRightChild(int index) &#123; return 2 * index + 2; &#125; public: // 构造函数，数组构造时，一个一个添加 MinHeap() &#123;&#125; MinHeap(const vector&lt;int&gt;&amp; nums) &#123; for (const auto&amp;num: nums) &#123; add(num); &#125; &#125; // 添加元素 void add(int value) &#123; heap.push_back(value); heapifyUp(heap.size() - 1); &#125; // 弹出堆顶元素 int pop() &#123; if (heap.empty()) &#123; throw std::out_of_range(&quot;Heap is empty&quot;); &#125; int top = heap[0]; heap[0] = heap.back(); heap.pop_back(); heapifyDown(0); return top; &#125; // 获取堆顶元素（不弹出） int top() const &#123; if (heap.empty()) &#123; throw std::out_of_range(&quot;Heap is empty&quot;); &#125; return heap[0]; &#125; // 获取堆的大小 size_t size() const &#123; return heap.size(); &#125; // 判断堆是否为空 bool empty() const &#123; return heap.empty(); &#125; &#125;; C++中的优先队列这块有点反直觉说实话 #include &lt;iostream&gt; #include &lt;queue&gt; // 包含 priority_queue 头文件 #include &lt;vector&gt; using namespace std; // 定义一个结构体 struct MyStruct &#123; int value; // 重载 operator&lt; // C++的priority_queue的默认是最大堆，最优先的在堆顶， // 意思是，堆顶元素的operator&lt;函数，对于其他非顶元素，都为false。 bool operator&lt;(const MyStruct&amp; other) const &#123; // 在这里实现自定义的比较逻辑 return value &lt; other.value; &#125; &#125;; int main() &#123; // 定义一个自定义比较器结构体，如果需要的话 struct MyComparator &#123; bool operator()(const MyStruct&amp; a, const MyStruct&amp; b) const &#123; return a.value &lt; b.value; // &gt;小顶堆；&lt;大顶堆 &#125; &#125;; // 使用自定义的结构体类型和比较器创建优先队列 std::priority_queue&lt;MyStruct, vector&lt;MyStruct&gt;, MyComparator&gt; pq; // std::priority_queue&lt;MyStruct&gt; pq; // 添加元素到优先队列 pq.push(&#123;5&#125;); pq.push(&#123;10&#125;); pq.push(&#123;3&#125;); // 弹出并输出队列中的元素 while (!pq.empty()) &#123; std::cout &lt;&lt; pq.top().value &lt;&lt; &quot; &quot;; pq.pop(); &#125; return 0; &#125; KMP找到所有匹配子串的位置 vector&lt;int&gt; findAllSubStrPosition(const string&amp; s, const string&amp; subStr) &#123; int n = subStr.size(); vector&lt;int&gt; next(n, 0); // next[j]代表[0,j]这个子串的前后相同部分的长度 // 也代表在j + 1匹配失败时，下一个尝试匹配的位置。 for (int i = 1, j = 0; i &lt; subStr.size(); ++i) &#123; while (j != 0 &amp;&amp; subStr[j] != subStr[i]) &#123; j = next[j - 1]; &#125; if (subStr[i] == subStr[j]) &#123; ++j; &#125; next[i] = j; &#125; vector&lt;int&gt; allPosition; for (int i = 0, j = 0; i &lt; s.size(); ++i) &#123; // j的位置是尝试匹配的位置，不匹配则需要返回到next[j - 1]（这个也就是下一个尝试的位置） // 举例 s=&quot;abab-ababe&quot; subStr=&quot;ababe&quot;, 其中next为[0, 0, 1, 2, 0] // 正常匹配，关键位置举例，此时i、j位置如下 // i // | // a b c d - a b a b e // a b a b e // | // j // 此时尝试匹配e和-，会匹配失败，子串的next为[0, 0, 1, 2, 0]， // 即在e尝试失败时，需要在已经匹配的部分（即以j - 1结尾的前后部分，这里为2）找共同部分, 如下 // i // | // a b c d - a b a b e // a b a b e // | // j // 此时还是匹配失败，就只能跳到0了（next[2 - 1] = 0） while (j != 0 &amp;&amp; subStr[j] != s[i]) &#123; j = next[j - 1]; &#125; if (s[i] == subStr[j]) &#123; ++j; if (j == subStr.size()) &#123; allPosition.emplace_back(i - j + 1); &#125; &#125; &#125; return allPosition; &#125; 前缀树class Trie &#123; public: Trie(): isEnd(false) &#123;&#125; void insert(const string&amp; word) &#123; Trie* curr = this; for (int i = 0; i &lt; word.size(); ++i) &#123; if (!curr-&gt;next.count(word[i])) &#123; curr-&gt;next[word[i]] = new Trie; &#125; curr = curr-&gt;next[word[i]]; &#125; curr-&gt;isEnd = true; &#125; bool search(const string&amp; word) &#123; Trie* p = searchPtr(word); return p != nullptr &amp;&amp; p-&gt;isEnd; &#125; bool startsWith(const string&amp; prefix) &#123; return searchPtr(prefix) != nullptr; &#125; private: Trie* searchPtr(const string&amp; prefix) &#123; Trie* curr = this; for (int i = 0; i &lt; prefix.size(); ++i) &#123; if (!curr-&gt;next.count(prefix[i])) return nullptr; curr = curr-&gt;next[prefix[i]]; &#125; return curr; &#125; unordered_map&lt;char, Trie*&gt; next; bool isEnd; &#125;; 缓存淘汰LRU// 要点： // 1. 哈希表加速node检索 // 2. 从头插，从尾删，保证顺序 class LRUCache &#123; public: LRUCache(int capacity): capacity(capacity) &#123;&#125; int get(int key) &#123; // 不存在直接返回 auto it = map.find(key); if (it == map.end()) &#123; return -1; &#125; // 存在则提出来放头部 int value = it-&gt;second-&gt;second; updatePosition(key, value); return value; &#125; void put(int key, int value) &#123; // 存在，提出来放头部并修改value auto it = map.find(key); if (it != map.end()) &#123; updatePosition(key, value); &#125; else &#123; // 不存在，放入；放入前检查容量，不足则弹出尾部。 insertNewNode(key, value); &#125; &#125; private: list&lt;pair&lt;int, int&gt;&gt; nodes; unordered_map&lt;int, list&lt;pair&lt;int, int&gt;&gt;::iterator&gt; map; int capacity; void insertNewNode(int key, int value) &#123; if (full()) &#123; pop(); &#125; putIn(key, value); &#125; void updatePosition(int key, int value) &#123; dropOut(key); putIn(key, value); &#125; // 尾部弹出 void pop() &#123; auto it = --nodes.end(); auto key = it-&gt;first; map.erase(key); nodes.erase(it); &#125; // 放入头部，操作map和list。 void putIn(int key, int value) &#123; auto it = nodes.emplace_front(key, value); map[key] = nodes.begin(); &#125; // 删除节点，操作map和list。 void dropOut(int key) &#123; auto it = map.find(key)-&gt;second; map.erase(key); nodes.erase(it); &#125; bool full() &#123; return map.size() == capacity; &#125; &#125;; LFUstruct Node&#123; int key; int value; int frequency; Node(int key, int value, int frequency): key(key), value(value), frequency(frequency) &#123;&#125; &#125;; // 要点： // 1. 通过minimumFrequency记录最小频率，避免pop时遍历frequencyMap。 // 2. 维护最小频率，只需考虑这两种情况。因为不主动删除，只在满时pop，所以满时要么插入新（为1），要么提高（n + 1）； // 1. 插入新节点，更新为1。 // 2. 提升频率，最小频率链表为空时提升为。 // 3. 每个链表，从头插，从尾删，保证频率相同时，删除最先插入的。 class LFUCache &#123; public: LFUCache(int capacity): capacity(capacity), minimumFrequency(0) &#123;&#125; int get(int key) &#123; // 不存在返回错误 auto it = map.find(key); if (it == map.end()) &#123; return -1; &#125; // 存在，提升频率 int value = it-&gt;second-&gt;value; incrementFrequency(key, value); return value; &#125; void put(int key, int value) &#123; // 不存在，插入频率为1的链表，注意满时pop auto it = map.find(key); if (it == map.end()) &#123; insertNewNode(key, value); &#125; else &#123; // 存在，提升频率 incrementFrequency(key, value); &#125; &#125; private: unordered_map&lt;int, std::list&lt;Node&gt;&gt; frequencyMap; unordered_map&lt;int, std::list&lt;Node&gt;::iterator&gt; map; int minimumFrequency; // 频率更新情况：1. 插入新节点，更新为1。 2. 提升频率，最小频率链表为空时提升。 int capacity; private: bool full() &#123; return this-&gt;map.size() == this-&gt;capacity; &#125; void insertNewNode(int key, int value) &#123; if (full()) &#123; if (this-&gt;capacity &lt; 0) &#123; return ; &#125; pop(); &#125; insertNode(key, value, 1); this-&gt;minimumFrequency = 1; // 1. 插入新节点，更新为1。 &#125; // 弹出频率最低的节点。 void pop() &#123; int key = frequencyMap[minimumFrequency].back().key; removeNode(key); &#125; // 删除节点：删除map和frequcnyMap信息，但未更新频率 void removeNode(int key) &#123; removeFromFrequencyMap(key); map.erase(key); &#125; // 更新频率：涉及value更新、map指向更新、frequency频率更新 void incrementFrequency(int key, int value) &#123; Node d = *(map.find(key)-&gt;second); removeNode(key); insertNode(d.key, value, d.frequency + 1); if (!frequencyMap.count(minimumFrequency)) &#123;// 2. 提升频率，原链表为空时提升。 ++minimumFrequency; &#125; &#125; // 只操作frequecnyMap删除key，并删除空链表 void removeFromFrequencyMap(int key) &#123; auto it = map.find(key)-&gt;second; int frequency = it-&gt;frequency; frequencyMap[frequency].erase(it); if (frequencyMap[frequency].empty()) &#123; frequencyMap.erase(frequency); &#125; &#125; // 将node插入到map和frequecnyMap void insertNode(int key, int value, int frequency) &#123; auto it = frequencyMap[frequency].emplace_front(key, value, frequency); map[key] = frequencyMap[frequency].begin(); &#125; &#125;;","categories":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://messenger1th.github.io/categories/LeetCode/"}],"tags":[]},{"title":"String","slug":"LeetCode/String","date":"2024-07-24T14:47:33.964Z","updated":"2024-07-24T14:47:33.964Z","comments":true,"path":"2024/07/24/LeetCode/String/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/LeetCode/String/","excerpt":"","text":"151. 翻转字符串里的单词trim，两次翻转。 647. 回文子串 1044. 最长重复子串 后缀数组|字符串哈希+二分","categories":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://messenger1th.github.io/categories/LeetCode/"}],"tags":[]},{"title":"Math","slug":"LeetCode/Math","date":"2024-07-24T14:47:33.961Z","updated":"2024-07-24T14:47:33.961Z","comments":true,"path":"2024/07/24/LeetCode/Math/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/LeetCode/Math/","excerpt":"","text":"Math 258. 各位相加(数字根%9同余) 12. 整数转罗马数字 13. 罗马数字转整数 9. 回文数 89. 格雷编码 172. Factorial Trailing Zeroes 166. Fraction to Recurring Decimal 441. Arranging Coins 进制相关 逆序求和, 按进制进位, 结果转置即可 67. 二进制求和 415. 字符串相加 43. 字符串相乘 约瑟夫环 数组模拟 环形链表模拟 数学方法 扩展：找最后k个剩余的人 1823. 找出游戏的获胜者 剑指 Offer 62. 圆圈中最后剩下的数字 最大公因数和最小公倍数 欧几里得算法（辗转相除法） //最大公因数 int GCD(int a, int b)&#123; if(b == 0) return a; else return GCD(b, a%b); &#125; //最小公倍数 int LCM(int a,int b)&#123; int gcd = GCD(a,b); int lcm = a/gcd*b; return lcm; &#125; 约数 试除法 vector&lt;int&gt; getFactors(int n) &#123; vector&lt;int&gt; res; for (int i = 1; i &lt;= n / i; ++i) &#123; if (n % i == 0) &#123; res.emplace_back(i); if (n / i != i) &#123; res.emplace_back(n / i); &#125; &#125; &#125; return res; &#125; 取模 168. Excel表列名称 357. 统计各位数字都不同的数字个数排列组合C&#x2F;A 2400. Number of Ways to Reach a Position After Exactly k Steps","categories":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://messenger1th.github.io/categories/LeetCode/"}],"tags":[]},{"title":"Milestone","slug":"LeetCode/Milestone","date":"2024-07-24T14:47:33.961Z","updated":"2024-07-24T14:47:33.961Z","comments":true,"path":"2024/07/24/LeetCode/Milestone/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/LeetCode/Milestone/","excerpt":"","text":"Leetcode300题 2022&#x2F;3&#x2F;20 10:04:00 400题 2022&#x2F;4&#x2F;20 21:39:09 剑指Offer (第2版) 2022&#x2F;04&#x2F;30 14:12:19 Hot 100 2022&#x2F;05&#x2F;01 10:14:22 500题 2022&#x2F;05&#x2F;08 09:34:24 600题 2022&#x2F;06&#x2F;08 21:59:55 700题 2022&#x2F;06&#x2F;28 20:40:28 800题 2022&#x2F;08&#x2F;29 13:00:32 900题 2022&#x2F;09&#x2F;26 15:59:39","categories":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://messenger1th.github.io/categories/LeetCode/"}],"tags":[]},{"title":"Greedy","slug":"LeetCode/Greedy","date":"2024-07-24T14:47:33.958Z","updated":"2024-07-24T14:47:33.958Z","comments":true,"path":"2024/07/24/LeetCode/Greedy/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/LeetCode/Greedy/","excerpt":"","text":"","categories":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://messenger1th.github.io/categories/LeetCode/"}],"tags":[]},{"title":"LinkedList","slug":"LeetCode/LinkedList","date":"2024-07-24T14:47:33.958Z","updated":"2024-07-24T14:47:33.958Z","comments":true,"path":"2024/07/24/LeetCode/LinkedList/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/LeetCode/LinkedList/","excerpt":"","text":"链表 链表操作基本都需要prev指针, 搭配dummy用于操作头节点. 删除 203. 移除链表元素 83. 删除排序链表中的重复元素 82. 删除排序链表中的重复元素 II 19. 删除链表的倒数第 N 个结点 交换 206. 反转链表 24. 两两交换链表中的节点 25. K 个一组翻转链表 插入、归并 21. 合并两个有序链表 23. 合并 K 个升序链表 86. 分隔链表 取中点 876. 链表的中间结点 综合 143. 重排链表 234. 回文链表 61. 旋转链表 92. 反转链表 II 109. 有序链表转换二叉搜索树 特殊位置 通常搭配多指针使用 19. 删除链表的倒数第 N 个结点 141. 环形链表 142. 环形链表 II f &#x3D; 2 * nb, s &#x3D; nb, 交点：a + nb 。 所以用个指针再走a即可。 160. 相交链表 排序 插入排序 归并排序：注意找中点时的起点和循环终止条件的组合。 148. 排序链表 静态链表 287. 寻找重复数 技巧 237. 删除链表中的节点 分析取中点 876. 链表的中间结点 区分起点，其实这两种只是置换了下节点数量的奇偶性。 从dummy开始 从第一个节点开始 区分循环终止条件，注意这两种，在偶数情况下都是找到中点左边节点。 fast-&gt;next != nullptr &amp;&amp; fast-&gt;next-&gt;next != nullptr 奇数找到中点前置节点 fast != nullptr &amp;&amp; fast-&gt;next != nullptr 奇树找到中点。 总结 从dummy开始：两种都不用特判空，根据要求使用即可。 从第一个节点开始：注意，从第一节点开始和 fast-&gt;next != nullptr &amp;&amp; fast-&gt;next-&gt;next != nullptr 一起时，fast可能初始化为nullptr，注意特判。所以不推荐这种组合。 从dummy开始这是逻辑最清晰的一种方式 如果循环终止条件为 终止条件： fast-&gt;next != nullptr &amp;&amp; fast-&gt;next-&gt;next != nullptr 奇数情况下，会到中点前置节点。 偶数情况下，会找到中点左边节点。 终止条件 fast != nullptr &amp;&amp; fast-&gt;next != nullptr 奇数情况下，会到中点。 偶数情况下，会到中点左边节点。 从第一个节点开始注意第一个节点判空，奇偶情况和从dummy开始的情况对调即是答案。","categories":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://messenger1th.github.io/categories/LeetCode/"}],"tags":[]},{"title":"Graph","slug":"LeetCode/Graph","date":"2024-07-24T14:47:33.957Z","updated":"2024-07-24T14:47:33.957Z","comments":true,"path":"2024/07/24/LeetCode/Graph/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/LeetCode/Graph/","excerpt":"","text":"大类 有向图 无向图 加权图 有向图 考虑入度和出度。 841. 钥匙和房间 997. 找到小镇的法官 1557. 可以到达所有点的最少点数目 拓扑排序 207. 课程表 210. 课程表 II 851. 喧闹和富有 802. 找到最终的安全状态 310. 最小高度树 444. 序列重建 1557. Minimum Number of Vertices to Reach All Nodes 最小生成树 Prim Kruskal 都是考虑权值最小的边，但角度有所不同 Prim Kruskal 从点出发，考虑当前最近的点 从边出发，考虑所有边中cost最小的边。 Prim 1135. 最低成本联通所有城市 Kruskal 1631. 最小体力消耗路径 778. 水位上升的泳池中游泳 最短路径问题模板题：743. 网络延迟时间 n 为顶点个数， E为边个数 图 单源\\多源 负权边 负权环 时间复杂度 空间 Dijkstra 单源 不适用 不适用 $O(n^2 + E)$ $O(n^2)$ Dijkstra（堆优化） 单源 不适用 不适用 $O(n + E\\log{E})$ $O(n + E)$ Bellman-Ford 单源 适用 适用 $O(nE)$ $O(E)$ SPFA（栈\\队列优化） 单源 适用 适用 $O(k*E)$ $O(E)$ Floyd 多源 适用 不适用 $O(n^3)$ $O(n^2)$ A star Dijkstra 每次选取距离起点最近的点，选取之后更新各点的最短距离。 Dijkstra不适用于负权边,因为不考虑已经走过的地方。 优化：最小堆 堆优化Dijkstra 用priority_queue&lt;&gt;存储边， $O(\\log(n)$时间内获取最小权边 2045. 到达目的地的第二短时间 1786. 从第一个节点出发到最后一个节点的受限路径数 相关参数 priority_queue&lt;&gt; minHeap 存边和点，每次取权值最小的边。 dist[n] 最短路径 起点start, 终点target 实现思路 dist[start] = 0,同时minHeap 入队起点，边权值设为0 易错点 注意设置每次更新dist[i]都要将dist[i]和i入队，因为可能比minHeap中该点（但该点未visited）的dist要更小。 题外话Dijkstra(堆优化)跟Prim算法很像，都是取dist最小的边。 区别在于， 前者的dist是最短距离，后者存的是一条边的权重。 因为Prim是把已经成树的点看作一个整体，只要看一条边的权重即可。 扩展 1162. 地图分析 多源最短路。二维表 Bellman-Ford遍历边来relax，对于不含负权环的图来说，遍历n-1次一定能设置好最短路径。 适用负权环 1334. 阈值距离内邻居最少的城市 787. K 站中转内最便宜的航班 1129. Shortest Path with Alternating Colors 检测负环 只需对第n次检查是否relax了dist数组就能判断是否含负权环。 Bellman-Ford优化：SPFADFS(Stack) &#x2F; BFS (Queue) 建议使用BFS(Queue)优化的SPFA, 无负环时不影响效率。 实现思路 bool inQueue[]表示点是否在Q里头 dist[]距离 将起点入队，同时inQueue[start] = true 取队首元素为cur，同时设置inQueue[cur] = false 更新与cur相邻的dist[]，如果邻点inQueue[] = false， 则将其入队，且设置inQueue[] = true， 一入队就更新inQueue防止重复入队。 重复上述步骤，直至Q.empty == true，至此dist数组更新完毕。 检测负环 用一个cnt[]来记录入队次数，如果入队次数大于n，就说明有负环。 用一个cnt[]来记录从起点到i的最短距离包含点的个数， 初始化cnt[] = 1, 用点u松弛v时更新cnt[v] = cnt[u] + 1 ， 若发现cnt[v] &gt; n则存在负环 Floyd 基于DP，因此K放外层循环。 对于i，j两点。用k点检查是否缩短该两点距离 Floyd适用负权边，因为三重循环，一直寻找最短。 Dijkstra、Bellman-Ford都不适用负权环。 总结 注意判断是否是有向图。 注意有限制的最短路，不同的方法，不同优化对应不同场景。 当权值为非负时，用Dijkstra。 可能有负权环，用BFS-Bellman-Ford，cnt[]检测入队次数。 Bellman_Ford 可解决有中转次数的最短路问题。 Floyd 适用于经过的所有点编号不会超过k的问题。最小环或者求“重心点”（即删除该点后，最短路值会变大）。 深度优先搜索 常辅以记忆化递归（memo） 对于图，一般需要一个visited数组来防止重复递归。如果图的元素限制了递归，就可能不需要。 对于需要返回值来提前结束递归或者积累子问题的结果，我们需要设置返回值，其他一般为void，获取全部可能。 回溯问题一般在函数前面部分处理递归出口，其他一般在循环中判断是否进入递归，这样更具有自由度：一个返回值所含信息有限，无法处理所有情况。实际上，返回值和递归入口出口的设置很灵活，难以总结。 树的DFS中，只能向下。但如果有parent数组记录，则可向上，但DFS时需要多一个from参数防止重复递归。 200. 岛屿数量 LCP 07. 传递信息 863. 二叉树中所有距离为 K 的结点 62. 不同路径 63. 不同路径 II 980. 不同路径 III 返回值做子问题的累计 329. 矩阵中的最长递增路径 2049. 统计最高分的节点数目 返回值做提前结束递归 403. 青蛙过河 785. 判断二分图 返回值告知整体情况 这种情况，在循环内限制递归入口不能实现理想效果或实现复杂。 1020. 飞地的数量 循环内限制递归入口 1034. 边界着色 广度优先搜索 注意最大、最小次数、最短距离等字眼，可以考虑BFS。 大致思路相关参数 visited防止重复搜索。如果是有向图，就可以不用。 queue 用于存储待搜索的节点 dirs搜索方向，level搜索深度,size每一层搜索的节点个数。 实现 将当前状态入队，根据搜索规则将下一轮的状态入队。queue 不一定是队列，只要是存现在的状态就行，如哈希表。 visited的具体实现可以是数组，也可以是哈希表。 队空搜索完成。 易错不同于Prim和priority_queue Dijkstra， BFS是加入queue时就设置visited，防止重复入queue。 130. 被围绕的区域 200. 岛屿数量 547. 省份数量 1091. 二进制矩阵中的最短路径 1020. 飞地的数量 1034. 边界着色 2039. 网络空闲的时刻 909. 蛇梯棋 433. 最小基因变化 994. 腐烂的橘子 多源BFS 417. Pacific Atlantic Water Flow 多次BFS 1765. 地图中的最高点 (多源BFS) DP 1162. 地图分析 （多源BFS） 752. 打开转盘锁 (哈希visited) 301. 删除无效的括号 773. 滑动谜题 01 BFS 2290. 到达角落需要移除障碍物的最小数目 扩展 双向BFS 有限次数BFS 2059. 转化数字的最小运算数 127. 单词接龙 1345. 跳跃游戏 IV 由于BFS搜索的状态增加是指数级别的，条件允许可以考虑双向BFS。 1036. 逃离大迷宫 数据量很大，考虑有限次数的BFS。 815. 公交路线 并查集 Disjoint-set structure 将二维下标转化为一维下的通常需要 index = i * col + j转化 547. 省份数量 200. 岛屿数量 130. 被围绕的区域 685. 冗余连接 II 778. 水位上升的泳池中游泳 399. 除法求值 785. Is Graph Bipartite? 886. Possible Bipartition 其他 不好分类 407. 接雨水 II 399. 除法求值","categories":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://messenger1th.github.io/categories/LeetCode/"}],"tags":[]},{"title":"状态机","slug":"LeetCode/Dynamic Programming/状态机","date":"2024-07-24T14:47:33.957Z","updated":"2024-07-24T14:47:33.957Z","comments":true,"path":"2024/07/24/LeetCode/Dynamic Programming/状态机/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/LeetCode/Dynamic%20Programming/%E7%8A%B6%E6%80%81%E6%9C%BA/","excerpt":"","text":"状态机DP 用DP数组的某一维【k】来表示k个状态 打家劫舍 198. 打家劫舍 213. 打家劫舍 II 337. 打家劫舍 III 740. 删除并获得点数 1388. 3n 块披萨 粉刷房子 256. 粉刷房子 265. 粉刷房子 II 1473. 粉刷房子 III 801. 使序列递增的最小交换次数1186. Maximum Subarray Sum with One Deletion买卖股票的最佳时机 状态的选择是关键在于用最少的空间覆盖所有状态。当题目有限制时，需要将部分状态展开。 121. 买卖股票的最佳时机 122. 买卖股票的最佳时机 II 123. 买卖股票的最佳时机 III 188. 买卖股票的最佳时机 IV 309. 最佳买卖股票时机含冷冻期 714. 买卖股票的最佳时机含手续费","categories":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://messenger1th.github.io/categories/LeetCode/"},{"name":"Dynamic Programming","slug":"LeetCode/Dynamic-Programming","permalink":"https://messenger1th.github.io/categories/LeetCode/Dynamic-Programming/"}],"tags":[]},{"title":"矩阵","slug":"LeetCode/Dynamic Programming/矩阵","date":"2024-07-24T14:47:33.957Z","updated":"2024-07-24T14:47:33.957Z","comments":true,"path":"2024/07/24/LeetCode/Dynamic Programming/矩阵/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/LeetCode/Dynamic%20Programming/%E7%9F%A9%E9%98%B5/","excerpt":"","text":"矩阵 120. 三角形最小路径和 931. 下降路径最小和 1289. 下降路径最小和 II 64. 最小路径和 221. 最大正方形 576. 出界的路径数 174. 地下城游戏 1301. 最大得分的路径数目 升维 85. 最大矩形 363. 矩形区域不超过 K 的最大数值和 面试题 17.24. 最大子矩阵 1444. 切披萨的方案数","categories":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://messenger1th.github.io/categories/LeetCode/"},{"name":"Dynamic Programming","slug":"LeetCode/Dynamic-Programming","permalink":"https://messenger1th.github.io/categories/LeetCode/Dynamic-Programming/"}],"tags":[]},{"title":"背包","slug":"LeetCode/Dynamic Programming/背包","date":"2024-07-24T14:47:33.957Z","updated":"2024-07-24T14:47:33.957Z","comments":true,"path":"2024/07/24/LeetCode/Dynamic Programming/背包/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/LeetCode/Dynamic%20Programming/%E8%83%8C%E5%8C%85/","excerpt":"","text":"背包问题01背包 一定容量的背包所能装下的最大物品价值。 对于每个物品，选与不选两个状态，取最大值。 先遍历物品，再遍历容量。如果是一维数组 注意01背包是从后遍历来防止重复选物品。 完全背包就从物品的容量开始，到最大容量，即可以重复选。 经典 416. 分割等和子集 1049. 最后一块石头的重量 II 变式 多维01背包 494. 目标和 元素正负两种状态，转化成加法的01背包，看是否能凑齐。 474. 一和零 进阶 879. 盈利计划 含限制的01多维背包 多重背包 相同物品有多件。是特殊01背包。加一个循环遍历相同物品个数。 完全背包 在元素可以重复添加的条件下，能装下的最大物品价值、硬币兑换最小次数、子串是否能组成字符串等。 例子求[1,2,3]组成4的种类 组合:[1,1,1,1],[1,1,2],[2,2],[1,3] 像是后面的物品把前面的物品包含了进去，一轮循环考虑一个物品。 排列: [1,1,1,1],[1,1,2],[1,2,1],[1,3],[2,1,1],[2,2],[3,1] _像是随机替换，一轮可以替换多个物品_。 组合 279. 完全平方数 322. 零钱兑换 518. 零钱兑换 II 排列 组合不考虑元素顺序，排列考虑。 139. 单词拆分 377. 组合总和 Ⅳ 进阶 记录路径：记录选择了哪些物品 01背包记录路径 01背包，物品有多种选择，不同选择花销不同，收获不同。 // n个题，限定t时间，在限定时间内拿到更高的分，返回每个题的做法。 // F代表不做，获得0分； // B代表暴力算法，花费force[i].first时间，获得force[i].second分； // C代表完美通过，花费perfect[i].first时间，获得perfect[i].second分； // 其实是01背包，每种物品有三种选择，path记录时，多判断一个状态即可。 // 通过逆序查找来查找路径。 string GetMaxScoreStrategy(int n, int t, vector&lt;pair&lt;int, int&gt;&gt;&amp; force, vector&lt;pair&lt;int, int&gt;&gt;&amp; perfect) &#123; vector&lt;vector&lt;char&gt;&gt; path(n + 1, vector&lt;char&gt; (t + 1, &#x27;F&#x27;)); vector&lt;vector&lt;int&gt;&gt; dp(n + 1, vector&lt;int&gt; (t + 1, 0)); for (int i = 1; i &lt;= n; ++i) &#123; for (int j = 0; j &lt;= t; ++j) &#123; // 不做 dp[i][j] = dp[i - 1][j]; // 判断暴力算法 int currTime = force[i - 1].first, currScore = force[i - 1].second; if (currTime &lt;= j &amp;&amp; dp[i][j] &lt; dp[i - 1][j - currTime] + currScore) &#123; dp[i][j] = dp[i - 1][j - currTime] + currScore; path[i][j] = &#x27;B&#x27;; &#125; // 判断完美算法 currTime = perfect[i - 1].first, currScore = perfect[i - 1].second; if (currTime &lt;= j &amp;&amp; dp[i][j] &lt; dp[i - 1][j - currTime] + currScore) &#123; dp[i][j] = dp[i - 1][j - currTime] + currScore; path[i][j] = &#x27;A&#x27;; &#125; &#125; &#125; int currTime = t, currIndex = n; string res(n, &#x27;F&#x27;); // 默认不做 while (currIndex &gt; 0 &amp;&amp; currTime &gt; 0) &#123; // 为0时，为初始状态，无背包或者时间，无需计算。 switch (path[currIndex][currTime]) &#123; case &#x27;F&#x27;: break; //noting. 默认就是不做。 case &#x27;A&#x27;: currTime -= perfect[currIndex - 1].first; res[currIndex - 1] = &#x27;A&#x27;; break; case &#x27;B&#x27;: currTime -= force[currIndex - 1].first; res[currIndex - 1] = &#x27;B&#x27;; break; &#125; --currIndex; &#125; return res; &#125; 完全背包记录记录 1449. 数位成本和为目标值的最大数字 其他背包进阶 背包9讲 【宫水三叶】分两步考虑问题，以及若干进阶思考（附背包问题攻略） - 数位成本和为目标值的最大数字 - 力扣（LeetCode）","categories":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://messenger1th.github.io/categories/LeetCode/"},{"name":"Dynamic Programming","slug":"LeetCode/Dynamic-Programming","permalink":"https://messenger1th.github.io/categories/LeetCode/Dynamic-Programming/"}],"tags":[]},{"title":"Advanced Data Structure&Algorithm","slug":"LeetCode/Advanced Data Structure&Algorithm","date":"2024-07-24T14:47:33.956Z","updated":"2024-07-24T14:47:33.956Z","comments":true,"path":"2024/07/24/LeetCode/Advanced Data Structure&Algorithm/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/LeetCode/Advanced%20Data%20Structure&Algorithm/","excerpt":"","text":"后缀数组 1044. 最长重复子串 树哈希 572. 另一棵树的子树//这里采用的哈希公式是：h(X) = Xv + mb + lb * h(Xl) + rb * h(Xr), 且h(nullptr) = 1 constexpr uint64_t lb = 2333, rb = 97755331, mb = 23333; class Solution &#123; public: int trans(TreeNode* root)&#123; return !root ? 1 : root-&gt;val = lb * trans(root-&gt;left) + rb * trans(root-&gt;right) + root-&gt;val + mb; &#125; bool dfs(TreeNode* root, int k)&#123; return root &amp;&amp; (root-&gt;val == k || dfs(root-&gt;left, k) || dfs(root-&gt;right, k)); &#125; bool isSubtree(TreeNode* root, TreeNode* subRoot) &#123; return dfs((trans(root), root), trans(subRoot)); &#125; &#125;; Rabin-Karp算法: 子字符串匹配、优化散列查找 28. 实现 strStr() 1044. Longest Duplicate Substring 快速幂和快速乘 50. Pow(x, n) double binaryExponentiation(double x, long long n) &#123; if (n == 0) &#123; return 1.0; &#125; double half = binaryExponentiation(x, n &gt;&gt; 1); return n &amp; 1? half * half * x : half * half; &#125; double iteration(double x, long long n) &#123; double res = 1.0; double xContribution = x; while (n &gt; 0) &#123; if (n &amp; 1) &#123; res *= xContribution; &#125; xContribution *= xContribution; n &gt;&gt;= 1; &#125; return res; &#125; 29. 两数相除 long mul(int x, long n) &#123; long res = 0; while (n &gt; 0) &#123; if (n &amp; 1) &#123; res += x; &#125; n &gt;&gt; 1; x += x; &#125; return res; &#125; 剑指 Offer 10- I. 斐波那契数列 Manacher 647. 回文子串 区间查询修改 数组不变，区间查询：__前缀和__、树状数组、线段树； 数组单点修改，区间查询：__树状数组__、线段树； 数组区间修改，单点查询：__差分__、线段树； 数组区间修改，区间查询：__线段树__。 前缀和 前缀和差分数组 应用场景：区间修改, 单点查询。 模板题 1893. 检查是否区域内所有整数都被覆盖 1109. 航班预订统计 370. 区间加法 变式 995. K 连续位的最小翻转次数 树状数组 单点修改, 区间查询 307. 区域和检索 - 数组可修改 待学习: 【宫水三叶の相信科学系列】二维最长上升子序列：朴素 DP &amp; 二分 DP（含证明）&amp; 树状数组 DP - 俄罗斯套娃信封问题 - 力扣（LeetCode） 分段树（线段树）segment tree 区间修改, 区间查询. 以上区间求和题目都能做, 但不是最优. 启发式搜索A Star 最好提前判断是否有解, 无解情况需要遍历所有可能. 设置f()作为启发式函数, 用于计算于终点的最短距离. 用优先队列存储过程, 优先取出与终点理论距离最短, 即f()算出来最短的那个中间值. 433. Minimum Genetic Mutation 待学习: 打开转盘锁 - 打开转盘锁 IDA Star 相对于 A*算法，它的优势如下： 不需要判重，不需要排序； 空间需求减少。 待学习: 【宫水三叶】一题三解：「双向 BFS」&amp; 「AStar 算法」&amp;「IDA* 算法」 - 打开转盘锁 字符串哈希 1044. 最长重复子串","categories":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://messenger1th.github.io/categories/LeetCode/"}],"tags":[]},{"title":"BackTracking","slug":"LeetCode/BackTracking","date":"2024-07-24T14:47:33.956Z","updated":"2024-07-24T14:47:33.956Z","comments":true,"path":"2024/07/24/LeetCode/BackTracking/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/LeetCode/BackTracking/","excerpt":"","text":"回溯 常常搭配剪枝来提速 回溯的时间复杂度通常是指数级别的 应用范围 组合和排列 切割 子集 棋盘 路线 组合、排列和集合 代码不同体现在startIndex、去重方式、获取结果等方面. 注意树层和树枝剪枝的区别 组合 77. 组合 最入门的 39. 组合总和可复用，注意去重 216. 组合总和 III 40. 组合总和 II 数组元素不唯一且不可复用，注意排序\\used数组剪枝。 17. 电话号码的字母组合 排列排列需要用到used数组，否则没法区分是否使用。 46. 全排列 47. 全排列 II 集合 78. 子集 90. 子集 II 含重复元素，注意用sort剪枝 序列 491. 递增子序列 因为保证序列的顺序，不能排序。通过set来记录每层用过的元素。 总结： 排列问题需要从0开始，组合从start开始。 组合问题, 如果含重复元素, 要先排序, 后去重, 方法如下. i &gt; 0 &amp;&amp; nums[i] == nums[i - 1] &amp;&amp; !used[i - 1] i &gt; startIndex &amp;&amp; nums[i] == nums[i - 1] (推荐, 无需used数组) 排列问题同理, 但是used数组必不可少，否则没法记录是否使用。 组合排列问题在叶子节点处收集结果, 子集收集所有路径. 分割 131. 分割回文串 93. 复原IP地址 其他（较难） 51. N 皇后 52. N皇后 II 37. 解数独 301. 删除无效的括号 212. 单词搜索 II 282. 给表达式添加运算符 332. 重新安排行程","categories":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://messenger1th.github.io/categories/LeetCode/"}],"tags":[]},{"title":"Binary Operation","slug":"LeetCode/Binary Operation","date":"2024-07-24T14:47:33.956Z","updated":"2024-07-24T14:47:33.956Z","comments":true,"path":"2024/07/24/LeetCode/Binary Operation/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/LeetCode/Binary%20Operation/","excerpt":"","text":"位运算异或 找出在数组中唯一出现奇数次的数 找出在数组中唯二出现奇数次的数, 需要用bit位将两组数分开取异或 知道数的所有取值, 可以每个数都再取异或, 改变出现次数的奇偶性, 匹配上面的方法. 136. 只出现一次的数字 645. 错误的集合 260. 只出现一次的数字 III 面试题 17.19. Missing Two LCCI 137. 只出现一次的数字 II 421. 数组中两个数的最大异或值 面试题 16.01. Swap Numbers LCCI 数位 面试题 05.01. Insert Into Bits LCCI 面试题 05.02. Binary Number to String LCCI 面试题 05.03. Reverse Bits LCCI 面试题 05.06. Convert Integer LCCI 面试题 05.07. Exchange LCCI 面试题 05.08. Draw Line LCCI 面试题 17.01. Add Without Plus LCCI 318. 最大单词长度乘积 338. 比特位计数 371. Sum of Two Integers","categories":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://messenger1th.github.io/categories/LeetCode/"}],"tags":[]},{"title":"Binary Tree","slug":"LeetCode/Binary Tree","date":"2024-07-24T14:47:33.956Z","updated":"2024-07-24T14:47:33.956Z","comments":true,"path":"2024/07/24/LeetCode/Binary Tree/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/LeetCode/Binary%20Tree/","excerpt":"","text":"树：Tree遍历 前序遍历 中序遍历 后序遍历 层序遍历 后序结果可由前序改变入栈顺序，翻转结果数组得来。**但这种方法不是真正意义上的后序遍历:左—&gt;右-&gt;中** 。但是其实遍历本来就要用root节点做媒介，也先访问了root节点。 遍历题目前中后序 递归和迭代的写法. 144. 二叉树的前序遍历 94. 二叉树的中序遍历 145. 二叉树的后序遍历 遍历应用 513. 找树左下角的值 129. 求根节点到叶节点数字之和 285. 二叉搜索树中的中序后继 426. 将二叉搜索树转化为排序的双向链表 113. 路径总和 II 437. 路径总和 III 层序遍历 116. 填充每个节点的下一个右侧节点指针 117. 填充每个节点的下一个右侧节点指针 II 103. 二叉树的锯齿形层序遍历 114. 二叉树展开为链表 特殊种类 满二叉树 完全二叉树 二叉搜索树 平衡二叉树 平衡二叉搜索树 善用特殊树各种性质解题 完全二叉树 222. 完全二叉树的节点个数 平衡二叉树 110.平衡二叉树 二叉搜索树 inOrder有序 700. 二叉搜索树中的搜索 98.验证二叉搜索树 530. 二叉搜索树的最小绝对差 501. 二叉搜索树中的众数 235. 二叉搜索树的最近公共祖先 701. 二叉搜索树中的插入操作 450. 删除二叉搜索树中的节点 669. 修剪二叉搜索树 108. 将有序数组转换为二叉搜索树 538. 把二叉搜索树转换为累加树 1382. 将二叉搜索树变平衡 : 旋转？？ 96. 不同的二叉搜索树(dp) 653. 两数之和 IV - 输入 BST(考虑树双指针双栈实现)Morris+双指针 ： defer 783. 二叉搜索树节点最小距离 构造遍历构造 迭代法值得考究 105. 从前序与中序遍历序列构造二叉树 106. 从中序与后序遍历序列构造二叉树 数组构造 654. 最大二叉树 单调栈 tricky 108. 将有序数组转换为二叉搜索树 链表构造 109. 有序链表转换二叉搜索树 深度 104. 二叉树的最大深度 111. 二叉树的最小深度 递归妙解 814. 二叉树剪枝 236. 二叉树的最近公共祖先 其他操作 226. 翻转二叉树 156. 上下翻转二叉树 101. 对称二叉树 做一下迭代 257. 二叉树的所有路径 404. 左叶子之和 617. 合并二叉树 543. 二叉树的直径 863. All Nodes Distance K in Binary Tree 插入、删除通常需要用到返回值!!! hard 968. 监控二叉树 297. 二叉树的序列化与反序列化 572. 另一棵树的子树 ：树哈希和树上字符串匹配 树形DP题型 124. 二叉树中的最大路径和 二叉树中找连通块的最大值（Acwing题目） 687. 最长同值路径 968. 监控二叉树 类似这题，用返回值告诉子节点状态。 未归档1382. 将二叉搜索树变平衡 ：遍历 + 构造，没看到高阶解法。","categories":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://messenger1th.github.io/categories/LeetCode/"}],"tags":[]},{"title":"Design&Implement","slug":"LeetCode/Design&Implement","date":"2024-07-24T14:47:33.956Z","updated":"2024-07-24T14:47:33.956Z","comments":true,"path":"2024/07/24/LeetCode/Design&Implement/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/LeetCode/Design&Implement/","excerpt":"","text":"Design &amp; ImplementImplement 232. 用栈实现队列 225. 用队列实现栈 707. Design Linked List 622. Design Circular Queue 641. Design Circular Deque 705. 设计哈希集合 706. 设计哈希映射 535. Encode and Decode TinyURL 146. LRU 缓存 460. LFU Cache [432. All O&#96;one Data Structure](https://leetcode.cn/problems/all-oone-data-structure/) 面试题 03.05. Sort of Stacks LCCI Design 933. 最近的请求次数 346. 数据流中的移动平均值 295. 数据流的中位数 173. 二叉搜索树迭代器 303. 区域和检索 - 数组不可变 307. 区域和检索 - 数组可修改 155. 最小栈 716. Max Stack 297. 二叉树的序列化与反序列化 380. O(1) 时间插入、删除和获取随机元素 381. Insert Delete GetRandom O(1) - Duplicates allowed 676. 实现一个魔法字典 1756. Design Most Recently Used Queue 1429. First Unique Number 1500. Design a File Sharing System 341. Flatten Nested List Iterator 1206. Design Skiplist 355. Design Twitter 981. Time Based Key-Value Store 面试题 10.10. Rank from Stream LCCI 2080. Range Frequency Queries 1381. Design a Stack With Increment Operation Trie Tree 208. 实现 Trie (前缀树) 820. 单词的压缩编码 677. 键值映射 648. 单词替换 211. Design Add and Search Words Data Structure 1858. 包含所有前缀的最长单词 212. 单词搜索 II 642. Design Search Autocomplete System 1032. Stream of Characters 745. Prefix and Suffix Search 472. Concatenated Words 面试题 17.15. Longest Word LCCI 面试题 16.20. T9 LCCI Calender 729. My Calendar I 731. My Calendar II 732. My Calendar III Serialization 297. Serialize and Deserialize Binary Tree 449. Serialize and Deserialize BST","categories":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://messenger1th.github.io/categories/LeetCode/"}],"tags":[]},{"title":"Divide&Conquer","slug":"LeetCode/Divide&Conquer","date":"2024-07-24T14:47:33.956Z","updated":"2024-07-24T14:47:33.956Z","comments":true,"path":"2024/07/24/LeetCode/Divide&Conquer/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/LeetCode/Divide&Conquer/","excerpt":"","text":"分治 将大问题分治为小问题再依次解决 跟动态规划很类似 分治通常用借以栈的特性，小问题入栈先解决。递归实现。 不同于动态规划， 动态规划通常用于计算结果数量，分治可以得到完整信息。同时，因为数据量很大，因此$n$的大小通常不大。 面试题 08.06. Hanota LCCI 面试题 08.14. Boolean Evaluation LCCI 241. 为运算表达式设计优先级 96. 不同的二叉搜索树 95. 不同的二叉搜索树 II 23. 合并K个升序链表 254. Factor Combinations 394. Decode String","categories":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://messenger1th.github.io/categories/LeetCode/"}],"tags":[]},{"title":"Double Pointer","slug":"LeetCode/Double Pointer","date":"2024-07-24T14:47:33.956Z","updated":"2024-07-24T14:47:33.956Z","comments":true,"path":"2024/07/24/LeetCode/Double Pointer/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/LeetCode/Double%20Pointer/","excerpt":"","text":"删除 || 替换 减少从左边，增加从右边。 剑指 Offer 05. 替换空格 27. 移除元素 经典 15. 三数之和 (注意去重操作、移动到左右边界或者直接移出边界) 16. 最接近的三数之和 18. 四数之和 151. 翻转字符串里的单词 (一次整体、一次局部) 977. 有序数组的平方 88. 合并两个有序数组 LinkedList 利用长度关系, 维护两个指针的距离来找某个节点, 160. 相交链表 142. 环形链表 II 19. 删除链表的倒数第 N 个结点","categories":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://messenger1th.github.io/categories/LeetCode/"}],"tags":[]},{"title":"单串","slug":"LeetCode/Dynamic Programming/单串","date":"2024-07-24T14:47:33.956Z","updated":"2024-07-24T14:47:33.956Z","comments":true,"path":"2024/07/24/LeetCode/Dynamic Programming/单串/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/LeetCode/Dynamic%20Programming/%E5%8D%95%E4%B8%B2/","excerpt":"","text":"单串问题确定的依赖位置仅仅依赖之前的一个确定位置, 如i - 1,i &lt;&lt; 1等. 因此, 在理解题意后, 可以很平滑地理清楚状态地转移. 338. 比特位计数 91. 解码方法 801. 使序列递增的最小交换次数 不确定的依赖位置依赖位置有所不同. 不能直接明确地找到, 需要遍历, 或者通过之前元素的性质使用二分, 前缀和等算法优化. 32. 最长有效括号 132. 分割回文串 II 871. 最低加油次数 取决于两个位置 873. 最长的斐波那契子序列的长度 1027. 最长等差数列 LIS: Longest Increasing Sequence记录最大长度 300. 最长递增子序列 354. 俄罗斯套娃信封问题($O(n^2)$可能会超时, 需要优化) 334. 递增的三元子序列 (特例, 可以用三指针优化时空) 记录最大长度时记录个数 673. 最长递增子序列的个数 记录路径 368. 最大整除子集 进阶: 记录所有可能路径?多一个限制维度单串状态机DP 打家劫舍 粉刷房子 买卖股票 限制子数组个数 813. 最大平均值和的分组 410. 分割数组的最大值","categories":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://messenger1th.github.io/categories/LeetCode/"},{"name":"Dynamic Programming","slug":"LeetCode/Dynamic-Programming","permalink":"https://messenger1th.github.io/categories/LeetCode/Dynamic-Programming/"}],"tags":[]},{"title":"Dynamic Programming","slug":"LeetCode/Dynamic Programming/Dynamic Programming","date":"2024-07-24T14:47:33.956Z","updated":"2024-07-24T14:47:33.956Z","comments":true,"path":"2024/07/24/LeetCode/Dynamic Programming/Dynamic Programming/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/LeetCode/Dynamic%20Programming/Dynamic%20Programming/","excerpt":"","text":"动态规划 与暴力回溯相比，对于计算个数的题目更快。 也可记忆化搜索 120. 三角形最小路径和 序列和数组 序列不要求连续, 子数组要求连续; 子数组通常可以优化成常量，而子序列不行，无法保存这么多信息，需要两层循环。 LCS: Longest Common Sequence 1143. 最长公共子序列 1035. 不相交的线 Others 91. 解码方法 583. 两个字符串的删除操作 115. 不同的子序列 进阶 97. 交错字符串 72. 编辑距离 44. 通配符匹配 10. 正则表达式匹配 132. 分割回文串 II 最大子数组系列 通常要求子数组, 需要一些trick来模拟抛弃数组的操作. 53. 最大子数组和 1186. 删除一次得到子数组最大和 152. 乘积最大子数组 918. 环形子数组的最大和 类似\\变式 718. 最长重复子数组 413. 等差数列划分 446. 等差数列划分 II - 子序列 进阶: 矩阵上的数组 面试题 17.24. 最大子矩阵 363. 矩形区域不超过 K 的最大数值和 区间dp 通常来说，解决区间dp的步骤是 找到依赖关系， 这一步决定了dp的维度和循环数 初始化 枚举长度length $\\to$ n，从小区间j转移到大区间 区间dp是自底向上的，有些题目是可以从自顶向下转换成区间dp的。 记忆化递归是自顶向下的。 516. 最长回文子序列 375. 猜数字大小 II 486. 预测赢家 312. 戳气球 2104. 子数组范围和 进阶 664. 奇怪的打印机 87. 扰乱字符串 546. 移除盒子 3维 状态压缩DP 由于状态压缩是用一个state来表示状态，因此对n有限制。 通常可以用暴力回溯解决，但回溯时间复杂度为：$O(n!)$。 526. 优美的排列 1723. 完成所有工作的最短时间 数位dp难，不建议做。 357. 统计各位数字都不同的数字个数 233. 数字 1 的个数 600. 不含连续1的非负整数 902. 最大为 N 的数字组合 路径问题 931. 下降路径最小和 1289. 下降路径最小和 II 576. 出界的路径数 1575. 统计所有可行路径 1301. 最大得分的路径数目 (这个题目中前向和返回两种方式的区别?)","categories":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://messenger1th.github.io/categories/LeetCode/"},{"name":"Dynamic Programming","slug":"LeetCode/Dynamic-Programming","permalink":"https://messenger1th.github.io/categories/LeetCode/Dynamic-Programming/"}],"tags":[]},{"title":"双串","slug":"LeetCode/Dynamic Programming/双串","date":"2024-07-24T14:47:33.956Z","updated":"2024-07-24T14:47:33.957Z","comments":true,"path":"2024/07/24/LeetCode/Dynamic Programming/双串/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/LeetCode/Dynamic%20Programming/%E5%8F%8C%E4%B8%B2/","excerpt":"","text":"双串子数组 718. 最长重复子数组 子序列 583. 两个字符串的删除操作 97. 交错字符串 1143. 最长公共子序列 1035. 不相交的线 44. 通配符匹配 10. 正则表达式匹配 72. 编辑距离 115. 不同的子序列 多一个维度 87. 扰乱字符串","categories":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://messenger1th.github.io/categories/LeetCode/"},{"name":"Dynamic Programming","slug":"LeetCode/Dynamic-Programming","permalink":"https://messenger1th.github.io/categories/LeetCode/Dynamic-Programming/"}],"tags":[]},{"title":"图解TCP&IP","slug":"Internet/TCP&IP/图解TCP&IP","date":"2024-07-24T14:47:33.955Z","updated":"2024-07-24T14:47:33.955Z","comments":true,"path":"2024/07/24/Internet/TCP&IP/图解TCP&IP/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Internet/TCP&IP/%E5%9B%BE%E8%A7%A3TCP&IP/","excerpt":"","text":"图解TCP&#x2F;IPNAT&#x2F; NAPT技术: 本地通信时采用私有IP, 与互联网通信时使用该技术转成公有IP 起因: 解决IPv4 IP地址不够用 IP隧道技术: 这种在网络层的首部后面继续追加网络层首部的通信方法 起因: IPv4和IPv6不兼容 扩展应用: IP隧道转发多播消息 Mobile IP: 在主机所连接的子网IP发 生变化时，主机IP地址仍保持不变。 起因: 与移动设备进行通信时，所连接的子网一旦发生变化，则无法通过 TCP继续通信。 第3章 数据链路 MAC地址: Media access control 第6章 TCP与UDPTCP: 面向有连接, 是一对一可靠性传输 校验和 序列号 确认应答 重发控制 连接管理 窗口控制 以上, 实现了可靠性传输. 三次握手, 四次挥手三次握手: 验证各自的接收能力和发送能力 第一次握手：客户端给服务端发一个 SYN 报文，并指明客户端的初始化序列号 ISN。此时客户端处于 SYN_SENT 状态。 首部的同步位SYN&#x3D;1，初始序号seq&#x3D;x，SYN&#x3D;1的报文段不能携带数据，但要消耗掉一个序号。 第二次握手：服务器收到客户端的 SYN 报文之后，会以自己的 SYN 报文作为应答，并且也是指定了自己的初始化序列号 ISN(s)。同时会把客户端的 ISN + 1 作为ACK 的值，表示自己已经收到了客户端的 SYN，此时服务器处于 SYN_RCVD 的状态。 在确认报文段中SYN&#x3D;1，ACK&#x3D;1，确认号ack&#x3D;x+1，初始序号seq&#x3D;y。 第三次握手：客户端收到 SYN 报文之后，会发送一个 ACK 报文，当然，也是一样把服务器的 ISN + 1 作为 ACK 的值，表示已经收到了服务端的 SYN 报文，此时客户端处于 ESTABLISHED 状态。服务器收到 ACK 报文之后，也处于 ESTABLISHED 状态，此时，双方已建立起了连接。 确认报文段ACK&#x3D;1，确认号ack&#x3D;y+1，序号seq&#x3D;x+1（初始为seq&#x3D;x，第二个报文段所以要+1），ACK报文段可以携带数据，不携带数据则不消耗序号。 四次挥手:当连接处于半关闭状态时，TCP 是允许单向传输数据的. 第一次挥手：客户端发送一个 FIN 报文，报文中会指定一个序列号。此时客户端处于 FIN_WAIT1 状态。即发出连接释放报文段（FIN&#x3D;1，序号seq&#x3D;u），并停止再发送数据，主动关闭TCP连接，进入FIN_WAIT1（终止等待1）状态，等待服务端的确认。 第二次挥手：服务端收到 FIN 之后，会发送 ACK 报文，且把客户端的序列号值 +1 作为 ACK 报文的序列号值，表明已经收到客户端的报文了，此时服务端处于 CLOSE_WAIT 状态。即服务端收到连接释放报文段后即发出确认报文段（ACK&#x3D;1，确认号ack&#x3D;u+1，序号seq&#x3D;v），服务端进入CLOSE_WAIT（关闭等待）状态，此时的TCP处于半关闭状态，客户端到服务端的连接释放。客户端收到服务端的确认后，进入FIN_WAIT2（终止等待2）状态，等待服务端发出的连接释放报文段。 第三次挥手：如果服务端也想断开连接了，和客户端的第一次挥手一样，发给 FIN 报文，且指定一个序列号。此时服务端处于 LAST_ACK 的状态。即服务端没有要向客户端发出的数据，服务端发出连接释放报文段（FIN&#x3D;1，ACK&#x3D;1，序号seq&#x3D;w，确认号ack&#x3D;u+1），服务端进入LAST_ACK（最后确认）状态，等待客户端的确认。 第四次挥手：客户端收到 FIN 之后，一样发送一个 ACK 报文作为应答，且把服务端的序列号值 +1 作为自己 ACK 报文的序列号值，此时客户端处于 TIME_WAIT 状态。需要过一阵子以确保服务端收到自己的 ACK 报文之后才会进入 CLOSED 状态，服务端收到 ACK 报文之后，就处于关闭连接了，处于 CLOSED 状态。即客户端收到服务端的连接释放报文段后，对此发出确认报文段（ACK&#x3D;1，seq&#x3D;u+1，ack&#x3D;w+1），客户端进入TIME_WAIT（时间等待）状态。此时TCP未释放掉，需要经过时间等待计时器设置的时间2MSL后，客户端才进入CLOSED状态。 第七章: 路由控制 动态路由和静态路由 路由协议IGP 和 EGP(Internal Gateway Protocol, External Gateway Protocol) 路由算法: 距离向量算法, 链路状态算法 RIP, RIP2, OSPF BGP RIP(Routine Information Protocol) 是距离向量型的一种路由协议, 广泛应用于LAN口. 采用RIP进行路由控制的范围内必须注意两点 因IP 地址的分类而产生不同的网络地址 构造网络地址长度不同的 网络环境时 RIP中路由变更时的处理: 将自己所知道的路由信息定期进行广播。 一旦认为网络被断开，数据将无法流过此路由器，其他路由器也就 可以得知网络已经断开。 以上两点存在一些问题, 解决办法 最长距离不超过16 规定路由器不再把所收到的路由消息原路返还给发送端。这也 被称作水平分割（Split Horizon） “毒性逆转”（Poisoned Reverse） “触发更新”（Triggered Update） OSPF:(Open Shortest Path First) 是链路状态型路由协议, 生成网络拓扑信息再生成控制表. BGP: (Border Gateway Protocol) 属于EGP MPLS: (Multi Protocol Label Switching) 标记交换技术 第八章: 应用协议 登录协议: TELNET SSH 文件传输: FTP协议 电子邮件: SMTP(Simple Mail Transfer Protocol) 和POP&#x2F;IMAP协议 Web HTTP协议 JavaScript Cookie CGI规范 RSS数据格式 网络管理 SNMP (Simple Network Management Protocol)","categories":[{"name":"Internet","slug":"Internet","permalink":"https://messenger1th.github.io/categories/Internet/"},{"name":"TCP&IP","slug":"Internet/TCP-IP","permalink":"https://messenger1th.github.io/categories/Internet/TCP-IP/"}],"tags":[]},{"title":"Question","slug":"Internet/TCP&IP/Question","date":"2024-07-24T14:47:33.950Z","updated":"2024-07-24T14:47:33.950Z","comments":true,"path":"2024/07/24/Internet/TCP&IP/Question/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Internet/TCP&IP/Question/","excerpt":"","text":"为什么需要三次握手? 阻⽌重复历史连接的初始化（主因) 当旧的SYN报⽂先到达服务端，服务端回⼀个ACK+SYN报⽂ 客户端收到后可以根据⾃身的上下⽂，判断这是⼀个历史连接（序列号过期或超时），那么客户端就会发送 RST 报⽂给服务端，表示中⽌这⼀次连接。 两次握⼿在收到服务端的响应后开始发⽣数据，不能判断当前连接是否是历史连接。 三次握⼿可以在客户端准备发送第三次报⽂时，客户端因有⾜够的上下⽂来判断当前连接是否是历史连接 同步双⽅的初始序列号 ⼀来⼀回，才能确保双⽅的初始序列号能被可靠的同步 两次握⼿只保证了⼀⽅的初始序列号能被对⽅成功接收，没办法保证双⽅的初始序列号都能被确认接收。 避免资源浪费 两次握⼿会造成消息滞留情况下，服务器重复接受⽆⽤SYN 报⽂，⽽造成重复分配资源. 只有两次握⼿时，如果客户端的SYN请求连接在⽹络中阻塞，客户端没有收到服务端的ACK报⽂，会重新发送 SYN。 由于没有第三次握⼿，服务器不清楚客户端是否收到了⾃⼰发送的建⽴连接的 ACK 确认信号，所以每收到⼀ 个 SYN 就只能先主动建⽴⼀个连接。 第三次握手Client发送ACK后, 若丢包, Server没进入ESTABLISHED状态, 而Client发送数据, 会发生什么? Server发送SYN-ACK报文后会进入TCP重传计时, 超时则重发SYN-ACK 若此时Client直接发送数据, Server会发送RST报文关闭TCP连接. 三次握手过程中可以携带数据吗? 其实第三次握手的时候，是可以携带数据的。但是，第一次、第二次握手不可以携带数据。 为什么这样呢?大家可以想一个问题，假如第一次握手可以携带数据的话，如果有人要恶意攻击服务器，那他每次都在第一次握手中的 SYN 报文中放入大量的数据。因为攻击者根本就不理服务器的接收、发送能力是否正常，然后疯狂着重复发 SYN 报文的话，这会让服务器花费很多时间、内存空间来接收这些报文。 如果仅采用用两次握手, 只要Server发出ACK到Client接收, 就建立连接? 如果网络拥堵, Client之前发送的失效ACK在网络滞留,后再发送给Server, Server接收到直接进入ESTABLISHED, 而此时Client已经CLOSED, 白白等待时间, 浪费资源. SYN攻击: 伪造不同IP发送SYN报文, 使得Server的半连接队列占满, 避免方式? 扩大半连接队列 缩短服务端超时重传时间, 使Server尽早丢弃⽆⽤连接. 当半连接队列满时，启动syn cookie,后续连接不进⼊半连接队列，⽽是计算⼀个cookie值，作为请求报⽂序列号发 送给客户端，如果服务端收到客户端确认报⽂，会检查ack包合法性，如果合法直接加⼊到accept队列. 为什么SYN需要消耗一个序号? networking - Why does a SYN or FIN bit in a TCP segment consume a byte in the sequence number space? - Stack Overflow 原因是 SYN 和 FIN 信号都是需要 acknowledgement 的，也就是你必须回复这个信号，如果它不占有一个字节的话，要如何判断你是回复这个信号还是回复这个信号之前的包呢？ 例如：如果 FIN 信号不占用一个字节，回复 FIN 的 ack 包就可能被误认为是回复之前的数据包被重新发送了一次，第二次挥手无法完成，连接也就无法正常关闭了。 为什么需要四次挥手？ 这是因为 TCP 不允许连接处于半打开状态时就单向传输数据，所以在三次握手建立连接时，服务器会把 ACK 和 SYN 放在一起发给客户端，其中，ACK 用来打开客户端的发送通道，SYN 用来打开服务器的发送通道。这样，原本的四次握手就降为三次握手了。 但是当连接处于半关闭状态时，TCP 是允许单向传输数据的。为便于理解，我们把先关闭连接的一方叫做主动方，后关闭连接的一方叫做被动方。当主动方关闭连接时，被动方仍然可以在不调用 close 函数的状态下，长时间发送数据，此时连接处于半关闭状态。这一特性是 TCP 的双向通道互相独立所致，却也使得关闭连接必须通过四次挥手才能做到。 第⼀次ACK应答报⽂可以省略，因为下⼀个报⽂段携带了ACK信息，ACK是否出现取决于延迟确认特性。 延迟确认：即接收⽅收到包后，如果暂时没有内容回复给发送⽅，则延迟⼀段时间再确认，假如在这个时间范 围内刚好有数据需要传输，则和确认包⼀起回复。这种也被称为数据捎带。延迟确认只是减轻⽹络负担，未必 可以提升⽹络性能，有些情况下反⽽会影响性能. 为什么 TIME_WAIT 等待的时间是 2MSL？ MSL是 Maximum Segment Lifetime，报⽂最⼤⽣存时间，它是任何报⽂在⽹络上存在的最⻓时间，超过这 个时间报⽂将被丢弃。 等待MSL两倍：⽹络中可能存在发送⽅的数据包，当这些发送⽅的数据包被接收⽅处理后⼜会向对⽅发送响 应，所以⼀来⼀回需要等待 2 倍的时间。 2MSL 的时间是从客户端接收到 FIN 后发送 ACK 开始计时的。如果在 TIME-WAIT 时间内，因为客户端的 ACK 没有传输到服务端，客户端⼜接收到了服务端᯿发的 FIN 报⽂，那么 2MSL 时间将重新计时. 为什么需要 TIME_WAIT 状态？ 防止已失效的连接请求报文段出现在新的连接中.客户端在发送完最后一个ACK 报文后，再经过时间2MSL，就可以使由于网络不通畅产生的滞留报文段失效. 最后一次的ACK丢包, Server未能关闭连接, 继而重发FIN, 正常的新连接可能因此关闭. 所以TIME_WAIT状态就是用来重发可能丢失的ACK报文. TIME_WAIT 过多有什么危害？ 内存资源占⽤； 对端⼝资源的占⽤，⼀个 TCP 连接⾄少消耗⼀个本地端⼝；可能无端口剩余, 无法创建新连接. 解决办法: 打开系统的TIMEWAIT重用和快速回收 修改TIME_WAIT连接状态的上限值 启动快速回收机制 开启复用机制 修改短连接为长连接方式 由客户端来主动断开连接","categories":[{"name":"Internet","slug":"Internet","permalink":"https://messenger1th.github.io/categories/Internet/"},{"name":"TCP&IP","slug":"Internet/TCP-IP","permalink":"https://messenger1th.github.io/categories/Internet/TCP-IP/"}],"tags":[]},{"title":"TCP","slug":"Internet/TCP&IP/TCP","date":"2024-07-24T14:47:33.950Z","updated":"2024-07-24T14:47:33.950Z","comments":true,"path":"2024/07/24/Internet/TCP&IP/TCP/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Internet/TCP&IP/TCP/","excerpt":"","text":"TCPTCP 是面向连接的、可靠的、基于字节流的传输层通信协议。 面向连接：一定是「一对一」才能连接，不能像 UDP 协议可以一个主机同时向多个主机发送消息，也就是一对多是无法做到的； 可靠的：无论的网络链路中出现了怎样的链路变化，TCP 都可以保证一个报文一定能够到达接收端； 字节流：用户消息通过 TCP 协议传输时，消息可能会被操作系统「分组」成多个的 TCP 报文，如果接收方的程序如果不知道「消息的边界」，是无法读出一个有效的用户消息的。并且 TCP 报文是「有序的」，当「前一个」TCP 报文没有收到的时候，即使它先收到了后面的 TCP 报文，那么也不能扔给应用层去处理，同时对「重复」的 TCP 报文会自动丢弃。 什么是 TCP 连接？ 我们来看看 RFC 793 是如何定义「连接」的： Connections: The reliability and flow control mechanisms described above require that TCPs initialize and maintain certain status information for each data stream. The combination of this information, including sockets, sequence numbers, and window sizes, is called a connection. 简单来说就是，用于保证可靠性和流量控制维护的某些状态信息，这些信息的组合，包括Socket、序列号和窗口大小称为连接。 Socket：由 IP 地址和端口号组成 序列号：用来解决乱序问题等 窗口大小：用来做流量控制 有了IP, 为什么还需要TCP? IP 层是「不可靠」的，因为: 网络包是否交付 不保证网络包的按序交付 也不保证网络包中的数据的完整性 因此, 就需要更高一层的TCP来保证. TCP 和 UDP 区别：1. 连接 TCP 是面向连接的传输层协议，传输数据前先要建立连接。 UDP 是不需要连接，即刻传输数据。 2. 服务对象 TCP 是一对一的两点服务，即一条连接只有两个端点。 UDP 支持一对一、一对多、多对多的交互通信 3. 可靠性 TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按需到达。 UDP 是尽最大努力交付，不保证可靠交付数据。 4. 拥塞控制、流量控制 TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。 UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。 5. 首部开销 TCP 首部长度较长，会有一定的开销，首部在没有使用「选项」字段时是 20 个字节，如果使用了「选项」字段则会变长的。 UDP 首部只有 8 个字节，并且是固定不变的，开销较小。 6. 传输方式 TCP 是流式传输，没有边界，但保证顺序和可靠。 UDP 是一个包一个包的发送，是有边界的，但可能会丢包和乱序。 7. 分片不同 TCP 的数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了一个分片，只需要传输丢失的这个分片。 UDP 的数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 IP 层组装完数据，接着再传给传输层。 TCP 和 UDP 应用场景由于 TCP 是面向连接，能保证数据的可靠性交付，因此经常用于： FTP 文件传输； HTTP &#x2F; HTTPS； 由于 UDP 面向无连接，它可以随时发送数据，再加上UDP本身的处理既简单又高效，因此经常用于： 包总量较少的通信，如 DNS 、SNMP 等； 视频、音频等多媒体通信； 广播通信； TCP连接建立: 三次握手过程图解如下(注意Client 和Server的状态变化): 第一次握手(SYN): 客户端发送SYN请求报文, 告知Seq Num = client_isn 第二次握手(ACK + SYN): 服务端用ACK表示确认收到, SYN告知Seq Num = server_isn 第三次握手(ACK): 客户端ACK表示收到了Seq Num 可以看到, 请求连接过程实际上发送接受了四个报文, 只不过第二次两个报文可以同时发送. TCP断开连接: 四次挥手过程图解如下:(同样注意双方状态变化) 第一次握手(FIN): 客户端要关闭连接, 发送FIN告诉服务端. 第二次握手(ACK): 服务端表示收到了客户端的FIN, 发送ACK表示收到.但是, 还有些数据没发送完, 稍等一会我这边再断开. 第三次握手(FIN): 服务端处理完了, 发送FIN告诉客户端. 第四次握手(ACK): 客户端发送ACK, 说”知道啦, 咱断开吧’’. 重传机制超时重传当发送端发送数据后， 定时器开始计时，没有接到ACK报文， 超过限定时间后，重新传输。这就是超时重传。 触发情况 数据包丢失。 接收方接收到了， 但是ACK报文在网络中丢失或者失效。 怎么确定多久就判定超时呢？ RTT和RTO RTT: round trip time RT0: retransmission timeout 不难得知， 超时重传时间 RTO 的值应该略大于报文往返 RTT 的值。 实际上「报文往返 RTT 的值」是经常变化的，因为我们的网络也是时常变化的。也就因为「报文往返 RTT 的值」 是经常波动变化的，所以「超时重传时间 RTO 的值」应该是一个动态变化的值。 如果超时重发的数据，再次超时的时候，又需要重传的时候，TCP 的策略是超时间隔加倍。 也就是每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。两次超时，就说明网络环境差，不宜频繁反复发送。 快速重传触发情况 当发送方接收到三个ACK报文都表示同一个数据块时， 会触发快速重传。 SACK重传 SACK： 即Selective Acknowledgement。 接收方在ACK报文头部中， 添加当前接收数据包的图表，表示当前数据包的接收情况。 发送方接收到ACK报文即可确定是否需要重发。 D-SACK Duplicate Selective Acknowledgement. SACK说明该部分重复接收了。 D-SACK不是一种新的机制， 而是当发送方收到ACK(SACK)报文后, 比对当前的SACK和ACK,以及是否有重传现象来说明一些重传问题。情况如下： 如果SACK小于ACK且无重传，则SACK对应数据包收到了， 但其ACK丢了。 如果SACK小于ACK且有重传， 说明数据包延时到达了。 如果SACK小于ACK且无重传且SACK对应的ACK包被接收， 说明「发送方」的数据包被复制了; 滑动窗口由于每发送一次就等待一次ACK, 太久了。 就衍生出了滑动窗口的概念， 发送一次后，无需等待ACK，可以再次发送，由序列号来确认数据包拼接顺序。 具体实现发送方 发送方维护三个指针变量（最小发送序号， 下一个数据包发送序号， 滑动窗口最大值）实现。 接收到的ACK指示， 小于该值的数据包都已经接收。可以移动窗口，发送新数据了。 接收方 接收方维护两个指针变量控制窗口(仅接收窗口之内的数据包) 窗口左侧的数据包到达后， 窗口左侧移动到下一个未到达的窗口。 回复的ACK中会通过TCP字段: window来指示接收窗口的大小，动态调整发送速度。 窗口大小，一般由接收方控制， 发送方和接收方的窗口大小大致相等（受操作系统和接收方数据处理速度影响）。 流量控制考虑到接收方处理能力和窗口大小， 需要对发送流量进行控制。 考虑以下情况 接收方的操作系统缓存区不够用了， 缩小了其TCP传输的滑动窗口。 接收方的滑动窗口里的数据处不过来，无法移动。 在以上情况发生时，窗口可用大小可能为0（即窗口关闭），或者太小。 窗口关闭窗口为0时，即窗口关闭， 发送方会等待接收方发送新的ACK告知非0窗口信号 但若这个ACK报文丢失了，发送方迟迟等不到， 就会造成死锁。 因此，发送方收到窗口关闭ACK时， 启动计时， 超时则发送窗口探测window Probe报文, 请求重发. 若探测三次仍是窗口关闭，有些TCP就会选择RST来中断连接。 糊涂窗口综合征 即接收方告知自己窗口很小， 耿直的发送方就发送这么小的数据。 用TCP40个字节的报文去发送几个字节的数据是不值得的。 因此， 可以从两边考虑解决这个问题。如 发送方窗口很小时，如小于1MSS， 或者缓存空间少于一半，直接告知窗口关闭。 采用Nagle算法，避免接收方发送小数据。 Nagle算法它满足以下两个条件中的一条才可以发送数据： 要等到窗口大小 &gt;&#x3D; MSS 或是 数据大小 &gt;&#x3D; MSS 收到之前发送数据的 ack 回包 但是对于一些需要小数据包交互的场景的程序，比如，telnet 或 ssh 这样的交互性比较强的程序，则需要关闭 Nagle 算法。 拥塞控制拥塞控制是为了防止互联网拥塞的， 当网络拥塞时，会降低发送频率。 因此， 拥塞控制主要针对发送方。为了调节发送量，类似滑动窗口， 引出了拥塞窗口的概念。发送窗口取的是接收窗口和拥塞窗口的最小值。 拥塞窗口 Congestion Window 拥塞窗口 cwnd 变化的规则： 只要网络中没有出现拥塞，cwnd 就会增大； 但网络中出现了拥塞，cwnd 就减少； 拥塞控制主要是四个算法： 慢启动 拥塞避免 拥塞发生 快速恢复 慢启动当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1 建立连接后，初始化cwnd = 1，发送一个数据包。 接收到ACK,cwnd += 1,发送2个数据包。 接收到2个ACK，cwnd += 2,发送4个数据包。 … 可以看出慢启动算法，发包的个数是指数性的增长 那慢启动涨到什么时候是个头呢？ 有一个叫慢启动门限 ssthresh （slow start threshold）状态变量。 当 cwnd &lt; ssthresh 时，使用慢启动算法。 当 cwnd &gt;&#x3D; ssthresh 时，就会使用「拥塞避免算法」。 拥塞避免当 cwnd &gt;&#x3D; ssthresh 时，就会使用「拥塞避免算法」。 一般来说 ssthresh 的大小是 65535 字节。 进入拥塞避免算法后，它的规则是：每当收到一个 ACK 时，cwnd 增加 1&#x2F;cwnd。 但是这还是会一直增长呀，会造成网络拥堵的。当网络拥堵时，在TCP连接中就体现为数据包重传。 拥塞发生我们知道有两种重传机制 超时重传 快速重传 超时重传说明数据包已经很难到达了， 因此需要大幅减小发送窗口。此时，将 ssthresh 设为 cwnd/2， cwnd 重置为 1 一夜回到解放前，请看图解 一下子降低到谷底， 很容易就发生卡顿。因此，这肯定不适用于所有网络情况，需要辅以更平缓的算法。 快速重传当发生快速重传时，说明还能收到3个ACK包， 也就没有那么拥塞。 cwnd = cwnd/2 ，也就是设置为原来的一半; ssthresh = cwnd; 注意，此时除了将cwnd = cwnd/2与超时重传不同外，还会进入快速恢复算法 快速恢复算法 拥塞窗口 cwnd = ssthresh + 3 （ 3 的意思是确认有 3 个数据包被收到了）； 重传丢失的数据包； 如果再收到重复的 ACK，那么 cwnd 增加 1； 如果收到新数据的 ACK 后，把 cwnd 设置为第一步中的 ssthresh 的值，原因是该 ACK 确认了新的数据，说明从 duplicated ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态； 拥塞发生整体示意图 相关问题 解答见：4.1 TCP 三次握手与四次挥手面试题 | 小林coding (xiaolincoding.com) 为什么是三次握手？不是两次、四次？ 为什么每次建立 TCP 连接时，初始化的序列号都要求不一样呢？ 初始序列号 ISN 是如何随机产生的？ 既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？ 第一次握手丢失了，会发生什么？ 第二次握手丢失了，会发生什么？ 第三次握手丢失了，会发生什么？ 什么是 SYN 攻击？如何避免 SYN 攻击？ 为什么挥手需要四次？ 第一次挥手丢失了，会发生什么？ 第二次挥手丢失了，会发生什么？ 第三次挥手丢失了，会发生什么？ 第四次挥手丢失了，会发生什么？ 为什么 TIME_WAIT 等待的时间是 2MSL？ 为什么需要 TIME_WAIT 状态？ TIME_WAIT 过多有什么危害？ 如何优化 TIME_WAIT？ 如果已经建立了连接，但是客户端突然出现故障了怎么办？ 如果已经建立了连接，但是服务端的进程崩溃会发生什么？ Socket 编程… 其他方面 已经建立TCP连接时， 拔掉网线， 断电，宕机，进程奔溃后，TCP状态是怎么样的？ HTTPS中的TLS和TCP能同时握手吗？ TCP Keepalive 和 HTTP Keep-Alive 是一个东西吗? tcp_tw_reuse 为什么默认是关闭的？","categories":[{"name":"Internet","slug":"Internet","permalink":"https://messenger1th.github.io/categories/Internet/"},{"name":"TCP&IP","slug":"Internet/TCP-IP","permalink":"https://messenger1th.github.io/categories/Internet/TCP-IP/"}],"tags":[]},{"title":"IP","slug":"Internet/TCP&IP/IP","date":"2024-07-24T14:47:33.947Z","updated":"2024-07-24T14:47:33.948Z","comments":true,"path":"2024/07/24/Internet/TCP&IP/IP/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Internet/TCP&IP/IP/","excerpt":"","text":"IP地址IP地址演变过程, 首先是IPv4. IPv4共32位bit, 以每 8 位为组，共分为 4 组，每组以「.」隔开，再将每组转换成十进制。 由于只有32位, 故最大值为 也就说，最大允许 43 亿台计算机连接到网络。 实际上，IP 地址并不是根据主机台数来配置的，而是以网卡。像服务器、路由器等设备都是有 2 个以上的网卡，也就是它们会有 2 个以上的 IP 地址。 因此，让 43 亿台计算机全部连网其实是不可能的，更何况 IP 地址是由「网络标识」和「主机标识」这两个部分组成的，所以实际能够连接到网络的计算机个数更是少了很多。 IP地址分类互联网诞生之初，IP 地址显得很充裕，于是计算机科学家们设计了分类地址。 IP 地址分类成了 5 种类型，分别是 A 类、B 类、C 类、D 类、E 类。 ABC类地址对于复杂场景, 需要一些特殊IP地址有不一样的用途. 主机号全为 1 指定某个网络下的所有主机，用于广播 主机号全为 0 指定某个网络 广播地址用于在同一个链路中相互连接的主机之间发送数据包。 在本网络内广播的叫做本地广播。例如网络地址为 192.168.0.0&#x2F;24 的情况下，广播地址是 192.168.0.255 。因为这个广播地址的 IP 包会被路由器屏蔽，所以不会到达 192.168.0.0&#x2F;24 以外的其他链路上。 在不同网络之间的广播叫做直接广播。例如网络地址为 192.168.0.0&#x2F;24 的主机向 192.168.1.255&#x2F;24 的目标地址发送 IP 包。收到这个包的路由器，将数据转发给 192.168.1.0&#x2F;24，从而使得所有 192.168.1.1~192.168.1.254 的主机都能收到这个包（由于直接广播有一定的安全问题，多数情况下会在路由器上设置为不转发)。 D、E 类地址而 D 类和 E 类地址是没有主机号的，所以不可用于主机 IP，D 类常被用于多播，E 类是预留的分类，暂时未使用。 多播用于将包发送给特定组内的所有主机。 还是举班级的栗子，老师说：“最后一排的同学，上来做这道数学题。”，老师指定的是最后一排的同学，也就是多播的含义了。 由于广播无法穿透路由，若想给其他网段发送同样的包，就可以使用可以穿透路由的多播。 如何判别是哪类地址? IP分类的缺点缺点一: 同一网络下没有地址层次 比如一个公司里用了 B 类地址，但是可能需要根据生产环境、测试环境、开发环境来划分地址层次，而这种 IP 分类是没有地址层次划分的功能，所以这就缺少地址的灵活性. 缺点二: 网络无法自适应主机数, 导致一个网络下的IP地址浪费或者不够用. C 类地址能包含的最大主机数量实在太少了，只有 254 个，估计一个网吧都不够用。 而 B 类地址能包含的最大主机数量又太多了，6 万多台机器放在一个网络下面，一般的企业基本达不到这个规模，闲着的地址就是浪费。 因此, 提出了无分类IP方案. 即CIDR. 无分类IP方案子网掩码: Mask首先是子网掩码, 是一个使用额外的32bit, 来区分网络和主机号的机制.将子网掩码和 IP 地址按位计算&amp;，就可得到网络号。 由于子网掩码占用了32个bit, 因此在IP地址后使用/区分网络号和主机号的机制:CIDR. CIDR CIDR的全称是Classless Interdomain Routing, 即无类别域间路由, 是子网掩码的另一种表现形式. 表示形式为: ** a.b.c.d/x，其中 /x 表示前 x 位属于网络号**， x 的范围是 0 ~ 32，这就使得 IP 地址更加具有灵活性。 有了自由分类网络号和主机号的机制, 就可以更灵活的配置网络. 但是, 前面我们提到, IP数是由上限的, 不可能把所有设备都接入互联网. 因此, 对于IP地址不够用的情况, 就衍生出公有 IP 地址与私有 IP 地址. 公有 IP 地址与私有 IP 地址 公有 IP 地址是有个组织统一分配的, 由ICANN 组织管理，中文叫「互联网名称与数字地址分配机构」。 **公有IP:**假设你要开一个博客网站，那么你就需要去申请购买一个公有 IP，这样全世界的人才能访问。并且公有 IP 地址基本上要在整个互联网范围内保持唯一。 私有IP:平时我们办公室、家里、学校用的 IP 地址，一般都是私有 IP 地址。因为这些地址允许组织内部的 IT 人员自己管理、自己分配，而且可以重复。因此，你学校的某个私有 IP 地址和我学校的可以是一样的。 那么问题来了, 私有IP如何接入互联网呢? NAT应运而生 NAT&#x2F;NAPT 简单的来说 NAT 就是同个公司、家庭、教室内的主机对外部通信时，把私有 IP 地址转换成公有 IP 地址。 那不是 N 个私有 IP 地址，你就要 N 个公有 IP 地址？这怎么就缓解了 IPv4 地址耗尽的问题？这不瞎扯吗？ 确实是，普通的 NAT 转换没什么意义。 由于绝大多数的网络应用都是使用传输层协议 TCP 或 UDP 来传输数据的。 因此，可以把 IP 地址 + 端口号一起进行转换。 这样，就用一个全球 IP 地址就可以了，这种转换技术就叫网络地址与端口转换 NAPT。 转换过程生成一个 NAPT 路由器的转换表，就可以正确地转换地址跟端口的组合，令客户端 A、B 能同时与服务器之间进行通信。 这种转换表在 NAT 路由器上自动生成。例如，在 TCP 的情况下，建立 TCP 连接首次握手时的 SYN 包一经发出，就会生成这个表。而后又随着收到关闭连接时发出 FIN 包的确认应答从表中被删除。 NAPT 那么牛逼，难道就没缺点了吗？ 缺点由于 NAT&#x2F;NAPT 都依赖于自己的转换表，因此会有以下的问题： 外部无法主动与 NAT 内部服务器建立连接，因为 NAPT 转换表没有转换记录。 转换表的生成与转换操作都会产生性能开销。 通信过程中，如果 NAT 路由器重启了，所有的 TCP 连接都将被重置。 优化方案优化方案一 NAT穿透技术: 客户端主动从 NAT 设备获取公有 IP 地址，然后自己建立端口映射条目，然后用这个条目对外通信，就不需要 NAT 设备来进行转换了。 优化方案二: 上IPv6. IP协议相关技术 DNS: 已知域名求IP ARP: 已知IP求Mac地址.RARP: 已知Mac求IP地址. 常用于打印机等小型嵌入式设备. DHCP: 动态获取IP地址. NAT&#x2F;NAPT: 私有IP转换成公有IP接入互联网. ICMP: 互联网控制报文协议, 指令PING用到该技术 .5.2 ping 的工作原理) IGMP: DHCP DHCP 在生活中我们是很常见的了，我们的电脑通常都是通过 DHCP 动态获取 IP 地址，大大省去了配 IP 信息繁琐的过程。 先说明一点，DHCP 客户端进程监听的是 68 端口号，DHCP 服务端进程监听的是 67 端口号。 请求过程 客户端使用UDP广播,查询DHCP服务器地址. 使用的是255.255.255.255（端口 67）并且使用 0.0.0.0（端口 68） 作为源 IP 地址. DHCP 服务器收到 DHCP 发现报文时，用 DHCP 提供报文（DHCP OFFER） 向客户端做出响应。该报文仍然使用 IP 广播地址 255.255.255.255，该报文信息携带服务器提供可租约的 IP 地址、子网掩码、默认网关、DNS 服务器以及 IP 地址租用期。 客户端收到一个或多个服务器的 DHCP 提供报文后，从中选择一个服务器，并向选中的服务器发送 DHCP 请求报文（DHCP REQUEST)进行响应，回显配置的参数。 最后，服务端用 DHCP ACK 报文对 DHCP 请求报文进行响应，应答所要求的参数。 如果租约的 DHCP IP 地址快期后，客户端会向服务器发送 DHCP 请求报文： 服务器如果同意继续租用，则用 DHCP ACK 报文进行应答，客户端就会延长租期。 服务器如果不同意继续租用，则用 DHCP NACK 报文，客户端就要停止使用租约的 IP 地址。 可以发现，DHCP 交互中，全程都是使用 UDP 广播通信。 咦，用的是广播，那如果 DHCP 服务器和客户端不是在同一个局域网内，路由器又不会转发广播包，那不是每个网络都要配一个 DHCP 服务器？ 所以，为了解决这一问题，就出现了 DHCP 中继代理。有了 DHCP 中继代理以后，对不同网段的 IP 地址分配也可以由一个 DHCP 服务器统一进行管理。 DHCP 客户端会向 DHCP 中继代理发送 DHCP 请求包，而 DHCP 中继代理在收到这个广播包以后，再以单播的形式发给 DHCP 服务器。 服务器端收到该包以后再向 DHCP 中继代理返回应答，并由 DHCP 中继代理将此包广播给 DHCP 客户端 。 因此，DHCP 服务器即使不在同一个链路上也可以实现统一分配和管理IP地址。 ICMP ICMP 全称是 Internet Control Message Protocol，也就是互联网控制报文协议。 ICMP 主要的功能包括：确认 IP 包是否成功送达目标地址、报告发送过程中 IP 包被废弃的原因和改善网络设置等。 在 IP 通信中如果某个 IP 包因为某种原因未能达到目标地址，那么这个具体的原因将由 ICMP 负责通知。 ICMP 大致可以分为两大类： 一类是用于诊断的查询消息，也就是「查询报文类型」 另一类是通知出错原因的错误消息，也就是「差错报文类型」 IGMP 在前面我们知道了组播地址，也就是 D 类地址，既然是组播，那就说明是只有一组的主机能收到数据包，不在一组的主机不能收到数组包，怎么管理是否是在一组呢？那么，就需要 IGMP 协议了。 5.1 IP 基础知识全家桶 | 小林coding (xiaolincoding.com)","categories":[{"name":"Internet","slug":"Internet","permalink":"https://messenger1th.github.io/categories/Internet/"},{"name":"TCP&IP","slug":"Internet/TCP-IP","permalink":"https://messenger1th.github.io/categories/Internet/TCP-IP/"}],"tags":[]},{"title":"Internet-Miscellany","slug":"Internet/Internet-Miscellany","date":"2024-07-24T14:47:33.937Z","updated":"2024-07-24T14:47:33.937Z","comments":true,"path":"2024/07/24/Internet/Internet-Miscellany/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Internet/Internet-Miscellany/","excerpt":"","text":"数据链路层数据链路层总时延的瓶颈依赖于多个因素，如 发送速率：主机或路由器发送数据帧所需要的时间。 传播速率：电磁波在信道中传播的速度。 处理时延：主机或路由器对帧的处理，如分析帧首尾、提取数据部分、差错检验、查找转发表等。 排队时延：在路由器中排队再发出的时延。 数据链路层的工作 封装成帧：互联网上传输的数据以分组为单位，分组交换的必然要求就是帧定界，尤其在数据出现错误时，封装成帧可以让出错的部分尽可能的小，需要重新传输的部分就更少。 透明传输：防止帧定界符被错误处理，如数据中含有界定帧，导致数据出现差错； 差错检测：防止接收到错误数据。 透明传输的方式：字节填充法 差错检测的类型 循环冗余检测法：CRC。例如给数据加上帧校验序列FCS。","categories":[{"name":"Internet","slug":"Internet","permalink":"https://messenger1th.github.io/categories/Internet/"}],"tags":[]},{"title":"Protocol","slug":"Internet/Protocol","date":"2024-07-24T14:47:33.937Z","updated":"2024-07-24T14:47:33.938Z","comments":true,"path":"2024/07/24/Internet/Protocol/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Internet/Protocol/","excerpt":"","text":"协议DHCP什么是DHCP协议？DHCP（Dynamic Host Configuration Protocol,动态主机配置协议）是一个局域网的网络协议，使用UDP协议工作。主要用于给内部网络或网络服务提供供应商自动分配IP地址。DHCP协议是一个应用层协议，能够让设备自动获取IP地址以及其他重要的网络资源。DHCP是基于Client&#x2F;Server工作模式。 流程 DHCP Discover DHCP Offer DHCP Request DHCP ACK DHCP DiscoverDHCP发现阶段，即DHCP客户端寻找DHCP服务器的阶段， DHCP客户端以广播方式发送DHCP Discover包，因为客户端不知道服务器的IP地址，在网络上每台主机都会收到此广播包，但是只有DHCP服务器才可以响应。 DHCP Offer接受到DHCP Discover包的所有DHCP服务器都会做出响应。这些DHCP服务器从尚未出租的IP地址中挑选一个给客户端，向客户端发送一个包含IP地址和其他设置的DHCP Offer包。 DHCP Request客户端收到多台DHCP发送的DHCP offer包，DHCP客户端只接受其中一台DHCP服务器的数据，然后以广播的方式回应DHCP服务器DHCP Request，通知自己选择的DHCP服务器。当局域网中所以的DHCP服务器收到客户端发送的DHCP Request信息，通过查看包，确定是否是选择了自己IP，如果选择的是自己，则会发送一个确认包。否则，不进行响应。 为什么DHCP Request是广播呢？ 主要是为了让其他未被选择的DHCP服务器知道客户端的选择，不再等待，让本来待分配的IP可以再进入备选状态，回收该IP。 DHCP ACK对应的DHCP服务器确认所提供的IP地址信息阶段。 ARP什么是ARP协议？ARP（Address Resolution Protocol）协议，地址解析协议。该协议的功能是将IP地址转化为物理地址。 流程假设PC1想向PC2发生数据。此时，PC1知道PC2的IP，还需要知道MAC地址才能进行数据链路层通信。 首先会查询arp缓存表，如果存在PC2的IP和MAC，则不用Request，直接发生数据。不存在则Requst。 ARP RequestPC1广播Request请求，其中包含自己的IP和MAC地址，以及查询的PC2的IP地址。 ARP Reply由于Request是广播，所以局域网中所有主机都能接收到该包。当本地网络上所有主机都接收到ARP Request后，并且检查是否与自己的IP地址相匹配，如果不匹配则会丢弃，但会缓存PC1的IP和MAC地址。 此时PC2也会收到ARP请求报，PC2确定ARP请求中的IP地址与自己的IP地址相匹配。则会 将PC1的地址和MAC地址加入到自己的本地ARP缓存表中 将包含自己的MAC地址的ARP响应包回复到PC1，此时是单播 PC1接到该数据包，会将PC2的IP和MAC加入到ARP缓存，此时就可以进行正常通信了。 ARP到底是链路层还是网络层？以ARP协议为例，它的功能最终是获取到MAC信息，服务于链路层，从这点考虑，ARP是链路层协议；但是从层次来看，ARP基于Ethernet协议，IP协议基于Ethernet协议，它们在Ethernet协议里面有独立的Type类型，前者是0x0806，后者是0x0800，既然ARP和IP协议”平起平坐”，那么IP是网络层，ARP难道就不是网络层？ 小结：基于功能来考虑，ARP是链路层协议；基于分层&#x2F;包封装来考虑，ARP是网络层协议。（此方法对于ICMP协议同样管用） ICMP什么是ICMP协议？ICMP（Internet Control Message Protocol）网际报文控制协议，是Internet协议族的核心协议之一，它主要用在网络计算机的操作系统中发送出错信息。例如：请求服务不可用，主机不可达。ICMP协议是一种面向无连接的协议，用于传输出错报告控制信息。但是ICMP不是高层协议，而是IP层协议。 ICMP 主要的功能包括：确认 IP 包是否成功送达目标地址、报告发送过程中 IP 包被废弃的原因和改善网络设置等。 在 IP 通信中如果某个 IP 包因为某种原因未能达到目标地址，那么这个具体的原因将由 ICMP 负责通知。 ICMP 的这种通知消息会使用 IP 进行发送 。 报文格式ICMP 报文是封装在 IP 包里面，它工作在网络层，是 IP 协议的助手，包含IP信息和ICMP报文具体内容。 详细信息如下 类型所有类型如下 按照功能分，ICMP协议大致包含两类报文 一类是用于诊断的查询消息，也就是「查询报文类型」，即主动查询。 另一类是通知出错原因的错误消息，也就是「差错报文类型」，即被动地被通知。 查询报文查询报文包含两个，一个是类型为8的请求Echo Request和类型为0的应答Echo Reply。 这俩报文用于进行通信的主机或路由器之间，判断所发送的数据包是否已经成功到达对端的一种消息，ping 命令就是利用这俩实现的。 不过相比原生的 ICMP，Unix的ping实现多了两个字段： 标识符：用以区分是哪个应用程序发 ICMP 包，比如用进程 PID 作为标识符； 序号：序列号从 0 开始，每发送一次新的回送请求就会加 1， 可以用来确认网络包是否有丢失。 在选项数据中，ping 还会存放发送请求的时间值，来计算往返时间，说明路程的长短。 差错报文由类型可知，ICMP差错保温包含以下类型 目标不可达消息 —— 类型 为 3 原点抑制消息 —— 类型 4 重定向消息 —— 类型 5 超时消息 —— 类型 11 目标不可达由报文格式中提到的这个图 不难发现，除了ICMP类型的区分，一种类型还包含多种报文。 比如，类型为3的目标不可达消息（Destination Unreachable Message），还包含具体不可达的信息，如 网络不可达代码为 0 主机不可达代码为 1 协议不可达代码为 2 端口不可达代码为 3 需要进行分片但设置了不分片位代码为 4 代码号设置在类型号后。 网络不可达 代码为 0 IP 地址是分为网络号和主机号的，所以当路由器中的路由器表匹配不到接收方 IP 的网络号，就通过 ICMP 协议以网络不可达（Network Unreachable）的原因告知主机。 自从不再有网络分类以后，网络不可达也渐渐不再使用了。 主机不可达 代码为 1 当路由表中没有该主机的信息，或者该主机没有连接到网络，那么会通过 ICMP 协议以主机不可达（Host Unreachable）的原因告知主机。 协议不可达 代码为 2 当主机使用 TCP 协议访问对端主机时，能找到对端的主机了，可是对端主机的防火墙已经禁止 TCP 协议访问，那么会通过 ICMP 协议以协议不可达的原因告知主机。 端口不可达代码为 3 当主机访问对端主机 8080 端口时，这次能找到对端主机了，防火墙也没有限制，可是发现对端主机没有进程监听 8080 端口，那么会通过 ICMP 协议以端口不可达的原因告知主机。 需要进行分片但设置了不分片位代码为 4 发送端主机发送 IP 数据报时，将 IP 首部的分片禁止标志位设置为1。根据这个标志位，途中的路由器遇到超过 MTU 大小的数据包时，不会进行分片，而是直接抛弃。 随后，通过一个 ICMP 的不可达消息类型，代码为 4 的报文，告知发送端主机。 原点抑制消息原点抑制消息（ICMP Source Quench Message） —— 类型为 4 在使用低速广域线路的情况下，连接 WAN 的路由器可能会遇到网络拥堵的问题。 ICMP 原点抑制消息的目的就是为了缓和这种拥堵情况。 当路由器向低速线路发送数据时，其发送队列的缓存变为零而无法发送出去时，可以向 IP 包的源地址发送一个 ICMP 原点抑制消息。 收到这个消息的主机借此了解在整个线路的某一处发生了拥堵的情况，从而增大 IP 包的传输间隔，减少网络拥堵的情况。 然而，由于这种 ICMP 可能会引起不公平的网络通信，一般不被使用。 重定向消息重定向消息（ICMP Redirect Message） —— 类型 5 如果路由器发现发送端主机使用了「不是最优」的路径发送数据，那么它会返回一个 ICMP 重定向消息给这个主机。 在这个消息中包含了最合适的路由信息和源数据。这主要发生在路由器持有更好的路由信息的情况下。路由器会通过这样的 ICMP 消息告知发送端，让它下次发给另外一个路由器。 好比，小林本可以过条马路就能到的地方，但小林不知道，所以绕了一圈才到，后面小林知道后，下次小林就不会那么傻再绕一圈了。 超时消息IP 包中有一个字段叫做 TTL （Time To Live，生存周期），它的值随着每经过一次路由器就会减 1，直到减到 0 时该 IP 包会被丢弃。 此时，路由器将会发送一个 ICMP 超时消息给发送端主机，并通知该包已被丢弃。 设置 IP 包生存周期的主要目的，是为了在路由控制遇到问题发生循环状况时，避免 IP 包无休止地在网络上被转发。 减到0时，路由器就会向发送端回复一个超时消息。 此外，有时可以用 TTL 控制包的到达范围，例如设置一个较小的 TTL 值，衍生出一些应用。 应用ping —— 查询报文类型的使用像上面提到的， ping 这个程序是使用了 ICMP 里面的 ECHO REQUEST（类型为 8 ） 和 ECHO REPLY （类型为 0）。 traceroute —— 差错报文类型的使用有一款充分利用 ICMP 差错报文类型的应用叫做 traceroute（在UNIX、MacOS中是这个命令，而在Windows中对等的命令叫做 tracert ）。 作用一：追踪途径路由器 traceroute 的第一个作用就是故意设置特殊的 TTL，来追踪去往目的地时沿途经过的路由器。 它的原理就是利用 IP 包的生存期限 从 1 开始按照顺序递增的同时发送 UDP 包，强制接收 ICMP 超时消息的一种方法。 比如，将 TTL 设置 为 1，则遇到第一个路由器，就牺牲了，接着返回 ICMP 差错报文网络包，类型是时间超时。 接下来将 TTL 设置为 2，第一个路由器过了，遇到第二个路由器也牺牲了，也同时返回了 ICMP 差错报文数据包，如此往复，直到到达目的主机。 这样的过程，traceroute 就可以拿到了所有的路由器 IP。 当然有的路由器根本就不会返回这个 ICMP，所以对于有的公网地址，是看不到中间经过的路由的。 发送方如何知道发出的 UDP 包是否到达了目的主机呢？ traceroute 在发送 UDP 包时，会填入一个不可能的端口号值作为 UDP 目标端口号：33434。然后对于每个下一个探针，它都会增加一个，这些端口都是通常认为不会被使用，不过，没有人知道当某些应用程序监听此类端口时会发生什么。 当目的主机，收到 UDP 包后，会返回 ICMP 差错报文消息，但这个差错报文消息的类型是「端口不可达」。 所以，当差错报文类型是端口不可达时，说明发送方发出的 UDP 包到达了目的主机。 作用二：确定路径的 MTU traceroute 还有一个作用是故意设置不分片，从而确定路径的 MTU。 因为有的时候我们并不知道路由器的 MTU 大小，以太网的数据链路上的 MTU 通常是 1500 字节，但是非以太网的 MTU 值就不一样了，所以我们要知道 MTU 的大小，从而控制发送的包大小。 首先在发送端主机发送 IP 数据报时，将 IP 包首部的分片禁止标志位设置为 1。根据这个标志位，途中的路由器不会对大数据包进行分片，而是将包丢弃。 随后，通过一个 ICMP 的不可达消息将数据链路上 MTU 的值一起给发送主机，不可达消息的类型为「需要进行分片但设置了不分片位」。 发送主机端每次收到 ICMP 差错报文时就减少包的大小，以此来定位一个合适的 MTU 值，以便能到达目标主机。 DNS平时人们记住的都是网址，比如www.baidu.com，而要获取到该网址对应的IP，则需要DNS。 什么是DNS协议？DNS（Domain Name System， 域名系统）是因特网上作为域名和IP地址相互映射的一个分布式数据库，能够使用户更方便地访问互联网，而不是用去记住能够被机器直接读取的IP数串。在互联网上域名与IP地址之间是一对一或者多对一的，如果要记住所以的IP地址，显然是不太容易的。虽然域名便于人们记住，但是主机之间只能互相认识IP地址，所以它们之间的转化就需要DNS来完成。 DNS服务器我们常用的网址包含一定的层级关系，比如www.cqu.edu.cn。对应的层级有不同的服务器。 域名的层级关系类似一个树状结构： 根 DNS 服务器 顶级域 DNS 服务器（com） 权威 DNS 服务器（server.com） 缓存计算机中 DNS 记录在本地有两种缓存方式：浏览器缓存和操作系统缓存。 浏览器缓存：浏览器在获取网站域名的实际 IP 地址后会对其进行缓存，减少网络请求的损耗。每种浏览器都有一个固定的 DNS 缓存时间，如 Chrome 的过期时间是 1 分钟，在这个期限内不会重新请求 DNS 操作系统缓存：操作系统的缓存其实是用户自己配置的 hosts 文件。比如 Windows10 下的 hosts 文件存放在 C:\\Windows\\System32\\drivers\\etc\\hosts 查询方式具体 DNS 查询的方式有两种： 递归查询 迭代查询 顾名思义，递归查询就是客户端请求服务器1，则服务器1不知道就会问服务器2，一直问到有服务器知道。然后，一层一层地传递下去。服务器2拿到结果，返回服务器1，服务器1拿到，返回客户端。 迭代查询客户端是问服务器1，服务器1说不知道，但说服务器2可能知道。然后客户端又问服务器2，服务器2说不知道，但说服务器3可能知道。一直是又客户端问。 域名解析过程将查询缓存和DNS请求过程结合就是域名解析。具体过程如下 查缓存：分别查询 浏览器缓存 –&gt; 操作系统缓存 –&gt; hosts文件 缓存没查到，执行DNS查询。然后递归查询本地服务器，由本地服务器（本地服务器通常是网络服务商提供）执行查询。 本地服务器迭代查询（注意：本地域名服务器和其他域名服务器之间的查询方式是迭代查询，防止其他服务器压力过大） 首先本地域名服务器向根域名服务器发起请求，根域名服务器是最高层次的，它并不会直接指明这个域名对应的 IP 地址，而是返回顶级域名服务器的地址，也就是说给本地域名服务器指明一条道路，让他去这里寻找答案 本地域名服务器拿到这个顶级域名服务器的地址后，就向其发起请求，获取权限域名服务器的地址 本地域名服务器根据权限域名服务器的地址向其发起请求，最终得到该域名对应的 IP 地址 设置缓存：浏览器缓存 –&gt; 操作系统缓存 –&gt; hosts文件 用TCP还是UDPDNS一般是用UDP来传输，但特殊情况下会用到TCP。 DNS 不仅存在域名解析的过程，还有区域传输的过程，而在进行区域传输的时候 DNS 会强制使用 TCP 协议。 什么是区域传输？ 这就不得不提一下主域名服务器和辅助域名服务器。 设置域名服务器时，服务器管理员可以选择将域名服务器指定为主服务器还是辅助服务器（也称为从服务器）。 主域名服务器负责维护一个区域的所有域名信息，是特定的所有信息的权威信息源，数据可以修改。主服务器直接从本地文件获取此信息。只能在主服务器上更改区域的 DNS 记录，然后主服务器才能更新辅助服务器。 当主域名服务器出现故障、关闭或负载过重时，辅助域名服务器作为主域名服务器的备份提供域名解析服务。辅助域名服务器中的区域文件中的数据是从主域名服务器中复制过来的，无法自行修改。这个复制过程就是区域传输。 其实就是主从的概念，各位应该也都比较熟悉了。主域名服务器用来写，辅助域名服务器用来读，提供负载均衡的能力，缓解主域名服务器的压力。 总结 DNS 在设计之初就在区域传输中引入了 TCP 协议，在查询中使用 UDP 协议； 当 DNS 超过了 512 字节的限制，我们第一次在 DNS 协议中明确了『当 DNS 查询被截断时，应该使用 TCP 协议进行重试』这一规范； 随后引入的 EDNS 机制允许我们使用 UDP 最多传输 4096 字节的数据，但是由于 MTU 的限制导致的数据分片以及丢失，使得这一特性不够可靠； 在最近的几年，我们重新规定了 DNS 应该同时支持 UDP 和 TCP 协议，TCP 协议也不再只是重试时的选择； NATIPv4 的地址是非常紧缺的，可以通过无分类地址来减缓 IPv4 地址耗尽的速度，但是互联网的用户增速是非常惊人的，所以 IPv4 地址依然有被耗尽的危险。 于是，提出了一种网络地址转换 NAT 的方法，再次缓解了 IPv4 地址耗尽的问题。 简单的来说 NAT 就是同个公司、家庭、教室内的主机对外部通信时，把私有 IP 地址转换成公有 IP 地址。 但是站在NAT路由器的角度来说，N个私有IP对应了N个公有IP，由于是一一对应，问题还是没有得到解决。 普通的 NAT 转换没什么意义。 由于绝大多数的网络应用都是使用传输层协议 TCP 或 UDP 来传输数据的。 因此，可以把 IP 地址 + 端口号一起进行转换。 这样，就用一个全球 IP 地址就可以了，这种转换技术就叫网络地址与端口转换 NAPT。 转换表在 NAT 路由器上自动生成。例如，在 TCP 的情况下，建立 TCP 连接首次握手时的 SYN 包一经发出，就会生成这个表。而后又随着收到关闭连接时发出 FIN 包的确认应答从表中被删除。 NAT 的缺点肯定没有十全十美的方案。 由于 NAT&#x2F;NAPT 都依赖于自己的转换表，因此会有以下的问题： 外部无法主动与 NAT 内部服务器建立连接，因为 NAPT 转换表没有转换记录。 转换表的生成与转换操作都会产生性能开销。 通信过程中，如果 NAT 路由器重启了，所有的 TCP 连接都将被重置。 如何解决 NAT 潜在的问题呢？解决的方法主要有两种方法。 第一种就是改用 IPv6 ： 解决IP地址不够用的问题。 IPv6 可用范围非常大，以至于每台设备都可以配置一个公有 IP 地址，就不搞那么多花里胡哨的地址转换了，但是 IPv6 普及速度还需要一些时间。 第二种 NAT 穿透技术：减小NAT路由器的压力，均摊到每个设备 NAT 穿越技术拥有这样的功能，它能够让网络应用程序主动发现自己位于 NAT 设备之后，并且会主动获得 NAT 设备的公有 IP，并为自己建立端口映射条目，注意这些都是 NAT设备后的应用程序自动完成的。 也就是说，在 NAT 穿透技术中，NAT设备后的应用程序处于主动地位，它已经明确地知道 NAT 设备要修改它外发的数据包，于是它主动配合 NAT 设备的操作，主动地建立好映射，这样就不像以前由 NAT 设备来建立映射了。 说人话，就是客户端主动从 NAT 设备获取公有 IP 地址，然后自己建立端口映射条目，然后用这个条目对外通信，就不需要 NAT 设备来进行转换了。 IGMP ICMP（Internet Group Management Protocol）是因特网组管理协议。 ICMP 跟 IGMP 是一点关系都没有的。 在前面我们知道了组播地址，也就是 D 类地址，既然是组播，那就说明是只有一组的主机能收到数据包，不在一组的主机不能收到数组包，怎么管理是否是在一组呢？那么，就需要 IGMP 协议了。 组播地址一般是用于udp协议，机器发送UDP组播数据时，目标地址填的是组播地址，那么在组播组内的机器都能收到数据包。 TCP和UDPTCP和UDP内容太多，本文不展开。 参考 ping 的工作原理 超详细 DNS 协议解析 IP 基础知识全家桶","categories":[{"name":"Internet","slug":"Internet","permalink":"https://messenger1th.github.io/categories/Internet/"}],"tags":[]},{"title":"RSA与ECDHE","slug":"Internet/HTTP/RSA与ECDHE","date":"2024-07-24T14:47:33.937Z","updated":"2024-07-24T14:47:33.937Z","comments":true,"path":"2024/07/24/Internet/HTTP/RSA与ECDHE/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Internet/HTTP/RSA%E4%B8%8EECDHE/","excerpt":"","text":"RSA算法的TLS四次握手检测对方的数字签名， 验证对方是否有数字签名对应的私钥，并安全地告知对称加密密钥。 TLS 第一次握手： 客户端首先会发一个「Client Hello」消息，字面意思我们也能理解到，这是跟服务器「打招呼」。 消息里面有客户端使用的 TLS 版本号、支持的密码套件列表，以及生成的随机数（Client Random），这个随机数会被服务端保留，它是生成对称加密密钥的材料之一。 TLS 第二次握手 当服务端收到客户端的「Client Hello」消息后，会确认 TLS 版本号是否支持，和从密码套件列表中选择一个密码套件，以及生成随机数（Server Random）。 TLS 第三次握手 客户端验证完证书后，认为可信则继续往下走。接着，客户端就会生成一个新的随机数 (*pre-master*)，用服务器的 RSA 公钥加密该随机数，通过「Change Cipher Key Exchange」消息传给服务端。 TLS 第四次握手 服务器也是同样的操作，发「Change Cipher Spec」和「Encrypted Handshake Message」消息，如果双方都验证加密和解密没问题，那么握手正式完成。 RSA 算法的缺陷使用 RSA 密钥协商算法的最大问题是不支持前向保密。 因为客户端传递随机数（用于生成对称加密密钥的条件之一）给服务端时使用的是公钥加密的，服务端收到到后，会用私钥解密得到随机数。所以一旦服务端的私钥泄漏了，过去被第三方截获的所有 TLS 通讯密文都会被破解。 为了解决这个问题，后面就出现了 ECDHE 密钥协商算法，我们现在大多数网站使用的正是 ECDHE 密钥协商算法。 HTTPS ECDHE 握手解析HTTPS 常用的密钥交换算法有两种，分别是 RSA 和 ECDHE 算法。 离散对数 上图的，底数 a 和模数 p 是离散对数的公共参数，也就说是公开的，b 是真数，i 是对数。知道了对数，就可以用上面的公式计算出真数。但反过来，知道真数却很难推算出对数。 特别是当模数 p 是一个很大的质数，即使知道底数 a 和真数 b ，在现有的计算机的计算水平是几乎无法算出离散对数的，这就是 DH 算法的数学基础。 根据私钥生成的方式，DH 算法分为两种实现： static DH 算法，这个是已经被废弃了； DHE 算法，现在常用的； static DH 算法里有一方的私钥是静态的，也就说每次密钥协商的时候有一方的私钥都是一样的，一般是服务器方固定，即 a 不变，客户端的私钥则是随机生成的。 于是，DH 交换密钥时就只有客户端的公钥是变化，而服务端公钥是不变的，那么随着时间延长，黑客就会截获海量的密钥协商过程的数据，因为密钥协商的过程有些数据是公开的，黑客就可以依据这些数据暴力破解出服务器的私钥，然后就可以计算出会话密钥了，于是之前截获的加密数据会被破解，所以 static DH 算法不具备前向安全性。 DHE算法既然固定一方的私钥有被破解的风险，那么干脆就让双方的私钥在每次密钥交换通信时，都是随机生成的、临时的，这个方式也就是 DHE 算法，E 全称是 ephemeral（临时性的）。 所以，即使有个牛逼的黑客破解了某一次通信过程的私钥，其他通信过程的私钥仍然是安全的，因为每个通信过程的私钥都是没有任何关系的，都是独立的，这样就保证了「前向安全」。 但是，由于DHE 算法计算性能不佳，因为需要做大量的乘法，为了提升 DHE 算法的性能，所以就出现了现在广泛用于密钥交换算法 —— ECDHE 算法。 ECDHE 算法ECDHE 算法是在 DHE 算法的基础上利用了 ECC 椭圆曲线特性，可以用更少的计算量计算出公钥，以及最终的会话密钥。 小红和小明使用 ECDHE 密钥交换算法的过程： 双方事先确定好使用哪种椭圆曲线，和曲线上的基点 G，这两个参数都是公开的； 双方各自随机生成一个随机数作为私钥d，并与基点 G相乘得到公钥Q（Q &#x3D; dG），此时小红的公私钥为 Q1 和 d1，小明的公私钥为 Q2 和 d2； 双方交换各自的公钥，最后小红计算点（x1，y1） &#x3D; d1Q2，小明计算点（x2，y2） &#x3D; d2Q1，由于椭圆曲线上是可以满足乘法交换和结合律，所以 d1Q2 &#x3D; d1d2G &#x3D; d2d1G &#x3D; d2Q1 ，因此双方的 x 坐标是一样的，所以它是共享密钥，也就是会话密钥。 这个过程中，双方的私钥都是随机、临时生成的，都是不公开的，即使根据公开的信息（椭圆曲线、公钥、基点 G）也是很难计算出椭圆曲线上的离散对数（私钥）。 握手过程3.4 HTTPS ECDHE 握手解析 | 小林coding (xiaolincoding.com)","categories":[{"name":"Internet","slug":"Internet","permalink":"https://messenger1th.github.io/categories/Internet/"},{"name":"HTTP","slug":"Internet/HTTP","permalink":"https://messenger1th.github.io/categories/Internet/HTTP/"}],"tags":[]},{"title":"加密算法","slug":"Internet/HTTP/加密算法","date":"2024-07-24T14:47:33.937Z","updated":"2024-07-24T14:47:33.937Z","comments":true,"path":"2024/07/24/Internet/HTTP/加密算法/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Internet/HTTP/%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/","excerpt":"","text":"加密算法由于HTTP是明文传输，存在安全问题。 窃听风险，比如通信链路上可以获取通信内容，用户号容易没。 篡改风险，比如强制植入垃圾广告，视觉污染，用户眼容易瞎。 冒充风险，比如冒充淘宝网站，用户钱容易没。 HTTPS 在 HTTP 与 TCP 层之间加入了 SSL/TLS 协议，可以很好的解决了上述的风险： 信息加密：交互信息无法被窃取。 校验机制：无法篡改通信内容，篡改了就不能正常显示。 身份证书：证明淘宝是真的淘宝网。 HTTPS 采用的是对称加密和非对称加密结合的「混合加密」方式。 1. 混合加密 通过混合加密的方式可以保证信息的机密性，解决了窃听的风险。 如何保证安全呢？ 内容有可能会被窃取呀。如何保证内容不被窃取呢？ 那使用加密算法嘛。 内容有可能被修改呀。如何保证内容不被修改呢？ 使用摘要算法（哈希函数），算出来一个哈希值，传输时将哈希值也传输过去，接收方使用同样的哈希函数算出值来比对。 但是，通过哈希算法可以确保内容不会被篡改，但是并不能保证「内容 + 哈希值」不会被中间人替换，因为这里缺少对客户端收到的消息是否来源于服务端的证明。 如何保证这个信息是真的发送方而不是伪造的呢？ 用数字签名嘛，有了签名就可用证明身份了。 但是，数字签名也是可伪造的呀？ 于是，就有了混合加密。 在通信建立前采用非对称加密的方式交换「会话秘钥」，后续就不再使用非对称加密。 在通信过程中全部使用对称加密的「会话秘钥」的方式加密明文数据。 采用「混合加密」的方式的原因： 对称加密只使用一个密钥，运算速度快，密钥必须保密，无法做到安全的密钥交换。 非对称加密使用两个密钥：公钥和私钥，公钥可以任意分发而私钥保密，解决了密钥交换问题但速度慢。 这两个密钥可以双向加解密的，比如可以用公钥加密内容，然后用私钥解密，也可以用私钥加密内容，公钥解密内容。 公钥通过网络加密传输，私钥自己保存。 公钥加密，私钥解密。这个目的是为了保证内容传输的安全，因为被公钥加密的内容，其他人是无法解密的，只有持有私钥的人，才能解密出实际的内容； 私钥加密，公钥解密。这个目的是为了保证消息不会被冒充，因为私钥是不可泄露的，如果公钥能正常解密出私钥加密的内容，就能证明这个消息是来源于持有私钥身份的人发送的。 因此，现在只要保证数字签名没问题，我发给你的公钥不被窃取或者修改，就可以保证安全。那要怎么保证你安全地得到我的公钥和数字签名呢？ 权威机构CA登场，全靠信誉吃饭。 服务器把自己的公钥注册到CA。 CA用自己的私钥给服务器的数字签名和公钥加密成「数字证书」 将CA的公钥安全地写入操作系统或者浏览器。 这个过程主要保证数字签名和公钥绑定, 无法被篡改。 经典算法经典非对称加密算法 RSA DSA DH ECDHE 经典对称加密算法 DES AES 相关问题为什么需要CA呢？直接发送公钥，保留私钥不就好了吗？ 这种情况数字签名可能被伪造， 即冒充某个服务器。 TLS怎么保证证书的权威性？ CA会对证书（证书即服务端公钥）进行非对称加密，用私钥进行加密。客户端只需要用CA的公钥解密即可验证。 我收集到了服务的数字证书，现在想冒充它，给客户端捏造内容，附上真的数字证书，可以可得逞吗？ 验证的环节是没问题的，客户端可以得到真正的数字签名和公钥，但是冒充的服务器没有真正的私钥，在第四次握手验证时会出现问题。 RSA算法怎么保证客户端和服务端中间的节点无法窃取通讯信息？ 因为第三次握手的时候，客户端发送一个随机数，同时用公钥加密，此时只有持有私钥的服务器能够解密拿到这个随机数。中间节点拿不到。 之后，客户端和服务端拿到3个随机数按照算法生成同一个会话密钥，就可以进行后续加密传输了。而中间节点由于缺少一个随机数，所以无法生成。","categories":[{"name":"Internet","slug":"Internet","permalink":"https://messenger1th.github.io/categories/Internet/"},{"name":"HTTP","slug":"Internet/HTTP","permalink":"https://messenger1th.github.io/categories/Internet/HTTP/"}],"tags":[]},{"title":"Http","slug":"Internet/HTTP/Http","date":"2024-07-24T14:47:33.924Z","updated":"2024-07-24T14:47:33.925Z","comments":true,"path":"2024/07/24/Internet/HTTP/Http/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Internet/HTTP/Http/","excerpt":"","text":"HttpHyper Text Transfer Protocol: 超文本传输协议 超文本：富含文字，图片，视频，超链接等的混合文本。 常见状态码 2xx表示服务器成功处理了客户端请求。 「200 OK」是最常见的成功状态码，表示一切正常。如果是非 HEAD 请求，服务器返回的响应头都会有 body 数据。 「204 No Content」也是常见的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。 「206 Partial Content」是应用于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源的全部，而是其中的一部分，也是服务器处理成功的状态。 3xx表示请求的资源发生变动，需要使用新的URL请求。也就是「重定向」。 「301 Moved Permanently」表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL 再次访问。 「302 Found」表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。 ​ 301 和 302 都会在响应头里使用字段 Location，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。 「304 Not Modified」不具有跳转的含义，表示资源未修改，重定向已存在的缓冲文件，也称缓存重定向，也就是告诉客户端可以继续使用缓存资源，用于缓存控制。 4xx 类状态码表示客户端发送的报文有误，服务器无法处理，也就是错误码的含义。 「400 Bad Request」表示客户端请求的报文有错误，但只是个笼统的错误。 「403 Forbidden」表示服务器禁止访问资源，并不是客户端的请求出错。 「404 Not Found」表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。 5xx 类状态码表示客户端请求报文正确，但是服务器处理时内部发生了错误，属于服务器端的错误码。 「500 Internal Server Error」与 400 类型，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道。 「501 Not Implemented」表示客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思。 「502 Bad Gateway」通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。 「503 Service Unavailable」表示服务器当前很忙，暂时无法响应客户端，类似“网络服务正忙，请稍后重试”的意思。 常见字段 Host字段：用于请求同一台服务器上的不同网站。 Content-Type 字段：服务器回应时，告诉客户端，本次数据是什么格式。 Content-Length 字段：服务器在返回数据时，会有 Content-Length 字段，表明本次回应的数据长度。 Content-Encoding 字段：说明数据的压缩方法。表示服务器返回的数据使用了什么压缩格式 Connection 字段：最常用于客户端要求服务器使用 TCP 持久连接，以便其他请求复用。 Get与PostGET 和 POST 有什么区别？ 根据RFC规范， GET的语义是从服务器获取指定的资源。GET 请求的参数位置一般是写在 URL 中，URL 规定只能支持 ASCII，所以 GET 请求的参数只允许 ASCII 字符 ，而且浏览器会对 URL 的长度有限制（HTTP协议本身对 URL长度并没有做任何规定）。 根据 RFC 规范，**POST 的语义是根据请求负荷（报文body）对指定的资源做出处理.**具体的处理方式视资源类型而不同。POST 请求携带数据的位置一般是写在报文 body 中， body 中的数据可以是任意格式的数据，只要客户端与服务端协商好即可，而且浏览器不会对 body 大小做限制。 GET 和 POST 方法都是安全和幂等的吗？先说明下安全和幂等的概念： 在 HTTP 协议里，所谓的「安全」是指请求方法不会「破坏」服务器上的资源。 所谓的「幂等」，意思是多次执行相同的操作，结果都是「相同」的。 如果从 RFC 规范定义的语义来看： GET 方法就是安全且幂等的，因为它是「只读」操作，无论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。所以，可以对 GET 请求的数据做缓存，这个缓存可以做到浏览器本身上（彻底避免浏览器发请求），也可以做到代理上（如nginx），而且在浏览器中 GET 请求可以保存为书签。 POST 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是不安全的，且多次提交数据就会创建多个资源，所以不是幂等的。所以，浏览器一般不会缓存 POST 请求，也不能把 POST 请求保存为书签。 注意， 上面是从 RFC 规范定义的语义来分析的。 但是实际过程中，开发者不一定会按照 RFC 规范定义的语义来实现 GET 和 POST 方法。比如： 可以用 GET 方法实现新增或删除数据的请求，这样实现的 GET 方法自然就不是安全和幂等。 可以用 POST 方法实现查询数据的请求，这样实现的 POST 方法自然就是安全和幂等。 曾经有个笑话，有人写了个博客，删除博客用的是GET请求，他觉得没人访问就连鉴权都没做。然后Google服务器爬虫爬了一遍，他所有博文就没了。。。 RFC 规范并没有规定 GET 请求不能带 body 的。理论上，任何请求都可以带 body 的。只是因为 RFC 规范定义的 GET 请求是获取资源，所以根据这个语义不需要用到 body。 另外，URL 中的查询参数也不是 GET 所独有的，POST 请求的 URL 中也可以有参数的。 缓存技术HTTP 缓存有两种实现方式，分别是强制缓存和协商缓存。 什么是强制缓存？强制缓存指的是只要浏览器判断缓存没有过期，则直接使用浏览器的本地缓存，决定是否使用缓存的主动性在于浏览器这边。 强缓存是利用下面这两个 HTTP 响应头部（Response Header）字段实现的，它们都用来表示资源在客户端缓存的有效期： Cache-Control， 是一个相对时间； Expires，是一个绝对时间； 如果 HTTP 响应头部同时有 Cache-Control 和 Expires 字段的话，Cache-Control的优先级高于 Expires 。 Cache-control 选项更多一些，设置更加精细，所以建议使用 Cache-Control 来实现强缓存。具体的实现流程如下： 当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 Cache-Control，Cache-Control 中设置了过期时间大小； 浏览器再次请求访问服务器中的该资源时，会先通过请求资源的时间与 Cache-Control 中设置的过期时间大小，来计算出该资源是否过期，如果没有，则使用该缓存，否则重新请求服务器； 服务器再次收到请求后，会再次更新 Response 头部的 Cache-Control。 什么是协商缓存？当我们在浏览器使用开发者工具的时候，你可能会看到过某些请求的响应码是 304，这个是告诉浏览器可以使用本地缓存的资源，通常这种通过服务端告知客户端是否可以使用缓存的方式被称为协商缓存。 协商缓存可以基于两种头部来实现。 第一种：请求头部中的 If-Modified-Since 字段与响应头部中的 Last-Modified 字段实现，这两个字段的意思是： 响应头部中的 Last-Modified：标示这个响应资源的最后修改时间； 请求头部中的 If-Modified-Since：当资源过期了，发现响应头中具有 Last-Modified 声明，则再次发起请求的时候带上 Last-Modified 的时间，服务器收到请求后发现有 If-Modified-Since 则与被请求资源的最后修改时间进行对比（Last-Modified），如果最后修改时间较新（大），说明资源又被改过，则返回最新资源，HTTP 200 OK；如果最后修改时间较旧（小），说明资源无新修改，响应 HTTP 304 走缓存。 第二种：请求头部中的 If-None-Match 字段与响应头部中的 ETag 字段，这两个字段的意思是： 响应头部中 Etag：唯一标识响应资源； 请求头部中的 If-None-Match：当资源过期时，浏览器发现响应头里有 Etag，则再次向服务器发起请求时，会将请求头If-None-Match 值设置为 Etag 的值。服务器收到请求后进行比对，如果资源没有变化返回 304，如果资源变化了返回 200。 第一种实现方式是基于时间实现的，第二种实现方式是基于一个唯一标识实现的，相对来说后者可以更加准确地判断文件内容是否被修改，避免由于时间篡改导致的不可靠问题。 如果 HTTP 响应头部同时有 Etag 和 Last-Modified 字段的时候， Etag 的优先级更高，也就是先会判断 Etag 是否变化了，如果 Etag 没有变化，然后再看 Last-Modified。 注意，协商缓存这两个字段都需要配合强制缓存中 Cache-control 字段来使用，只有在未能命中强制缓存的时候，才能发起带有协商缓存字段的请求。 HTTP 特性 HTTP（1.1） 的优点有哪些？HTTP 最凸出的优点是「简单、灵活和易于扩展、应用广泛和跨平台」。 1. 简单 HTTP 基本的报文格式就是 header + body，头部信息也是 key-value 简单文本的形式，易于理解，降低了学习和使用的门槛。 2. 灵活和易于扩展 HTTP协议里的各类请求方法、URI&#x2F;URL、状态码、头字段等每个组成要求都没有被固定死，都允许开发人员自定义和扩充。 同时 HTTP 由于是工作在应用层（ OSI 第七层），则它下层可以随意变化。 HTTPS 也就是在 HTTP 与 TCP 层之间增加了 SSL&#x2F;TLS 安全传输层，HTTP&#x2F;3 甚至把 TCP 层换成了基于 UDP 的 QUIC。 3. 应用广泛和跨平台 互联网发展至今，HTTP 的应用范围非常的广泛，从台式机的浏览器到手机上的各种 APP，从看新闻、刷贴吧到购物、理财、吃鸡，HTTP 的应用遍地开花，同时天然具有跨平台的优越性。 HTTP（1.1） 的缺点有哪些？HTTP 协议里有优缺点一体的双刃剑，分别是「无状态、明文传输」，同时还有一大缺点「不安全」。 1. 无状态双刃剑 无状态的好处，因为服务器不会去记忆 HTTP 的状态，所以不需要额外的资源来记录状态信息，这能减轻服务器的负担，能够把更多的 CPU 和内存用来对外提供服务。 无状态的坏处，既然服务器没有记忆能力，它在完成有关联性的操作时会非常麻烦。 例如登录-&gt;添加购物车-&gt;下单-&gt;结算-&gt;支付，这系列操作都要知道用户的身份才行。但服务器不知道这些请求是有关联的，每次都要问一遍身份信息。 这样每操作一次，都要验证信息，这样的购物体验还能愉快吗？别问，问就是酸爽！ 对于无状态的问题，解法方案有很多种，其中比较简单的方式用 Cookie 技术。 Cookie 通过在请求和响应报文中写入 Cookie 信息来控制客户端的状态。 2. 明文传输双刃剑 明文意味着在传输过程中的信息，是可方便阅读的，通过浏览器的 F12 控制台或 Wireshark 抓包都可以直接肉眼查看，为我们调试工作带了极大的便利性。 但是这正是这样，HTTP 的所有信息都暴露在了光天化日下，相当于信息裸奔。在传输的漫长的过程中，信息的内容都毫无隐私可言，很容易就能被窃取，如果里面有你的账号密码信息，那你号没了。 3. 不安全 HTTP 比较严重的缺点就是不安全： 通信使用明文（不加密），内容可能会被窃听。比如，账号信息容易泄漏，那你号没了。 不验证通信方的身份，因此有可能遭遇伪装。比如，访问假的淘宝、拼多多，那你钱没了。 无法证明报文的完整性，所以有可能已遭篡改。比如，网页上植入垃圾广告，视觉污染，眼没了。 HTTP 的安全问题，可以用 HTTPS 的方式解决，也就是通过引入 SSL&#x2F;TLS 层，使得在安全上达到了极致。 HTTP&#x2F;1.1、HTTP&#x2F;2、HTTP&#x2F;3 演变HTTP&#x2F;1.1优化 使用长连接改善了HTTP&#x2F;1.0短链接「请求 - 应答」的模式，改用长连接，在请求头中加入keep alive，告诉服务器响应后不要关闭。 支持管道pipline网络传输， 第一个请求发出去，不必等其响应，就可用发送第二个请求。 但是，仍然有性能瓶颈。 仅压缩body部分， 每次发送请求报文的头部重复且冗长未经压缩。 服务器按请求顺序响应， 因此存在「队头阻塞」情况。 没有请求优先级控制。 请求只能从客户端开始，服务器只能被动响应。对于那些很大概率要一块使用的数据，无法智能地一块发送。 由此引出HTTP&#x2F;2。 HTTP&#x2F;2优化对于安全性，HTTP&#x2F;2直接基于HTTPS，安全性有保障。 其次，性能方面，HTTP&#x2F;2 头部压缩：采用HPACK算法，客户端和服务器同时维护一张头部信息表，存入所有字段，生成索引号，仅发送索引号即可（优化问题1）。 二进制格式：HTTP&#x2F;2不像HTTP&#x2F;1.1里地纯文本，采用的是二进制。如状态码200，采用的是11001000而不是字符2,0,0. 数据流：给发送的数据包打上IDStream ID, 即可不按顺序发送。客户端建立的 Stream 必须是奇数号，而服务器建立的 Stream 必须是偶数号。客户端还可以指定数据流的优先级。优先级高的请求，服务器就先响应该请求（优化了问题3）。 多路复用：移除HTTP&#x2F;1.1的串行请求，无需排队，降低延迟，大幅提高连接利用率（优化问题2） 服务器推送：服务端不再是被动地响应，可以主动向客户端发送消息。（优化问题4） 但是，HTTP&#x2F;2仍存在问题。 HTTP&#x2F;2把四个问题都给优化了一遍，但「队头阻塞」问题仍然存在。因为HTTP基于TCP，TCP会保证所有的数据包都到达，即丢包重发。因此，丢包时TCP会发送阻塞。 HTTP&#x2F;3优化HTTP&#x2F;2 队头阻塞的问题是因为 TCP，所以 HTTP&#x2F;3 把 HTTP 下层的 TCP 协议改成了 UDP！ UDP不是可靠的协议， 即使丢包也不会重发。但基于 UDP 的 QUIC 协议 可以实现类似 TCP 的可靠性传输。 QUIC 有以下 3 个特点。 无队头阻塞：QUIC 协议也有类似 HTTP&#x2F;2 Stream 与多路复用的概念，也是可以在同一条连接上并发传输多个 Stream，Stream 可以认为就是一条 HTTP 请求。当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响，因此不存在队头阻塞问题。 更快的连接建立: TCP 和 TLS 是分层的，分别属于内核实现的传输层、openssl 库实现的表示层，因此它们难以合并在一起，需要分批次来握手，先 TCP 握手，再 TLS 握手。 HTTP&#x2F;3 在传输数据前虽然需要 QUIC 协议握手，这个握手过程只需要 1 RTT，握手的目的是为确认双方的「连接 ID」，连接迁移就是基于连接 ID 实现的。 但是 HTTP&#x2F;3 的 QUIC 协议并不是与 TLS 分层，而是QUIC 内部包含了 TLS，它在自己的帧会携带 TLS 里的“记录”，再加上 QUIC 使用的是 TLS&#x2F;1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与密钥协商.如下图： 甚至，在第二次连接的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0-RTT 的效果。 连接迁移:基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接，那么当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立连接。而建立连接的过程包含 TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动的减速过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。 而 QUIC 协议没有用四元组的方式来“绑定”连接，而是通过连接 ID来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了连接迁移的功能。 所以， QUIC 是一个在 UDP 之上的伪 TCP + TLS + HTTP&#x2F;2 的多路复用的协议。 QUIC 是新协议，对于很多网络设备，根本不知道什么是 QUIC，只会当做 UDP，这样会出现新的问题，因为有的网络设备是会丢掉 UDP 包的，而 QUIC 是基于UDP 实现的，那么如果网络设备无法识别这个是 QUIC 包，那么就会当作 UDP包，然后被丢弃。 所以，HTTP&#x2F;3 现在普及的进度非常的缓慢，不知道未来 UDP 是否能够逆袭 TCP。","categories":[{"name":"Internet","slug":"Internet","permalink":"https://messenger1th.github.io/categories/Internet/"},{"name":"HTTP","slug":"Internet/HTTP","permalink":"https://messenger1th.github.io/categories/Internet/HTTP/"}],"tags":[]},{"title":"intro","slug":"Golang/intro","date":"2024-07-24T14:47:33.922Z","updated":"2024-07-24T14:47:33.922Z","comments":true,"path":"2024/07/24/Golang/intro/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Golang/intro/","excerpt":"","text":"入门for range 实现range for slicefor range底层是通过调用for i = 0; i &lt; len; i++来实现的。通过将元素赋值给index和value。 特定情况下有问题。 循环取地址，所有的，取到的地址是那个临时的value的地址。 arr := [2]int&#123;1, 2&#125; res := []*int&#123;&#125; for _, v := range arr &#123; res = append(res, &amp;v) &#125; fmt.Println(*res[0],*res[1]) //expect: 1 2, actual 2 2. 循环开go协程。 var m = []int&#123;1, 2, 3&#125; for i := range m &#123; go func() &#123; fmt.Print(i) &#125;() &#125; //阻塞1分钟等待所有goroutine运行完 time.Sleep(time.Millisecond) //结果可能是3 3 3。 原因类似 range for map对map遍历时删除元素能遍历到么？ var m = map[int]int&#123;1: 1, 2: 2, 3: 3&#125; //only del key once, and not del the current iteration key var once sync.Once for i := range m &#123; once.Do(func() &#123; for _, key := range []int&#123;1, 2, 3&#125; &#123; if key != i &#123; fmt.Printf(&quot;当前 i:%d, del key:%d\\n&quot;, i, key) delete(m, key) break &#125; &#125; &#125;) fmt.Printf(&quot;%d%d\\n&quot;, i, m[i]) &#125; 运行结果： 当前 i:1, del key:2 11 33 上述代码once.Do保证只删除一次。 map内部实现是一个链式hash表，为保证每次无序，初始化时会随机一个遍历开始的位置, 这样，如果删除的元素开始没被遍历到，那就后边就不会出现。 对map遍历时新增元素能遍历到么？ var m = map[int]int&#123;1:1, 2:2, 3:3&#125; for i, _ := range m &#123; m[4] = 4 fmt.Printf(&quot;%d%d &quot;, i, m[i]) &#125; 答案是：可能会。 原因同上，map的hash表初始化时会随机一个遍历开始的位置。 range for channel遍历channel是最特殊的，这是由channel的实现机制决定的： // The loop we generate: // for &#123; // index_temp, ok_temp = &lt;-range // if !ok_temp &#123; // break // &#125; // index = index_temp // original body // &#125; channel遍历是依次从channel中读取数据,读取前是不知道里面有多少个元素的。如果channel中没有元素，则会阻塞等待，如果channel已被关闭，则会解除阻塞并退出循环。 注： 上述注释中index_temp实际上描述是有误的，应该为value_temp，因为index对于channel是没有意义的。 使用for-range遍历channel时只能获取一个返回值。 总结 for-range的实现实际上是C风格的for循环 使用index,value接收range返回值会发生一次数据拷贝 Select实现原理数据结构源码包src/runtime/select.go:scase定义了表示case语句的数据结构： type scase struct &#123; c *hchan // channel kind uint16 elem unsafe.Pointer // data element &#125; scase.c为当前case语句所操作的channel指针，这也说明了一个case语句只能操作一个channel。scase.kind表示该case的类型，分为读channel、写channel和default，三种类型分别由常量定义： caseRecv：case语句中尝试读取scase.c中的数据； caseSend：case语句中尝试向scase.c中写入数据； caseDefault： default语句 scase.elem表示缓冲区地址，跟据scase.kind不同，有不同的用途： scase.kind &#x3D;&#x3D; caseRecv ： scase.elem表示读出channel的数据存放地址； scase.kind &#x3D;&#x3D; caseSend ： scase.elem表示将要写入channel的数据存放地址； Select源码包src/runtime/select.go:selectgo()定义了select选择case的函数： func selectgo(cas0 *scase, order0 *uint16, ncases int) (int, bool) 函数参数： cas0为scase数组的首地址，selectgo()就是从这些scase中找出一个返回。 order0为一个两倍cas0数组长度的buffer，保存scase随机序列pollorder和scase中channel地址序列lockorder pollorder：每次selectgo执行都会把scase序列打乱，以达到随机检测case的目的。 lockorder：所有case语句中channel序列，以达到去重防止对channel加锁时重复加锁的目的。 ncases表示scase数组的长度 函数返回值： int： 选中case的编号，这个case编号跟代码一致 bool: 是否成功从channle中读取了数据，如果选中的case是从channel中读数据，则该返回值表示是否读取成功。 selectgo实现伪代码如下： func selectgo(cas0 *scase, order0 *uint16, ncases int) (int, bool) &#123; //1. 锁定scase语句中所有的channel //2. 按照随机顺序检测scase中的channel是否ready // 2.1 如果case可读，则读取channel中数据，解锁所有的channel，然后返回(case index, true) // 2.2 如果case可写，则将数据写入channel，解锁所有的channel，然后返回(case index, false) // 2.3 所有case都未ready，则解锁所有的channel，然后返回（default index, false） //3. 所有case都未ready，且没有default语句 // 3.1 将当前协程加入到所有channel的等待队列 // 3.2 当将协程转入阻塞，等待被唤醒 //4. 唤醒后返回channel对应的case index // 4.1 如果是读操作，解锁所有的channel，然后返回(case index, true) // 4.2 如果是写操作，解锁所有的channel，然后返回(case index, false) &#125; 特别说明：对于读channel的case来说，如case elem, ok := &lt;-chan1:, 如果channel有可能被其他协程关闭的情况下，一定要检测读取是否成功，因为close的channel也有可能返回，此时ok &#x3D;&#x3D; false。 Context实现https://zhuanlan.zhihu.com/p/68792989 Timer实现原理https://www.cyhone.com/articles/analysis-of-golang-timer/ 时间轮Timer TimerTimer的数据结构如下 type Timer struct &#123; C &lt;-chan Time r runtimeTimer &#125; Timer只有两个成员： C: 管道，上层应用跟据此管道接收事件； r: runtime定时器，该定时器即系统管理的定时器，对上层应用不可见； 这里应该按照层次来理解Timer数据结构，Timer.C即面向Timer用户的，Timer.r是面向底层的定时器实现，用户无法感知Timer.r的存在。 runtimeTimer创建一个Timer实质上是把一个定时任务交给专门的协程进行监控，这个任务的载体便是runtimeTimer，简单的讲，每创建一个Timer意味着创建一个runtimeTimer变量，然后把它交给系统进行监控。我们通过设置runtimeTimer过期后的行为来达到定时的目的。 type runtimeTimer struct &#123; tb uintptr // 存储当前定时器的数组地址 i int // 存储当前定时器的数组下标 when int64 // 当前定时器触发时间 period int64 // 当前定时器周期触发间隔 f func(interface&#123;&#125;, uintptr) // 定时器触发时执行的函数 arg interface&#123;&#125; // 定时器触发时执行函数传递的参数一 seq uintptr // 定时器触发时执行函数传递的参数二(该参数只在网络收发场景下使用) &#125; tb: 系统底层存储runtimeTimer的数组地址； i: 当前runtimeTimer在tb数组中的下标； when: 定时器触发事件的时间； period: 定时器周期性触发间隔（对于Timer来说，此值恒为0）； f: 定时器触发时执行的回调函数，回调函数接收两个参数； arg: 定时器触发时执行回调函数的参数一； seq: 定时器触发时执行回调函数的参数二（Timer并不使用该参数）； 一个进程中的多个Timer都由一个Go底层的协程来管理，为了描述方便我们把这个协程称为系统协程。 系统协程把runtimeTimer存放在数组中，并按照when字段对所有的runtimeTimer进行堆排序，定时器触发时执行runtimeTimer中的预定义函数f，即完成了一次定时任务。 Timer对外接口创建Timer创建Timer实际上就是生成一个Timer，并加入系统协程管理的过程。 func NewTimer(d Duration) *Timer &#123; c := make(chan Time, 1) // 创建一个管道 t := &amp;Timer&#123; // 构造Timer数据结构 C: c, // 新创建的管道 r: runtimeTimer&#123; when: when(d), // 触发时间 f: sendTime, // 触发后执行函数sendTime arg: c, // 触发后执行函数sendTime时附带的参数 &#125;, &#125; startTimer(&amp;t.r) // 此处启动定时器，只是把runtimeTimer放到系统协程的堆中，由系统协程维护 return t &#125; NewTimer()只是构造了一个Timer，然后把Timer.r通过startTimer()交给系统协程维护。 其中when()方法是计算下一次定时器触发的绝对时间，即当前时间+NewTimer()参数d。整体流程如下 用户协程NewTimer，创建Timer，并startTimer，即加入系统协程的堆中由系统协程进行管理。 等时间到期时，系统协程调用创建时给定的函数f，即sendTime函数。sendtime函数将时间写入channel，此时channel会醒来，唤醒主线线程。 停止Timer停止Timer，只是简单的把Timer从系统协程中移除。函数主要实现如下： func (t *Timer) Stop() bool &#123; return stopTimer(&amp;t.r) &#125; stopTimer()即通知系统协程把该Timer移除，即不再监控。系统协程只是移除Timer并不会关闭管道，以避免用户协程读取错误。 系统协程监控Timer是否需要触发，Timer触发后，系统协程会删除该Timer。所以在Stop()执行时有两种情况： Timer还未触发，系统协程已经删除该Timer，Stop()返回false； Timer已经触发，系统协程还未删除该Timer，Stop()返回true; 综上，停止一个Timer示意图如下： 重置Timer重置Timer时会先timer先从系统协程中删除，修改周期后重新添加到系统协程中。 func (t *Timer) Reset(d Duration) bool &#123; w := when(d) active := stopTimer(&amp;t.r) t.r.when = w startTimer(&amp;t.r) return active &#125; 注意 需要注意的是，按照官方说明，Reset()应该作用于已经停掉的Timer或者已经触发的Timer，按照这个约定其返回值将总是返回false，之所以仍然保留是为了保持向前兼容，使用老版本Go编写的应用不需要因为Go升级而修改代码。 如果不按照此约定使用Reset()，有可能遇到Reset()和Timer触发同时执行的情况，此时有可能会收到两个事件，从而对应用程序造成一些负面影响，使用时一定要注意。 type timer struct &#123; tb *timersBucket // the bucket the timer lives in // 当前定时器寄存于系统timer堆的地址 i int // heap index // 当前定时器寄存于系统timer堆的下标 when int64 // 当前定时器下次触发时间 period int64 // 当前定时器周期触发间隔（如果是Timer，间隔为0，表示不重复触发） f func(interface&#123;&#125;, uintptr) // 定时器触发时执行的函数 arg interface&#123;&#125; // 定时器触发时执行函数传递的参数一 seq uintptr // 定时器触发时执行函数传递的参数二(该参数只在网络收发场景下使用) &#125; type timersBucket struct &#123; lock mutex gp *g // 处理堆中事件的协程 created bool // 事件处理协程是否已创建，默认为false，添加首个定时器时置为true sleeping bool // 事件处理协程（gp）是否在睡眠(如果t中有定时器，还未到触发的时间，那么gp会投入睡眠) rescheduling bool // 事件处理协程（gp）是否已暂停（如果t中定时器均已删除，那么gp会暂停） sleepUntil int64 // 事件处理协程睡眠时间 waitnote note // 事件处理协程睡眠事件（据此唤醒协程） t []*timer // 定时器切片 &#125; timer数据结构Timer和Ticker数据结构除名字外完全一样，二者都含有一个runtimeTimer类型的成员，这个就是系统协程所维护的对象。 runtimeTimer类型是time包的名称，在runtime包中，这个类型叫做timer。 timer数据结构如下所示： type timer struct &#123; tb *timersBucket // the bucket the timer lives in // 当前定时器寄存于系统timer堆的地址 i int // heap index // 当前定时器寄存于系统timer堆的下标 when int64 // 当前定时器下次触发时间 period int64 // 当前定时器周期触发间隔（如果是Timer，间隔为0，表示不重复触发） f func(interface&#123;&#125;, uintptr) // 定时器触发时执行的函数 arg interface&#123;&#125; // 定时器触发时执行函数传递的参数一 seq uintptr // 定时器触发时执行函数传递的参数二(该参数只在网络收发场景下使用) &#125; 其中timersBucket便是系统协程存储timer的容器，里面有个切片来存储timer，而i便是timer所在切片的下标。 存储拓扑以Ticker为例，我们回顾一下Ticker、timer和timersBucket关系，假设我们已经创建了3个Ticker，那么它们之间的关系如下： 用户创建Ticker时会生成一个timer，这个timer指向timersBucket，timersBucket记录timer的指针。 timersBucket数据结构我们来看一下timersBucket数据结构： type timersBucket struct &#123; lock mutex gp *g // 处理堆中事件的协程 created bool // 事件处理协程是否已创建，默认为false，添加首个定时器时置为true sleeping bool // 事件处理协程（gp）是否在睡眠(如果t中有定时器，还未到触发的时间，那么gp会投入睡眠) rescheduling bool // 事件处理协程（gp）是否已暂停（如果t中定时器均已删除，那么gp会暂停） sleepUntil int64 // 事件处理协程睡眠时间 waitnote note // 事件处理协程睡眠事件（据此唤醒协程） t []*timer // 定时器切片 &#125; “Bucket”译成中文意为”桶”，顾名思义，timersBucket意为存储timer的容器。 lock: 互斥锁，在timer增加和删除时需要使用； gp: 事件处理协程，就是我们所说的系统协程，这个协程在首次创建Timer或Ticker时生成； create： 状态值，表示系统协程是否创建； sleeping: 系统协程是否在睡眠； rescheduling: 系统协程是否已暂停； sleepUntil: 系统协程睡眠到指定的时间（如果有新的定时任务可能会提前唤醒）； waitnote: 提前唤醒时使用的通知； t: 保存timer的切片，当调用NewTimer()或NewTicker()时便会有新的timer存到此切片中； 看到这里应该能明白，系统协程在首次创建定时器时创建，定时器存储在切片中，系统协程负责计时并维护这个切片。 timersBucket数组通过timersBucket数据结构可以看到，系统协程负责计时并维护其中的多个timer，一个timersBucket包含一个系统协程。 当系统中定时器非常多时，一个系统协程可能处理能力跟不上，所以Go在实现时实际上提供了多个timersBucket，也就有多个系统协程来处理定时器。 最理想的情况，应该预留GOMAXPROCS个timersBucket，以便充分使用CPU资源，但需要跟据实际环境动态分配。为了实现简单，Go在实现时预留了64个timersBucket，绝大部分场景下这些足够了。 每当协程创建定时器时，使用协程所属的ProcessID%64来计算定时器存入的timersBucket。 下图三个协程创建定时器时，定时器分布如下图所示： 为描述方便，上图中3个协程均分布于3个Process中。 timerproctimerproc为系统协程的具体实现。它是在首次创建定时器创建并启动的，一旦启动永不销毁。 如果timersBucket中有定时器，取出堆顶定时器，计算睡眠时间，然后进入睡眠，醒来后触发事件。 某个timer的事件触发后，跟据其是否是周期性定时器来决定将其删除还是修改时间后重新加入堆。 如果堆中已没有事件需要触发，则系统协程将进入暂停态，也可认为是无限时睡眠，直到有新的timer加入才会被唤醒。 timerproc处理事件的流程图如下： TickerTicker与Tiimer类似，不再赘述。 与Timer不同的是，Ticker停止时没有返回值，即不需要关注返回值，实际上返回值也没啥用途。 Ticker没有重置接口，也即Ticker创建后不能通过重置修改周期。 需要格外注意的是Ticker用完后必须主动停止，否则会产生资源泄露，会持续消耗CPU资源。 资源泄露问题 前面介绍Ticker时格外提醒不使用的Ticker需要显式的Stop()，否则会产生资源泄露。研究过timer实现机制后，可以很好的解释这个问题了。 首先，创建Ticker的协程并不负责计时，只负责从Ticker的管道中获取事件； 其次，系统协程只负责定时器计时，向管道中发送事件，并不关心上层协程如何处理事件； 如果创建了Ticker，则系统协程将持续监控该Ticker的timer，定期触发事件。如果Ticker不再使用且没有Stop()，那么系统协程负担会越来越重，最终将消耗大量的CPU资源。 疑问 默认创建64个timersBucket，极端情况下会创建出64个协程来处理事件吗？会 Timer 1.20版本的新原理 Timer警告reset部分是出于什么情况考虑？ Defer 延迟函数的参数在defer语句出现时就已经确定下来了 延迟函数执行按后进先出顺序执行，即先出现的defer最后执行 延迟函数可能操作主函数的具名返回值 延迟函数的参数在defer语句出现时就已经确定下来了参数会被拷贝，如果参数是地址，则元素是最新值。 func a() &#123; i := 0 defer fmt.Println(i) // 0 i++ return &#125; func deferFuncParameter() &#123; var aArray = [3]int&#123;1, 2, 3&#125; //由于只拷贝aArray地址，并未拷贝元素。 defer printArray(&amp;aArray) // 10, 2, 3 aArray[0] = 10 return &#125; 延迟函数执行按后进先出顺序执行，即先出现的defer最后执行这个规则很好理解，定义defer类似于入栈操作，执行defer类似于出栈操作。 设计defer的初衷是简化函数返回时资源清理的动作，资源往往有依赖顺序，比如先申请A资源，再跟据A资源申请B资源，跟据B资源申请C资源，即申请顺序是:A–&gt;B–&gt;C，释放时往往又要反向进行。这就是把deffer设计成FIFO的原因。 每申请到一个用完需要释放的资源时，立即定义一个defer来释放资源是个很好的习惯。 延迟函数可能操作主函数的具名返回值有一个事实必须要了解，关键字return不是一个原子操作，实际上return只代理汇编指令ret，即将跳转程序执行。比如语句return i，实际上分两步进行，即将i值存入栈中作为返回值，然后执行跳转，而defer的执行时机正是跳转前，所以说defer执行时还是有机会操作返回值的。 举个实际的例子进行说明这个过程： func deferFuncReturn() (result int) &#123; i := 1 defer func() &#123; result++ &#125;() return i &#125; 该函数的return语句可以拆分成下面两行： result = i return 而延迟函数的执行正是在return之前，即加入defer后的执行过程如下： result = i result++ return 所以上面函数实际返回i++值。 关于主函数有不同的返回方式，但返回机制就如上机介绍所说，只要把return语句拆开都可以很好的理解，下面分别举例说明 分多重情况进行分析 主函数拥有匿名返回值，返回字面值 主函数拥有匿名返回值，返回变量 主函数拥有具名返回值 主函数含有匿名返回值，返回字面值一个主函数拥有一个匿名的返回值，返回时使用字面值，比如返回”1”、”2”、”Hello”这样的值，这种情况下defer语句是无法操作返回值的。 一个返回字面值的函数，如下所示： func foo() int &#123; var i int defer func() &#123; i++ &#125;() return 1 &#125; 上面的return语句，直接把1写入栈中作为返回值，延迟函数无法操作该返回值，所以就无法影响返回值。 主函数拥有匿名返回值，返回变量一个主函数拥有一个匿名的返回值，返回使用本地或全局变量，这种情况下defer语句可以引用到返回值，但不会改变返回值。 一个返回本地变量的函数，如下所示： func foo() int &#123; var i int defer func() &#123; i++ &#125;() return i &#125; 上面的函数，返回一个局部变量，同时defer函数也会操作这个局部变量。对于匿名返回值来说，可以假定仍然有一个变量存储返回值，假定返回值变量为”anony”，上面的返回语句可以拆分成以下过程： anony = i i++ return 由于i是整型，会将值拷贝给anony，所以defer语句中修改i值，对函数返回值不造成影响。 主函数拥有具名返回值主函声明语句中带名字的返回值，会被初始化成一个局部变量，函数内部可以像使用局部变量一样使用该返回值。如果defer语句操作该返回值，可能会改变返回结果。 一个影响函返回值的例子： func foo() (ret int) &#123; defer func() &#123; ret++ &#125;() return 0 &#125; 上面的函数拆解出来，如下所示： ret = 0 ret++ return 函数真正返回前，在defer中对返回值做了+1操作，所以函数最终返回1。 defer实现原理本节我们尝试了解一些defer的实现机制。 defer数据结构源码包src/src/runtime/runtime2.go:_defer定义了defer的数据结构： type _defer struct &#123; sp uintptr //函数栈指针 pc uintptr //程序计数器 fn *funcval //函数地址 link *_defer //指向自身结构的指针，用于链接多个defer &#125; 我们知道defer后面一定要接一个函数的，所以defer的数据结构跟一般函数类似，也有栈地址、程序计数器、函数地址等等。 与函数不同的一点是它含有一个指针，可用于指向另一个defer，每个goroutine数据结构中实际上也有一个defer指针，该指针指向一个defer的单链表，每次声明一个defer时就将defer插入到单链表表头，每次执行defer时就从单链表表头取出一个defer执行。 下图展示多个defer被链接的过程： 从上图可以看到，新声明的defer总是添加到链表头部。 函数返回前执行defer则是从链表首部依次取出执行，不再赘述。 一个goroutine可能连续调用多个函数，defer添加过程跟上述流程一致，进入函数时添加defer，离开函数时取出defer，所以即便调用多个函数，也总是能保证defer是按FIFO方式执行的。 4.2 defer的创建和执行源码包src/runtime/panic.go定义了两个方法分别用于创建defer和执行defer。 deferproc()： 在声明defer处调用，其将defer函数存入goroutine的链表中； deferreturn()：在return指令，准确的讲是在ret指令前调用，其将defer从goroutine链表中取出并执行。 可以简单这么理解，在编译在阶段，声明defer处插入了函数deferproc()，在函数return前插入了函数deferreturn()。 总结 defer定义的延迟函数参数在defer语句出时就已经确定下来了 defer定义顺序与实际执行顺序相反 return不是原子操作，执行过程是: 保存返回值(若有)–&gt;执行defer（若有）–&gt;执行ret跳转 申请资源后立即使用defer关闭资源是好习惯 Mutex实现原理type Mutex struct &#123; state int32 sema uint32 &#125; Go中的互斥锁是使用信号量实现的。由两个字段 state 和 sema 组成。其中 state 表示当前互斥锁的状态，而 sema 是用于控制锁状态的信号量。 mutexLocked — 表示互斥锁的锁定状态； mutexWoken — 表示从正常模式被从唤醒； mutexStarving — 当前的互斥锁进入饥饿状态； waitersCount — 当前互斥锁上等待的 Goroutine 个数； 正常模式与饥饿模式sync.Mutex 有两种模式 — 正常模式和饥饿模式。 在刚开始的时候，是处于正常模式（Barging），也就是，当一个G1持有着一个锁的时候，G2会自旋的去尝试获取这个锁 当自旋超过4次还没有能获取到锁的时候，这个G2就会被加入到获取锁的等待队列里面，并阻塞等待唤醒。 正常来说，获取的锁的顺序是按照FIFO先入先出的顺序。 但唤醒的goroutine 不会直接拥有锁，而是会和新请求锁的 goroutine 竞争锁。新请求锁的 goroutine 具有优势：它正在 CPU 上执行，而且可能有好几个，所以刚刚唤醒的 goroutine 有很大可能在锁竞争中失败，长时间获取不到锁，此时就会进入饥饿状态。这就是引入饥饿模式的原因，防止等待队列中的goroutine多次与正在运行的goroutine竞争失败。 那么也不可能说永远的保持一个饥饿的状态，总归会有吃饱的时候，也就是总有那么一刻Mutex会回归到正常模式，那么回归正常模式必须具备的条件有以下几种： G的执行时间小于1ms 等待队列已经全部清空了 当满足上述两个条件的任意一个的时候，Mutex会切换回正常模式。 Lock 首先假设当前mutex是无竞争、无等待的情况，尝试原子加锁。成功表示加上了锁。对应就是最简单、也可能是最常见的情况，只有一个goruntine在加锁。 不成功则进入慢速加锁。 尝试自旋、避免频繁的协程上下文切换。自旋4次。 自旋4次也拿不到锁，用信号量控制并发，进入睡眠。 等待唤醒后拿到锁。 当然这个流程中还有设置唤醒和饥饿标记、重置自旋次数并重新获取锁的一些步骤。 UnlockGo的Metex是由semaphore实现的， 那么posix库中的pmutex也是sem实现的吗？ C++的thread库中的mutex也是sem实现的吗？从封装posix库而来呢？ todo 第一类对象是指什么？ 参考 《Go专家编程》","categories":[{"name":"Golang","slug":"Golang","permalink":"https://messenger1th.github.io/categories/Golang/"}],"tags":[]},{"title":"golang杂谈","slug":"Golang/golang杂谈","date":"2024-07-24T14:47:33.921Z","updated":"2024-07-24T14:47:33.922Z","comments":true,"path":"2024/07/24/Golang/golang杂谈/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Golang/golang%E6%9D%82%E8%B0%88/","excerpt":"","text":"Golang名词说明变量 GOROOT：go sdk的下载存放位置，标准库包的源码在$GOROOT/src下 GOPATH：第三方依赖的下载存放位置，第三方依赖包的源码在$GOPATH/src下 层级 package：一个包含了多个 .go 文件的目录。 即当前目录下(不包子目录下的文件)的所有文件的包名必须一致. 目录名推荐和package一致，但不强制要求一致。 每一段 Go 程序都 必须 属于一个package包。 module：一个module管理多个package，统一用一个.mod文件控制版本。 一个module只由一个.mod文件管理依赖，且.mod文件定义了该模块的名字。 在同一个module下，import子package时，需要用到该module名字作为前缀。 Project：项目，通常是一个项目一个module，但也有例外，一个项目多个module， GOPATH 与 GOMODULEgo程序的初始化执行顺序从main包开始，递归地展开所有依赖的包并初始化。 go run *.go ├── 执行 Main 包 ├── 初始化Mian包所有引用的包 | ├── 初始化引用包的引用包 (recursive definition, 最后导入的包会最先初始化) | ├── 初始化全局变量 | └── 同一个package如果有多个文件，则以文件名的顺序调用各个文件的init 函数（） └── 初始化 Main 包 ├── 初始化全局变量 └── 以文件名的顺序调用main包中的init 函数 └── main函数 常用命令 go mod init：初始化module，通常就是创建一个.mod文件 go mody tidy：清楚.mod文件中未在使用的第三方依赖 go mod vendor：将.mod文件中依赖项下载到当前目录。 go mod download：下载当前.mod文件中所有的依赖项 go get：只负责下载、不负责编译、安装。 go install：go install 负责下载（但不更新go.mod）、编译、安装。 常见疑惑","categories":[{"name":"Golang","slug":"Golang","permalink":"https://messenger1th.github.io/categories/Golang/"}],"tags":[]},{"title":"Memory","slug":"Golang/Memory","date":"2024-07-24T14:47:33.918Z","updated":"2024-07-24T14:47:33.918Z","comments":true,"path":"2024/07/24/Golang/Memory/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Golang/Memory/","excerpt":"","text":"Golang内存内存分配概况内存分配的算法有很多种，比如 线性分配器 空闲链表分配器 线性分配器类似栈的分配，直接移动内存指针，简单高效， 缺点是 但无法回收中间部分的内存。 要回收的话，需要通过拷贝来回收，常用回收方法有 标记压缩（Mark-Compact） 复制回收（Copying GC） 分代回收（Generational GC） 线性分配器需要与具有拷贝特性的垃圾回收算法配合，一般比较费时， 此外，C&#x2F;C++ 等需要直接对外暴露指针的语言就无法使用该策略。 空闲链表分配器不同的内存块通过指针构成链表，所以可以无需通过拷贝来回收，直接回收那个链表节点即可。 空闲链表分配器可以选择不同的策略在链表中的内存块中进行选择，最常见的是以下四种： 首次适应（First-Fit）— 从链表头开始遍历，选择第一个大小大于申请内存的内存块； 循环首次适应（Next-Fit）— 从上次遍历的结束位置开始遍历，选择第一个大小大于申请内存的内存块； 最优适应（Best-Fit）— 从链表头遍历整个链表，选择最合适的内存块； 最差适应算法（worst-fit）— 它从全部空闲区中找出能满足作业要求的、且大小最大的空闲分区，从而使链表中的节点大小趋于均匀。 隔离适应（Segregated-Fit）— 将内存分割成多个链表，每个链表中的内存块大小相同，申请内存时先找到满足条件的链表，再从链表中选择合适的内存块； 前面4种都比较简单，适用简单情况，现在的分配器通常类似隔离适应算法。 隔离适应算法在Linux下的slab分配器也有应用。 多核并发一般来说，现代内存分配都需要考虑并发问题，所以内存分配时，需要尽量减小锁的开销。 一般有一个总的缓存，需要加锁访问。 其子缓存，就是属于每一个核心的缓存，无需加锁访问。 这就是线程缓存（Thread-Caching Malloc，TCMalloc）来减少锁的竞争。 Go中的内存分配基本如此，使用多级大小的缓存讲对象根据大小分类，并按照类别实施不同的分配策略，搭配上线程缓存分配。 对象类别在Golang中，按照大小，不同的对象可以分为 微对象 (0, 16B) 小对象 [16B, 32KB] 大对象 (32KB, +∞) 不同对象有不同的分配策略。 微对象 (0, 16B) — 先使用微型分配器，再依次尝试线程缓存、中心缓存和堆分配内存； 小对象 [16B, 32KB] — 依次尝试使用线程缓存、中心缓存和堆分配内存； 大对象 (32KB, +∞) — 直接在堆上分配内存； 微分配器Go 语言运行时将小于 16 字节的对象划分为微对象，它会使用线程缓存上的微分配器提高微对象分配的性能，我们主要使用它来分配较小的字符串以及逃逸的临时变量。 微分配器可以将多个较小的内存分配请求合入同一个内存块中，只有当内存块中的所有对象都需要被回收时，整片内存才可能被回收。 微分配器管理的对象不可以是指针类型，管理多个对象的内存块大小 maxTinySize 是可以调整的，在默认情况下，内存块的大小为 16 字节。maxTinySize 的值越大，组合多个对象的可能性就越高，内存浪费也就越严重；maxTinySize 越小，内存浪费就会越少，不过无论如何调整，8 的倍数都是一个很好的选择。 分配时，判断是微对象，就会判断微分配器的空间是否足够，足够则直接分配，不过该内存块只有所有对象都被标记为垃圾时才会回收。 分级分配Go语言中，内存管理单元的具象化结构体是runtime.spanClass，其中含有一个 runtime.mspan ，它标志了该内存管理单元的级别（即管理的内存大小级别）。 type mspan struct &#123; ... spanclass spanClass ... &#125; Go 语言的内存管理模块中一共包含 67 种跨度类，每一个跨度类都会存储特定大小的对象并且包含特定数量的页数以及对象，所有的数据都会被预选计算好并存储在 runtime.class_to_size 和 runtime.class_to_allocnpages 等变量中： class bytes&#x2F;obj bytes&#x2F;span objects tail waste max waste 1 8 8192 1024 0 87.50% 2 16 8192 512 0 43.75% 3 24 8192 341 0 29.24% 4 32 8192 256 0 46.88% 5 48 8192 170 32 31.52% 6 64 8192 128 0 23.44% 7 80 8192 102 32 19.07% … … … … … … 67 32768 32768 1 0 12.50% 当然，既然是分级的分配，每一级都会有不同程度的浪费。例如，跨度类为 5 的 runtime.mspan 中对象的大小上限为 48 字节、管理 1 个页、最多可以存储 170 个对象。因为内存需要按照页进行管理，所以在尾部会浪费 32 字节的内存，当页中存储的对象都是 33 字节时，最多会浪费 31.52% 的资源：$$\\frac{(48-33) * 170}{8192} &#x3D; 0.31518$$除了上述 67 个跨度类之外，运行时中还包含 ID 为 0 的特殊跨度类，它能够管理大于 32KB 的特殊对象。 多级缓存三大组件 mheap mcentral mcache mheapGo 在程序启动时，首先会向操作系统申请一大块内存，并交由mheap结构全局管理。 具体怎么管理呢？mheap 会将这一大块内存，切分成不同规格的小内存块，我们称之为 mspan。 mcentral启动一个 Go 程序，会初始化很多的 mcentral ，每个 mcentral 只负责管理一种特定规格的 mspan。 相当于 mcentral 实现了在 mheap 的基础上对 mspan 的精细化管理。 但是 mcentral 在 Go 程序中是全局可见的，因此如果每次协程来 mcentral 申请内存的时候，都需要加锁。 可以预想，如果每个协程都来 mcentral 申请内存，那频繁的加锁释放锁开销是非常大的。 因此需要有一个 mcentral 的二级代理来缓冲这种压力。 mcache在一个 Go 程序里，每个线程M会绑定给一个处理器P，在单一粒度的时间里只能做多处理运行一个goroutine，每个P都会绑定一个叫 mcache 的本地缓存。 当需要进行内存分配时，当前运行的goroutine会从mcache中查找可用的mspan。从本地mcache里分配内存时不需要加锁，这种分配策略效率更高。 Go中内存布局如下 参考 内存分配器 Golang 内存模型与分配机制","categories":[{"name":"Golang","slug":"Golang","permalink":"https://messenger1th.github.io/categories/Golang/"}],"tags":[]},{"title":"GPM","slug":"Golang/GPM","date":"2024-07-24T14:47:33.917Z","updated":"2024-07-24T14:47:33.917Z","comments":true,"path":"2024/07/24/Golang/GPM/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Golang/GPM/","excerpt":"","text":"GPM调度器核心结构 G（Goroutine） : 每个 Goroutine 对应一个 G 结构体，每个 Goroutine 都有自己独立的栈存放当前的运行内存及状态，可以把一个 G 当做一个任务，当 Goroutine 被调离 CPU 时，调度器代码负责把 CPU 寄存器的值保存在 G 对象的成员变量之中，当 Goroutine 被调度起来运行时，调度器代码又负责把 G 对象的成员变量所保存的寄存器的值恢复到 CPU 的寄存器。 M（Machine）:系统线程 — 对OS内核级线程的封装，**数量对应真实的CPU数(真正干活的对象)**，当 M 没有工作可做的时候，在它休眠前，会“自旋”地来找工作：检查全局队列，查看 netpoll，试图执行 gc 任务，或者“偷”工作 P (Processor): 它包含了运行 goroutine 的资源，如果线程想运行 goroutine，必须先获取 P，P 中还包含了可运行的 G 队列。 P 和 M 何时会被创建 P 何时创建：在确定了 P 的最大数量 n 后，运行时系统会根据这个数量创建 n 个 P。（!初始化的时候就创建了），p在初始化的时候会保存相应的 mcache ，能快速的进行分配微对象和小对象的分配。 M 何时创建：没有足够的 M 来关联 P 并运行其中的可运行的 G。比如所有的 M 此时都阻塞住了，而 P 中还有很多就绪任务，就会去寻找空闲的 M，而没有空闲的，就会去创建新的 M。 调度机制核心流程核心流程包含正常调度、阻塞、抢占三个核心过程。 正常调度：M结合P和G后开始执行G，一直执行完所有P上所有的G，尝试从全局队列拉取、尝试从其他P偷取，都拿不到G了，就自旋。 阻塞： 当 M 执行某一个 G 时候如果发生了 syscall 或则其余阻塞操作，M 会阻塞，如果当前有一些 G 在执行，runtime 会把这个线程 M 从 P 中摘除 (detach)，然后再创建一个新的操作系统的线程 (如果有空闲的线程可用就复用空闲线程) 来服务于这个 P。 当 M 系统调用结束时候，这个 G 会尝试获取一个空闲的 P 执行，并放入到这个 P 的本地队列。如果获取不到 P，那么这个线程 M 变成休眠状态， 加入到空闲线程中，然后这个 G 会被放入全局队列中。 抢占：在 coroutine 中要等待一个协程主动让出 CPU 才执行下一个协程，在 Go 中，一个 goroutine 最多占用 CPU 10ms，防止其他 goroutine 被饿死，go的协程之间通过信号的方式实现了抢占式的调度，这就是 goroutine 不同于 coroutine 的一个地方。 并行机制GOMAXPROCS 设置 P 的数量，最多有 GOMAXPROCS 个线程分布在多个 CPU 上同时运行。GOMAXPROCS 也限制了并发的程度，比如 GOMAXPROCS &#x3D; 核数&#x2F;2，则最多利用了一半的 CPU 核进行并行。 work stealing当本线程无可运行的 G 时，尝试从其他线程绑定的 P 偷取 G，而不是销毁线程。 Hand off机制当本线程因为 G 进行系统调用阻塞时，线程释放绑定的 P，把 P 转移给其他空闲的线程执行。 抢占机制在 coroutine 中要等待一个协程主动让出 CPU 才执行下一个协程，在 Go 中，一个 goroutine 最多占用 CPU 10ms，防止其他 goroutine 被饿死，go的协程之间通过信号的方式实现了抢占式的调度，这就是 goroutine 不同于 coroutine 的一个地方。 局部队列与全局队列在新的调度器中依然有全局 G 队列，但功能已经被弱化了，当 M 执行 work stealing 从其他 P 偷不到 G 时，它可以从全局 G 队列获取 G。 总结 新建协程优先加入当前的P，如果P队列满了，会从队列取出一部分，这部分和新建的都加入到全局队列。 新建G时，运行的 G 会尝试唤醒其他空闲的 P 和 M 组合去执行。 P队列为空时，尝试从全局队列拉取一批G到本地队列。如果全局队列为空，就从其他P的队列进行偷取。 如果偷都偷不到了，就会自旋。 问题 gmp goruntime的计数10ms是怎么实现的？ 10ms后的调度的上下文切换是怎么保存的？ p和m的绑定、解绑是怎么实现的？ gmp调度器中的g绑定到m是通过系统调用补丁吗？具体是怎么实现的？ 参考文章 Golang 调度器 GMP 原理与调度全分析 基于信号的抢占式调度","categories":[{"name":"Golang","slug":"Golang","permalink":"https://messenger1th.github.io/categories/Golang/"}],"tags":[]},{"title":"Golang常见问题","slug":"Golang/Golang常见问题","date":"2024-07-24T14:47:33.917Z","updated":"2024-07-27T12:11:51.877Z","comments":true,"path":"2024/07/24/Golang/Golang常见问题/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Golang/Golang%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/","excerpt":"","text":"Golang常见问题简答 make和new的区别 make：分配内存并初始化对象，只能用与三种引用对象（slice、map、channel）； new：只分配内存并返回对象指针，对象的底层空间置为0； 数组和切片slice的区别 for i, v := range() 这种方式遍历切片底层实现（但1.22版本，v地址会变化，不再赋值同一个元素） 遍历前取size，遍历时size不变。（所以增删元素时，会存在问题，越界or遍历不完） i是下标，v是一个单独的变量，循环时，每次将对应下标的元素赋值给v； v始终是一个变量，v的地址不变； struct能不能用&#x3D;&#x3D;比较 不同类型的不能比较 slice、map、func无法比较 两struct，任一个，含slice、map、func的struct则无法比较 不能用&#x3D;&#x3D;比较：可以用reflect.DeepEqual比较 空结构体struct&#123;&#125;&#123;&#125;占用空间吗：不占用，可以用unsafe.Sizeof(struct&#123;&#125;&#123;&#125; 算出为0 _的作用 import时： import _ &quot;context&quot; ，只执行包下的init函数，但不调用包。 返回值_：忽略返回值 包中init初始化： 包内可以有多个init函数，文件内也可以，执行顺序按照文件名逐个初始化 不管包导入多少次，init只调用一次 包内变量先初始化，再执行init 整个程序整体顺序为：import -&gt; const -&gt; var -&gt; init() -&gt; main() context类型context有四种类型，它本身其实是一个接口 emptyCtx：实现接口，但操作都是返回空值 cancelCtex：实现context和canceler接口，会通知children节点取消 timerCtx：内部封装了cancelCtx，同时也有deadline用于终止cancelCtx。当然也可以提前调用来终止。 valueCtx：能存储{k，v}对，会继承父ctx的{k, v} 应用场景 trace_id：做链路追踪，不侵入业务 流程控制：取消控制、超时控制 channel异常状态操作对于已经关闭的channel，写和再次close，都会panic；读可以正常读，读完则返回对于零值，并附赠标识 对于nil的channle，关闭会直接panic，读和写都会挂起，如果是main，会直接fatal error select交互selecct分为阻塞（不含default）和和非阻塞（含default） 阻塞的，需要等到某一路有数据时唤醒 非阻塞，在有数据的路中随机选一路（不含default），如果都没有数据，则到default。 Map 非并发安全：map不是并发安全的，并发读写的话，会fatal error且无法被recover map遍历无序：由于存在扩容，故扩容前后数据位置可能发生变更，为了不让用户依赖这个点，设计成随机遍历，不让用户迷惑。 nil map和空map有什么区别 对于nil map，写会panic，读、删除则不会。 空map，操作都正常 defer执行顺序defer func()：先压后执行，底层是链栈 defer的函数参数defer压栈时，参数已经像正常函数一样压栈。 func deferCopy() &#123; num := 1 defer fmt.Printf(&quot;num is %d&quot;, num) // 这里会输出1，因为参数已经拷贝到栈里头。 num = 2 return &#125; 但如果是引用类型，由于拷贝的是地址，则能够看到数据的变化。 func printArr(arr *[2]int) &#123; for i := range arr &#123; fmt.Printf(&quot;%d &quot;, arr[i]) &#125; fmt.Println() &#125; func deferRef() &#123; arr := [2]int&#123;1, 2&#125; defer printArr(&amp;arr) // 输出 99 2 arr[0] = 99 return &#125; defer与返回值返回值修改，整个过程分为3步 设置返回值，明确会返回哪个值（已经声明则是这个，未声明的隐式创建） 执行所有defer语句 返回步骤1的结果 所以，确定完结果后，如果defer时修改，最终结果是能看到变化的。 func deferReturnVal() (res int) &#123; // (res int) 这里声明返回值名字 res = 1 defer func() &#123; res++ &#125;() return // 到这里，先明确返回res，执行defer，res+1，返回res，也就是返回2. // return res; 这种方式也是一样的效果 &#125; 但注意，这种未提前声明返回值的，是不会的 实际的过程是，对于未声明的变量，会隐式声明对于的返回值，再执行上面说到的3个步骤。 func deferReturnVal() int &#123; // int 这里未声明返回值的具体名字 num := 1 defer func() &#123; num++ &#125;() return num // 返回1； // 这里存在一个隐式的res // 第一步，先res = num // 第二步，执行defer，num变为2 // 第三步，返回res，此时res为1 &#125; defer recover捕获 只能捕获当前goroutine，子goroutine无法捕获（拦截器处的recover，注意这个点，子goroutine无法捕获） 一个recover只能捕获一次panic，且一一对应 channelmap面试代码题多线程并发打印A、B、C package main import ( _ &quot;context&quot; &quot;fmt&quot; &quot;time&quot; ) var chAStart = make(chan struct&#123;&#125;) var chBStart = make(chan struct&#123;&#125;) var chCStart = make(chan struct&#123;&#125;) func printA() &#123; for &#123; &lt;-chAStart fmt.Println(&quot;A&quot;) time.Sleep(time.Second) chBStart &lt;- struct&#123;&#125;&#123;&#125; &#125; &#125; func printB() &#123; for &#123; &lt;-chBStart fmt.Println(&quot;B&quot;) time.Sleep(time.Second) chCStart &lt;- struct&#123;&#125;&#123;&#125; &#125; &#125; func printC() &#123; for &#123; &lt;-chCStart fmt.Println(&quot;C&quot;) time.Sleep(time.Second) chCStart &lt;- struct&#123;&#125;&#123;&#125; &#125; &#125; func main() &#123; go printA() go printB() go printC() chAStart &lt;- struct&#123;&#125;&#123;&#125; time.Sleep(time.Second * 10) &#125; 常见坑类型断言时，尽量采用ok式从interface{}转成对应类型时，如果类型类型错误切未采用ok式，会Panic package main import ( &quot;fmt&quot; ) // Person 定义一个示例结构体 type Person struct &#123; Name string `json:&quot;name&quot;` Age int `json:&quot;age&quot;` Address string `json:&quot;address&quot;` &#125; type FakePerson struct &#123; Name string `json:&quot;name&quot;` Age int `json:&quot;age&quot;` Address string `json:&quot;address&quot;` &#125; func main() &#123; // 创建一个 Person 对象 originalPerson := Person&#123;Name: &quot;Alice&quot;, Age: 30, Address: &quot;123 Wonderland Ave&quot;&#125; dataStore := make(map[int]interface&#123;&#125;) // 创建一个 map[int]interface&#123;&#125; dataStore[1] = originalPerson // 存入变成interface&#123;&#125; retrievedData := dataStore[1].(FakePerson) // 运行时Panic if false &#123; // 加这一行是为了假装用一下retrievedData，免于编译器报错 fmt.Println(retrievedData) &#125; // 推荐这种方式，不会panic //retrievedData, ok := dataStore[1].(FakePerson) //if !ok &#123; // fmt.Println(&quot;类型断言错误&quot;) //&#125; else &#123; // fmt.Println(retrievedData) //&#125; &#125; 类型断言时，对象值和对象指针是两种不同类型package main import ( &quot;fmt&quot; ) // Person 定义一个示例结构体 type Person struct &#123; Name string Age int Address string &#125; func main() &#123; // 创建一个 Person 对象 p := &amp;Person&#123;Name: &quot;Alice&quot;, Age: 30, Address: &quot;123 Wonderland Ave&quot;&#125; var i interface&#123;&#125; = p // 使用Person指针初始化 interface&#123;&#125; // 断言并输出 if person, ok := i.(Person); ok &#123; fmt.Printf(&quot;Person Value: %+v\\n&quot;, person) &#125; else &#123; fmt.Println(&quot;断言失败&quot;) &#125; &#125; 只能是存入什么类型就是什么类型，且区分对象还是指针。 结合上一个类型错误会Panic的点，存入对象，取出来断言成指针，就很容易Panic。 不可导出变量用json打印时，无法被打印出来常见疑惑类的操作函数中，指针参数和结构体参数有什么区别如果是指针实现，操作的就是原来的对象。 package main import &quot;fmt&quot; type Jiahao struct &#123; Money int &#125; func (jh *Jiahao) AddMoney() int &#123; jh.Money += 1 return jh.Money &#125; func main() &#123; originJH := Jiahao&#123;Money: 0&#125; fmt.Println(&quot;Jiahao 当前的钱为：&quot;, originJH.Money) // 输出 0 originJH.AddMoney() fmt.Println(&quot;Jiahao 执行 “func (originJH *Jiahao) AddMoney() int” 后的钱：&quot;, originJH.Money) // 输出 1 &#125; 如果是结构体实现，操作的是新拷贝的对象，并不会影响原来的对象。 package main import &quot;fmt&quot; type Jiahao struct &#123; Money int &#125; func (jh Jiahao) AddMoney() int &#123; jh.Money += 1 return jh.Money &#125; func main() &#123; originJH := Jiahao&#123;Money: 0&#125; fmt.Println(&quot;Jiahao 当前的钱为：&quot;, originJH.Money) // 输出 0 newJHMoney := originJH.AddMoney() fmt.Println(&quot;新Jiahao对象执行了AddMoney，而非OriginJh，newJHMoney为&quot;, newJHMoney) // 输出 1 fmt.Println(&quot;originJH 执行 “func (jh Jiahao) AddMoney() int” 后的钱，没有变化，还是：&quot;, originJH.Money) // 输出 0 &#125; 所以，指针实现操作原对象，而结构体实现是新拷贝一个对象并进行操作。 所以如果结构体较大，考虑用指针，如果只是为了获取一下临时的计算结果，可以用结构体。 接口实现中，指针实现和结构体实现有什么区别这个问题类似上一个“类的操作函数中，指针参数和结构体参数有什么区别”问题，其结论“指针实现操作原对象，而结构体实现是新拷贝一个对象并进行操作。”还是适用的，但略微有区别的是多态的处理。 面向对象中多态的用法都是接口类型（或者父类对象）指向子类对象，如下面这个例子 package main import &quot;fmt&quot; type IJiahao interface &#123; MakeMoney() error &#125; type Jiahao struct &#123; &#125; func (jh *Jiahao) MakeMoney() error &#123; fmt.Printf(&quot;Jiahao真的在挣钱中...\\n&quot;) return nil &#125; func main() &#123; var ijh IJiahao = &amp;Jiahao&#123;&#125; ijh.MakeMoney() &#125; 在golang中当然也没有问题，但针对 函数实现时，使用指针、使用结构体实现 初始化对象时，使用指针、使用结构体实现 &#96;&#96;&#96;golangvar ijh IJiahao &#x3D; &amp;Jiahao{} &#x2F;&#x2F; 使用指针初始化对象并赋值给接口类型var jh IJiahao &#x3D; Jiahao{} &#x2F;&#x2F; 使用结构体初始化对象并赋值给接口类型 这两个维度，可以组合出4种情况，这四种情况并不都能通过编译器的检查： | | 结构体实现函数 | 结构体指针实现函数 | | :------------------- | :------------- | ------------------ | | 结构体初始化变量 | 通过 | 不通过 | | 结构体指针初始化变量 | 通过 | 通过 | 都是结构体和都是指针的情况好理解，结构体是拷贝一个对象后操作这个新对象，指针是直接在原对象上操作。 而结构体实现函数，指针初始化的情况，其实也是拷贝一个新对象后处理。 重点看指针实现函数，结构体初始化的情况，如下例 ```golang package main import &quot;fmt&quot; type IJiahao interface &#123; MakeMoney() error &#125; type Jiahao struct &#123; Money int &#125; func (jh *Jiahao) MakeMoney() error &#123; jh.Money += 1 fmt.Printf(&quot;Jiahao真的在挣钱中...\\n&quot;) return nil &#125; func main() &#123; var ijh IJiahao = Jiahao&#123;&#125; // 注意！！！这里报错 ijh.MakeMoney() &#125; 我们知道golang中函数传参是值拷贝，哪怕是传的指针，其实也发生了值拷贝，只不过拷贝的是指针，两个指针指向同一个对象。对象的操作函数，本质也是函数第一个参数多了一个对象地址。 所以var ijh IJiahao = Jiahao&#123;&#125;这种情况，会拷贝出一个新的Jiahao，与定义的只允许指针类型的情况func (jh *Jiahao) MakeMoney() error &#123;冲突，所以编译报错。 当一个Interface含有多个抽象函数时，每一个抽象函数都需要符合这个规则。 继承中，指针继承和结构体继承有什么区别实例不转换为接口的情况下无区别总结：不转换为接口时(字段继承和字段指针继承)无区别，在代码中1,2,3,4处(即a,b,pa,pb)都可以正常调用父类的函数 package main import &quot;fmt&quot; type iter interface &#123; run() sleep() &#125; type base struct&#123;&#125; func (p *base) run() &#123; fmt.Println(&quot;Base::run()&quot;) &#125; func (p base) sleep() &#123; fmt.Println(&quot;Base::sleep()&quot;) &#125; type subA struct &#123; base // 字段继承 &#125; type subB struct &#123; *base // 字段指针继承 &#125; /* 总结： 不转换为接口时(字段继承和字段指针继承)无区别，就是正常类型实例使用 在1,2,3,4处(即a,b,pa,pb)都可以正常调用父类的函数 */ func main() &#123; // 实例[字段继承] a := subA&#123;base&#123;&#125;&#125; a.run() // 1 a.sleep() // 实例[字段指针继承] b := subB&#123;&amp;base&#123;&#125;&#125; b.run() // 2 b.sleep() // 指针实例[字段继承] pa := &amp;subA&#123;base&#123;&#125;&#125; pa.run() // 3 pa.sleep() // 指针实例[字段指针继承] pb := &amp;subB&#123;&amp;base&#123;&#125;&#125; pb.run() // 4 pb.sleep() &#125; 实例转换接口时有区别总结：转换为接口时(字段继承和字段指针继承)有区别，在B1,C1,D1都可以正常运行，在A1处出现错误，即subA实例[字段继承]未实现接口 run()方法 package main import &quot;fmt&quot; type iter interface &#123; run() sleep() &#125; type base struct &#123; &#125; func (p *base) run() &#123; fmt.Println(&quot;Base::run()&quot;) &#125; func (p base) sleep() &#123; fmt.Println(&quot;Base::sleep()&quot;) &#125; type subA struct &#123; base &#125; // ---------HERE------------ //func (p subA) run() &#123; // fmt.Println(&quot;subA::run()&quot;) //&#125; type subB struct &#123; *base &#125; /* * 总结： 转换为接口时(字段继承和字段指针继承)有区别， 在B1,C1,D1都可以正常运行 在A1处出现错误，即subA实例[字段继承]未实现接口run()方法 */ func main() &#123; // ======实例转换为接口============= var i iter // a实例[字段继承] a := subA&#123;base&#123;&#125;&#125; i = a // A1 error!!! : subA未实现接口，父类仅仅实现了sleep()方法,run()没有实现 i.run() // A1 i.sleep() // 如果需要将a实例转化为接口，必须实现接口 // Base结构体已经实现了接收者为实例的sleep()方法 // 那么可以在subA结构体实现 接收者为实例接受的run()方法即可---位于HERE处 // b实例[字段指针继承] b := subB&#123;&amp;base&#123;&#125;&#125; i = b // subB实现了接口 i.run() // B1 i.sleep() // =======指针实例转换为接口========== // 指针实例[字段继承] pa := &amp;subA&#123;base&#123;&#125;&#125; i = pa // subA实现了接口 i.run() // C1 i.sleep() // 指针实例[字段指针继承] pb := &amp;subB&#123;&amp;base&#123;&#125;&#125; i = pb // subB实现接口 i.run() // D1 i.sleep() &#125; 总的来说，这并非严格意义上的继承，而是嵌入，值嵌入和指针嵌入。指针嵌入意味着，多个子对象可以共享同一个父对象。 interface &#x3D; nil和指针的nil有什么区别在 Go 中，一个接口值包括两部分：一个是动态类型，一个是动态值。当一个接口被赋值为 nil 时，这意味着它的动态类型和动态值都为空。此时，接口被认为是 nil。 而普通的指针，只需要赋值为nil后就被认为是nil。 但当将一个指针变量（它指向了nil）赋值给interface{}，interface就不是nil了。例子如下 package main import &quot;fmt&quot; func main() &#123; var i interface&#123;&#125; = nil var p *int = nil if i == nil &#123; fmt.Println(&quot;The interface is nil&quot;) // 输出这个 &#125; else &#123; fmt.Println(&quot;The interface is not nil&quot;) &#125; if p == nil &#123; fmt.Println(&quot;The pointer is nil&quot;) // 输出这个 &#125; else &#123; fmt.Println(&quot;The pointer is not nil&quot;) &#125; i = p // 将 nil 指针赋值给接口，之后，p不再是nil if i == nil &#123; fmt.Println(&quot;The interface is nil after assigning a nil pointer&quot;) &#125; else &#123; fmt.Println(&quot;The interface is not nil after assigning a nil pointer&quot;) // 输出这个 &#125; if i == p &#123; fmt.Println(&quot;i == p&quot;) // 输出这个 &#125; else &#123; fmt.Println(&quot;i != p&quot;) &#125; &#125; i == nil为true这里，虽然初看有些惊讶，但其实很好理解，这interface{}存着这个指针的动态类型和动态值（动态类型为*int，动态值即nil），只要它有一个动态类型信息，就不会等于 nil。所以理所应当的不是nil。 i == p为true这里，在比较 interface&#123;&#125; 和具体的指针（即使该指针为 nil）时，会比较它们的动态类型和动态值是否相同，他们的动态类型且值是相同的，所以为true。 给interface{}赋值时，用指针和值的区别其实就是值拷贝和指针拷贝的换皮问题，golang是值传递，interface{}也符合这个规律。 package main import &quot;fmt&quot; type Person struct &#123; Name string Age int &#125; func main() &#123; personPtr := Person&#123;Name: &quot;Alice&quot;, Age: 30&#125; // 创建一个 Person 对象 var i interface&#123;&#125; = &amp;personPtr // 将指针赋值给 interface&#123;&#125; personPtr.Name = &quot;Bob&quot; // 修改指针指向的值 // 断言并输出 if person, ok := i.(*Person); ok &#123; // 指针，能感受到变化 fmt.Printf(&quot;Person (pointer): %+v\\n&quot;, person) &#125; personVal := Person&#123;Name: &quot;Alice&quot;, Age: 30&#125; var j interface&#123;&#125; = personVal personVal.Name = &quot;Bob&quot; // 断言并输出 if person, ok := j.(Person); ok &#123; // 值，不能感受到变化，两者是不同的对象 fmt.Printf(&quot;Person (value): %+v\\n&quot;, person) &#125; &#125; 其他打印时，各种参数 %v ：输出结构体各成员的值 %+v ：输出结构体各成员的名称和值 %#v ：输出结构体名称，并 输出结构体各成员的名称和值 函数闭包：也就是匿名函数，函数内如果有外部参数，会捕获变量 多返回值：底层实现是通过在栈中提前预留空位实现 todointerface怎么理解：原理、作为函数参数是怎么处理的uintptr和unsafe.Pointer的区别 总共三种指针：普通指针类型、unsafe.Pointer、uintptr（本质不是指针）。 普通指针 unsafe.Pointer uintptr sync.Map如何定位内存泄漏？再看下golang面试题 参考 https://ls8sck0zrg.feishu.cn/wiki/wikcnAew9xQPp1eiVT2ThB73lmh","categories":[{"name":"Golang","slug":"Golang","permalink":"https://messenger1th.github.io/categories/Golang/"}],"tags":[]},{"title":"GC","slug":"Golang/GC","date":"2024-07-24T14:47:33.915Z","updated":"2024-07-24T14:47:33.916Z","comments":true,"path":"2024/07/24/Golang/GC/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Golang/GC/","excerpt":"","text":"垃圾回收简介Golang的垃圾回收策略为：并发三色标记法+混合写屏障机制。 三色标记法是一种标记-清除法的实现，三色标记法在并发的时候会存在漏标问题，也就是可能存在资源泄露，可以通过插入写或者删除写屏障来避免。（还有内存碎片的问题，通过TCMalloc解决） 但实际上，还有栈上的对象需要考虑，栈对象可能设计频繁的轻量操作，对这些操作来说，屏障会带来不小的成本。所以Golang引入了混合写屏障，这样就保证了正确性，同时避免栈对象的操作引入屏障的成本。 常用算法标记-清除 Mark-Sweep标记清扫（Mark-Sweep）算法，分为两步走： 标记：标记出当前还存活的对象 清扫：清扫掉未被标记到的垃圾对象 这是一种类似于排除法的间接处理思路，不直接查找垃圾对象，而是标记存活对象，从而取补集推断出垃圾对象. 至于标记清扫算法的不足之处，通过上图也得以窥见一二，那就是会产生内存碎片. 经过几轮标记清扫之后，空闲的内存块可能零星碎片化分布，此时倘若有大对象需要分配内存，可能会因为内存空间无法化零为整从而导致分配失败. 标记-压缩 Mark-Compact 标记压缩（Mark-Compact）算法，是在标记清扫算法的基础上做了升级，在第二步”清扫“的同时还会对存活对象进行压缩整合，使得整体空间更为紧凑，从而解决内存碎片问题. 标记压缩算法在功能性上呈现得很出色，而其存在的缺陷也很简单，就是实现时会有很高的复杂度. 引用计数引用计数（Reference Counting）算法是很简单高效的： 对象每被引用一次，计数器加1 对象每被删除引用一次，计数器减1 GC时，把计数器等于 0 的对象删除 然而，这个朴素的算法存在一个致命的缺陷：无法解决循环引用或者自引用问题. 三色标记法Golang GC 中用到的三色标记法属于标记清扫-算法下的一种实现，由荷兰的计算机科学家 Dijkstra 提出，下面阐述要点： 对象分为三种颜色标记：黑、灰、白 黑对象代表，对象自身存活，且其指向对象都已标记完成 灰对象代表，对象自身存活，但其指向对象还未标记完成 白对象代表，对象尙未被标记到，可能是垃圾对象 标记开始前，将根对象（全局对象、栈上局部变量等）置黑，将其所指向的对象置灰 标记规则是，从灰对象出发，将其所指向的对象都置灰. 所有指向对象都置灰后，当前灰对象置黑 标记结束后，白色对象就是不可达的垃圾对象，需要进行清扫. 但它存在一个漏标问题。 漏标问题漏标问题指的是在用户协程与GC协程并发执行的场景下，部分存活对象未被标记从而被误删的情况。如下图，A被置为黑，B置为灰色。此时用户协程，断开B对C的引用，让A引用C。 错标问题 即本次垃圾回收被标记为灰色，但随后被删除引用（图中A删除对B的引用，此时B已经为灰色），此时可以被删除了，但本轮没删除。 但这本身不是啥问题，可以等到下一轮回收。 强弱三色不变式漏标问题的本质就是，一个已经扫描完成的黑对象指向了一个被灰\\白对象删除引用的白色对象. 构成这一场景的要素拆分如下： （1）黑色对象指向了白色对象 （2）灰、白对象删除了白色对象 （3）（1）、（2）步中谈及的白色对象是同一个对象 （4）（1）发生在（2）之前 一套用于解决漏标问题的方法论称之为强弱三色不变式： 强三色不变式：白色对象不能被黑色对象直接引用（直接破坏（1）） 弱三色不变式：白色对象可以被黑色对象引用，但要从某个灰对象出发仍然可达该白对象（间接破坏了（1）、（2）的联动） 可以通过插入写屏障删除写屏障来保证强弱三色不变式。 插入写屏障插入写屏障（Dijkstra）的目标是实现强三色不变式，保证当一个黑色对象指向一个白色对象前，会先触发屏障将白色对象置为灰色，再建立引用. 删除写屏障删除写屏障就是在删除一个白色对象的引用前，会给它标记为灰色，避免它被黑色对象引用，但显示为白色的情况。 两个屏障，二者选其一，即可解决GC并发的漏标的问题。 混合写屏障然而，真实场景中，需要补充一个新的设定——不太希望栈对象的操作都附带屏障机制。 这是因为栈对象可能涉及频繁的轻量操作，倘若这些高频度操作都需要一一触发屏障机制，那么所带来的成本将是无法接受的. 在这一背景下，单独看插入写屏障或删除写屏障，都无法真正解决漏标问题，除非我们引入额外的Stop the world（STW）阶段，对栈对象的处理进行兜底。 为了消除这个额外的 STW 成本，Golang 1.8 引入了混合写屏障机制，可以视为糅合了插入写屏障+删除写屏障的加强版本，要点如下： GC 开始前，以栈为单位分批扫描，将栈中所有对象置黑 GC 期间，栈上新创建对象直接置黑 堆对象正常启用插入写屏障 堆对象正常启用删除写屏障 内存逃逸分析机制在 C 语言和 C++ 这类需要手动管理内存的编程语言中，将对象或者结构体分配到栈上或者堆上是由工程师自主决定的，这也为工程师的工作带来的挑战，如果工程师能够精准地为每一个变量分配合理的空间，那么整个程序的运行效率和内存使用效率一定是最高的，但是手动分配内存会导致如下的两个问题： 不需要分配到堆上的对象分配到了堆上 — 浪费内存空间； 需要分配到堆上的对象分配到了栈上 — 悬挂指针、影响内存安全； 与悬挂指针相比，浪费内存空间反而是小问题。在 C 语言中，栈上的变量被函数作为返回值返回给调用方是一个常见的错误，在如下所示的代码中，栈上的变量 i 被错误返回： int *dangling_pointer() &#123; int i = 2; return &amp;i; &#125; 当 dangling_pointer 函数返回后，它的本地变量会被编译器回收，调用方获取的是危险的悬挂指针，我们不确定当前指针指向的值是否合法时，这种问题在大型项目中是比较难以发现和定位的。 在编译器优化中，逃逸分析是用来决定指针动态作用域的方法。Go 语言的编译器使用逃逸分析决定哪些变量应该在栈上分配，哪些变量应该在堆上分配，其中包括使用 new、make 和字面量等方法隐式分配的内存，Go 语言的逃逸分析遵循以下两个不变性： 指向栈对象的指针不能存在于堆中； 指向栈对象的指针不能在栈对象回收后存活； 栈内存管理为什么Golang需要管理栈对象，它不是在结束后直接通过调整栈指针回收了吗？ 在Go中，堆和栈上的对象都需要被垃圾收集器管理。与其他语言不同，Go中的本地变量和函数参数不仅分配在栈上，也分配在堆上。这是因为它们的作用域可能超出函数的生命周期，在栈上的对象可能函数结束后，需要返回，此时它是不能被回收的，所以对于这类对象，会分配在堆上。 简单来说，管理栈对象是因为栈上的对象也可能会引用堆上的对象，因此GC需要管理整个应用程序中的对象，包括栈和堆上的对象，以确保没有内存泄漏和堆溢出。 实际上，栈管理并不是说会通过垃圾回收机制删除栈的对象，而是垃圾回收器会分析栈对象是否引用堆对象，避免误删除；栈内存的管理还是通过调整栈指针的方式；本地变量具体分配在栈上还是堆上，在编译期时的内存逃逸分析时决定。 分代算法，采用不同的GC策略进行分类管理. 分代GC算法有效的前提是，绝大多数年轻代对象都是朝生夕死，拥有更高的GC回收率，因此适合采用特别的策略进行处理. 然而Golang中存在内存逃逸机制，会在编译过程中将生命周期更长的对象转移到堆中，将生命周期短的对象分配在栈上，并以栈为单位对这部分对象进行回收. 综上，内存逃逸机制减弱了分代算法对Golang GC所带来的优势，考虑分代算法需要产生额外的成本（如不同年代的规则映射、状态管理以及额外的写屏障），Golang 选择不采用分代GC算法. 问题 内存碎片问题解决：TCMalloc Golang为什么不用引用计数：引用计数在并发的时候需要用到原子操作，虽然它已经比较快了，但相较于普通的内存引用要慢，标记-清除垃圾回收不需要频繁的原子操作，因此在多线程环境下表现更好；而且，他在循环引用或者自引用时，无法清理。 参考 根对象到底是什么？ Golang 垃圾回收原理分析 Go 垃圾回收（三）——三色标记法是什么鬼？ 混合写屏障解决了单删除写屏障的什么情况下的问题？","categories":[{"name":"Golang","slug":"Golang","permalink":"https://messenger1th.github.io/categories/Golang/"}],"tags":[]},{"title":"Data Structure","slug":"Golang/Data Structure","date":"2024-07-24T14:47:33.911Z","updated":"2024-07-24T14:47:33.911Z","comments":true,"path":"2024/07/24/Golang/Data Structure/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Golang/Data%20Structure/","excerpt":"","text":"Go 中常用数据结构Slice实现Slice结构如下 slice struct &#123; array unsafe.Pointer len int cap int &#125; Slice底层依赖于数组来实现，有一个数组指针，指向实际存储数据的数组。 len指的是slice创建时制定的大小。 cap与数据数组的容量有关，当然创建时也可指定。 append时，当cap足够（即比len大），则不会更换底层的数组。 多个slice可以指向同一个数组，同时他们的len和cap都可以指定，修改元素、新增时其他slice会感受到，但新增更换底层数组就不是同一个数组，也就感受不到了。 String实现String的结构如下 type stringStruct struct &#123; str unsafe.Pointer len int &#125; 值得注意的是， len表示的是占的字节个数。比如： s := &quot;你好&quot; fmt.Println(len(s)) // len(s) = 6 字符串可为空，但不可为nil，也不支持修改。为什么不支持修改呢？ 像C++中的string，它本身是含有内存空间的，所以支持修改string。而在go的实现中，string只有一个内存的指针，不含实际存储空间，这样做的好处是string非常轻量，可以很方便的传递，不用担心太多内存拷贝。 因为string通常指向字符串字面量，而字符串字面量一般位于只读段，而不是堆或者栈，所以才有了不可修改的设定。 字符串的构建 可以通过双引号和反引号来构建字符串。 s1 := &quot;str&quot; s2 := ` Jiahao Sa: &quot;Hello&quot; ` //生字符串，不做任何转义。 通常是先构建stringStruct,再强转成string。 //go:nosplit func gostringnocopy(str *byte) string &#123; ss := stringStruct&#123;str: unsafe.Pointer(str), len: findnull(str)&#125; // 先构造 stringStruct s := *(*string)(unsafe.Pointer(&amp;ss)) // stringStruct 转换成 string return s &#125; []byte与string互相转换 string 的数据结构有点类似于切片，切片比它多了一个容量成员。string 和 byte 切片经常互转。 func ByteToString(s []byte) string &#123; return string(s) &#125; func StringToByte(str string) []byte &#123; return []byte(str) &#125; 转换的过程是深拷贝，涉及新内存的分配与内容拷贝。但特定情况下，无需拷贝内存。 有时只是临时需要字符串的场景下，byte 切片转换成 string 时并不会拷贝内存，而是直接返回一个 string，这个 string 的指针指向切片的内存。如 使用 m[string(b)] 来查找 map（map 是 string 为 key，临时把切片 b 转成 string） 字符串拼接，如”&lt;” + “string(b)” + “&gt;” 字符串比较：string(b) &#x3D;&#x3D; “foo” []byte与string应用场景区别 []byte适用于 修改字符，尤其是修改粒度为一个字符的场景。 需要nil值，作为一个slice，可以指向nil。 需要slice操作的场景。 string适用于 不需要nil的场景 需要比较字符串的场景。 实际上，string更具有可读性，所以适用范围更多。偏底层时，[]byte才使用更多。 字符串拼接 str := &quot;str1&quot; + &quot;str2&quot; + &quot;str3&quot; + &quot;str4&quot; 先计算长度再分配内存。分配好内存后，返回这个地址对应的切片，由于二者共用存储，后面向切片写入字符时，字符串就能看到修拼接后的值，也就间接修改了string。 虽然 Map实现原理https://zhuanlan.zhihu.com/p/495998623 type hmap struct &#123; count int // 元素的个数 B uint8 // buckets 数组的长度就是 2^B 个 overflow uint16 // 溢出桶的数量 buckets unsafe.Pointer // 2^B个桶对应的数组指针 oldbuckets unsafe.Pointer // 发生扩容时，记录扩容前的buckets数组指针 extra *mapextra //用于保存溢出桶的地址 &#125; B代表着当前Map的大小，表示当前有$2^B $个桶，哈希函数取模后会映射到这些桶中。下图是一个B&#x3D;2的一个例子，即4个桶。 bucket的数据结构bucket数据结构由runtime/map.go/bmap定义： type bmap struct &#123; tophash [8]uint8 //存储哈希值的高8位 data byte[1] //key value数据:key/key/key/.../value/value/value... overflow *bmap //溢出bucket的地址 &#125; 每个bucket可以存储8个键值对。 tophash是个长度为8的数组，哈希值相同的键（准确的说是哈希值低位相同的键）存入当前bucket时会将哈希值的高位存储在该数组中，以方便后续匹配。 data区存放的是key-value数据，存放顺序是key&#x2F;key&#x2F;key&#x2F;…value&#x2F;value&#x2F;value，如此存放是为了节省字节对齐带来的空间浪费。 overflow 指针指向的是下一个bucket，据此将所有冲突的键连接起来。 注意：上述中data和overflow并不是在结构体中显示定义的，而是直接通过指针运算进行访问的。 下图展示bucket存放8个key-value对： 哈希冲突当有多个元素经哈希函数分配到同一个桶中，即发生了哈希冲突。 go使用链地址法来解决哈希冲突。每一个桶中可以存放8个键值对，当超出时，会由overflow指向下一个桶。这样就形成了一个桶链表。如下图所示： 扩容负载因子负载因子用于衡量一个哈希表冲突情况，Go中的计算方式为：$$负载因子 &#x3D; \\frac{键数量}{bucket数量}$$ 例如，对于一个bucket数量为4，包含4个键值对的哈希表来说，这个哈希表的负载因子为1. 哈希表需要将负载因子控制在合适的大小，超过其阀值需要进行rehash，也即键值对重新组织： 哈希因子过小，说明空间利用率低 哈希因子过大，说明冲突严重，存取效率低 每个哈希表的实现对负载因子容忍程度不同，比如Redis实现中负载因子大于1时就会触发rehash，而Go则在在负载因子达到6.5时才会触发rehash，因为Redis的每个bucket只能存1个键值对，而Go的bucket可能存8个键值对，所以Go可以容忍更高的负载因子。 扩容时机为了保证访问效率，当新元素将要添加进map时，都会检查是否需要扩容，扩容实际上是以空间换时间的手段。 触发扩容的条件有二个： 负载因子 &gt; 6.5时，也即平均每个bucket存储的键值对达到6.5个。 overflow数量 &gt; 2^15时，也即overflow数量超过32768时。 扩容方式采用阻塞、全盘迁移的方式，会导致某一个请求耗时很长。所以一般采用渐进式扩容。GO中的扩容有两种 增量扩容：容量变大，数据迁移到更大的存储中。 等量扩容：容量不变，但把桶中元素变得紧凑。 渐进式扩容时的粒度是：一个hash位置。会把这个一整个桶链表迁移过去。 增量扩容 增量扩容增大B的大小，即每次至少扩大为2倍。假如当前为1个桶，扩容后变为2个，旧数据由oldbuckets指向。 hmap数据结构中oldbuckets成员指身原bucket，而buckets指向了新申请的bucket。新的键值对被插入新的bucket中。 后续对map的访问操作会触发迁移，将oldbuckets中的键值对逐步的搬迁过来。当oldbuckets中的键值对全部搬迁完毕后，删除oldbuckets。 等量扩容 由于链表节点是一个桶，含多个元素，所以频繁删除时，可能导致桶的稀疏。此时需要进行等量扩容来紧凑数据。 使用查找查找过程如下： 跟据key值算出哈希值 取哈希值低位与hmpa.B取模确定bucket位置 取哈希值高位在tophash数组中查询 如果tophash[i]中存储值与哈希值相等，则去找到该bucket中的key值进行比较 当前bucket没有找到，则继续从下个overflow的bucket中查找。 如果当前处于扩容迁移过程，则优先从oldbuckets查找，再查buckets 注：如果查找不到，也不会返回空值，而是返回相应类型的0值。 插入 跟据key值算出哈希值 取哈希值低位与hmap.B取模确定bucket位置 查找该key是否已经存在，如果存在则直接更新值 如果没找到将key，将key插入 sync.Map原理Channel实现原理Channel结构如下 type hchan struct &#123; qcount uint //Channel 中的元素个数； dataqsiz uint //Channel 中的循环队列的长度； buf unsafe.Pointer //Channel 的缓冲区数据指针； elemsize uint16 //收发元素的大小 closed uint32 elemtype *_type //收发元素的类型 sendx uint //Channel 的发送操作处理到的位置 recvx uint //Channel 的接收操作处理到的位置； recvq waitq //处于阻塞的接收队列 sendq waitq //处于阻塞的发送队列 lock mutex //防止并发的锁 &#125; 缓冲区Go中的缓冲区是通过环型队列实现的，创建时指定。下图展示了一个可缓存6个元素的channel示意图： dataqsiz指示了队列长度为6，即可缓存6个元素； buf指向队列的内存，队列中还剩余两个元素； qcount表示队列中还有两个元素； sendx指示后续写入的数据存储的位置，取值[0, 6)； recvx指示从该位置读取数据, 取值[0, 6)； 等待队列从channel读数据，如果channel缓冲区为空或者没有缓冲区，当前goroutine会被阻塞。 向channel写数据，如果channel缓冲区已满或者没有缓冲区，当前goroutine会被阻塞。 被阻塞的goroutine将会挂在channel的等待队列中： 因读阻塞的goroutine会被向channel写入数据的goroutine唤醒； 因写阻塞的goroutine会被从channel读数据的goroutine唤醒； 下图展示了一个没有缓冲区的channel，有几个goroutine阻塞等待读数据： 数据类型一个channel只能传递一种类型的值，类型信息存储在hchan数据结构中。 elemtype代表类型，用于数据传递过程中的赋值； elemsize代表类型大小，用于在buf中定位元素位置。","categories":[{"name":"Golang","slug":"Golang","permalink":"https://messenger1th.github.io/categories/Golang/"}],"tags":[]},{"title":"Effective STL","slug":"C++/Effective STL","date":"2024-07-24T14:47:33.911Z","updated":"2024-07-24T14:47:33.911Z","comments":true,"path":"2024/07/24/C++/Effective STL/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/C++/Effective%20STL/","excerpt":"","text":"Effective STLContainersItem 1: Choose Your containers with care Item 2: Beware the illusion of container-independent code use typedef to facilitate changes of container’s kind by encapsulating Item 3: Make copying cheap and correct for objects in containers create containers of pointers instead of containers of objects. use smart pointers to avoid resource leaking. Item 4: Call empty() instead of checking size() against zero. It’s always constant-time operation about empty() for all containers. But size() is linear time operation for some container, such as list. Item 5: Prefer range member to their single-element counterparts. If you want to do a operation a range of elements, using range member function to accelerate. Item 6: Be alert for C++’s most vexing parse. It’s confusing to recognize. ifstream dataFile(&quot;ints.dat&quot;); list&lt;int&gt; data(istream_iterator&lt;int&gt;(dataFile), istream_iterator&lt;int&gt;()); //this doesn&#x27;t do what you think it does. //three kinds of same declaration are as follow. int f(double d); int f(double (d)); int f(double); //g receive a function pointer. int g(double (*pf)()); int g(double pf()); int g(double ()); for list&lt;int&gt; data(para1, para2) idiom as above. para1‘s type is istream_iterator&lt;int&gt; para2‘s type is function pointer. list&lt;int&gt; data((istream_iterator&lt;int&gt;(dataFile)), istream_iterator&lt;int&gt;()); //proper way to involve range constructor. //solution2 ifstream dataFile(&quot;ints.dat&quot;); istream_iterator&lt;int&gt; dataBegin(dataFile); istream_iterator&lt;int&gt; dataEnd; list&lt;int&gt; data(dataBegin, dataEnd); **Item 7: When using containers of newed pointers, remember to deletethe pointers before the contains is destroyed. ** Containers have responsibility for the element they contain, it’s for pointer when contains pointer, but not for the object pointers point to. Item 8: Never create containers of auto_ptrs. copying leads to nullptr. Item 9: Choosing carefully among erasing options. using different erasing way for different contains. For sequence container, use erase-remove idiom. For list, use remove&amp;remove_if. For associative container, use its erase member function and update the iterator before erasing. Item 10: Be aware of allocator conventions and restrictions. wait updating. Item 11: Understand the legitimate uses of custom allocators. wait updating Item 12: Have realistic expectations about the thread safety of STL contains. use mutex lock to make thread safe. use local object to control lock. vector and stringItem 13: Prefer vector and string to dynamically allocated arrays. Advantages as follow. Resource manage. proper delete behavour. growing capacity. Item 14: Use reserve to avoid unnecessary reallocations. Item 15: Be aware of variations in string implementations. Based on referenced-counting or not. support per-object allocators or not. require zero, one or two dynamic allocations ? varing memory layout. Item 16: Know how to pass vector and string data to legacy APIs. use string::c_str()&amp;&amp;arr[0] to pass. Item 17: Use “the swap trick” to trim excess capacity. string s(&quot;11....1&quot;); //use s s.resize(s.size() / 2); //minimize s&#x27;s size, not capacity. string(s).swap(s);//trick to implement &quot;shrink-to-fit&quot; s.shrink_to_fit(); //library function. Item 18: Avoid using vector&lt;bool&gt; It doesn’t hold bools. It’s not an STL container, implemented by Proxy technique. Associative ContainersItem 19: Understand the difference between equality and equivalence. equality are defined by bool operator==();. equivalence depends on compare function, like typically bool oeprator&lt;(); This example, equivalence only when !(o1 &lt; o2) &amp;&amp; !(o2 &lt; o1). bool operator&lt;()return true when o1 should precede the o2 in order. Item 20: Specify comparison types for associative container of pointers. custom comparison if necessary, like container of pointer. Item 21: Always have comparison functions return false for equal values. As it mentioned in Item19, bool operator&lt;()return true when o1 should precede the o2 in order. when o1 equal o2(namely o1 == o2), o1 shouldn’t precede o2 and o2 shouldn’t precede o2. Also, in associative container, if comparison function return true for equal value, it’s not way that both can be in the range identified by equal_range. Because they are not equivalent. **set ** set&lt;int, less_equal&lt;int&gt;&gt; set&#123;10, 10&#125;; cout &lt;&lt; set.size() &lt;&lt; endl; //size = 2. multiset multiset&lt;int, less_equal&lt;int&gt;&gt; mset&#123;10, 10&#125;; auto it = mset.lower_bound(10); cout &lt;&lt; (it == mset.end()) &lt;&lt; endl; // 1 -&gt; true Item 22: Avoid in-place key modification in set and multiset. set contains &lt;K&gt;, while map contains pair&lt;const K, V&gt;; Don’t change the key part that order depends on, using erase and insert new technique to replace modification. Item 23： Consider replacing associative container with sorted vectors. Consider relevant consumption. Setup. Lookup. Reorganize. vectors commonly use less memory than associative container. Item 24: Choose carefully between map::operator[] and map::insertwhen efficiency is important. map&lt;obj, obj&gt; map; map[1] = 1; //1. map[1] means creating default object by its default construtor. //2. right hand side is created by relevant constructor. //3. replace the defualt one by &quot;=&quot; copy assignment. while insert skip the default object(constructor and destructor.) **Item 25: Familiarize yourself with the nonstandard hashed containers. ** While there are standard hashed container, unordered_set, unordered_map, unorderd_multiset, unordered_multimap. IteratorsItem 26：Prefer iterator to const_iterator, reverse_iterator, and const_reverse_iterator. deprecated: Iterator is more acceptable in many STL function. Item 27: Use distance and advance to convert a container’s const_iterators to iterators. For most containrs, iterator and const_iterator are not same type, except vector and string(using raw pointer and char*). They can’t be implicitly convert. vector&lt;int&gt; arr&#123;1, 2, 3, 4, 5&#125;; vector&lt;int&gt;::iterator it = arr.begin(); vector&lt;int&gt;::const_iterator cit = arr.cbegin() + 3; advance(it, distance&lt;vector&lt;int&gt;::const_iterator&gt;(it, cit)); cout &lt;&lt; *it; Item 28: Understand how to use a reverse_itertor‘s base iterator. Use reverse_iterator::base()to get relevant iterator. Item 29: Consider istreambuf_iterators for character-by-character input. To avoid some unnecessary check behavior consumption for character-by-character input. ifstream data(&quot;test.txt&quot;); string s((istreambuf_iterator&lt;char&gt;(data)), istreambuf_iterator&lt;char&gt;()); cout &lt;&lt; s; AlgorithmsItem 30: Make sure destination ranges are big enough. Be careful something like insert element to the end. Item 31: Know your sorting options. sort algorithm sort partial_sort nth_element partition stable_sort stable_partition Item 32: Follow remove-like algorithm by erase if your remove something. remove implemented by double pointer algorithm, remove the element remain in the front of contain, but don’t change the size. while erase eliminate the element. Item 33: Be wary of remove-like algorithm on container of pointers. Before erasing the pointer, free the resource it point to. Or, use smart pointer. Item 34: Note which algorithms expect sorted ranges. Relevant algorithm binary_seach lower_bound upper_bound equal_range set_union set_intersection set_symmetric_difference set_difference includes unique unique_copy **Item 35：Implement simple case -intensive string comparisons via mismatch or lexicographical_compare. ** custom you own comparison function or function object. Item 36: Understand the proper implementation of copy_if. Waiting Updating. Item 37: Use accumulate or for_each to summarize ranges. custom your function object to keep more information and state. Functors, Functor Classes, Functions, etc.Item 38: Design functor classes for pass-by-value. for BPFC(Big Polymorphic Functor Class), use container of pointer to keep small and monomorphic(not polymorphic). Item 39: Make predicates pure functions. pure functions keeps return bool. only depends on its parameters. Meanwhile, it’s important for functor to declare const for its operator() const. to keep pure. Item 40: Make functor classes adaptable. not1, not2, bind2nd Waiting Updating Item 41: Understand the reason for ptr_fun, mem_fun, and mem_fun_ref. Waiting Updating. class obj &#123; public: obj(char c):c(c) &#123;&#125; void say() &#123; cout &lt;&lt; c &lt;&lt; &#x27; &#x27;; &#125; private: char c; &#125;; For container of object, use vector&lt;obj&gt; vec; vec.emplace_back(&#x27;c&#x27;); for_each(vec.begin(), vec.end(), std::mem_fun_ref(&amp;obj::say)); For container of pointer, use vector&lt;obj*&gt; vec; vec.emplace_back(new obj(&#x27;c&#x27;)); for_each(vec.begin(), vec.end(), std::mem_fun(&amp;obj::say)); Item 42: Make sure less&lt;T&gt; means operator&lt;. less&lt;T&gt; will invoke operator&lt;(). Programing with STLItem 43：Prefer algorithm calls to hand-written loops. Item 44: Prefer member functions to algorithms with the same name. Item 45: Distinguish among count, find, binary_search, lower_bound, upper_bound, and equal_range. Item 46：Consider function objects instead of functions as algorithm parameters. Item 47: Avoid producing write-only code. Item 48: Always #include the proper headers. Item 49: Learn to decipher STL-related compiler diagnostics. Item 50: Familiarize yourself with STL-related websites. SGI STL STLport Boost SummaryFrankly speaking, most of items are useful. Some of them, I need more practice to understand relevant usage.(which I marked waiting updating.)","categories":[{"name":"C++","slug":"C","permalink":"https://messenger1th.github.io/categories/C/"}],"tags":[]},{"title":"More Effective C++","slug":"C++/More Effective C++","date":"2024-07-24T14:47:33.911Z","updated":"2024-07-24T14:47:33.911Z","comments":true,"path":"2024/07/24/C++/More Effective C++/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/C++/More%20Effective%20C++/","excerpt":"","text":"More Effecctive C++基本议题：Basics条款1： 仔细区别pointers和references 由于reference必须代表某个对象，因此必须被初始化。由此，reference不会成为null。 但指针有这种可能性。 pointers可以不被赋初值 pointers可以被重新赋值 条款2：最好使用C++转型操作符 四种 static_cast&lt;&gt;(): 常用于隐式类型转换 const_cast&lt;&gt;()：去除或添加常量性 dynamic_cast&lt;&gt;() 用于多态的类型中，基类与子类的互转。 reintepret_cast&lt;&gt;()：最常用于函数指针转换。不具有移植性。 条款3：绝对不要以多态（polymorphically）方式处理数组 数组是根据当前位置，数组存放对象的大小，来计算下一个对象的位置。 继承体系中，子类很有可能会比基类占用更大内存。 因此，当使用多态方式处理数组时，内存偏移量很可能是错误的，无法找到下一个下标的对象的位置。 条款4： 非不要不提供default constructor 在一定的场景下，没有指定的信息，构造出来的对象是无意义的。 操作符：Operators条款5： 对定制的“类型转换”函数保持警觉 类型转换函数有转换构造和操作符转换等。尽可能声明为explicit来避免非预期的隐式转换。（可以主动使用static_cast转换） class obj&#123; public: explicit obj(int val): val(val) &#123;&#125; explicit operator double() &#123; return val * 10.1; &#125; private: int val; &#125;; 条款6：区分increment和decrement的前置和后置形式 前置和后置形式都应该以前置式为基础，只需维护前置形式即可。 条款7：千万不要重载&amp;&amp;,||和，操作符 就算可以被重载，也不应该无理由的进行重载。 因为无法令其行为像他们内置的行为一样（执行顺序，短路性质）。 *条款8：了解各种不同意义的 new和 delete* operator new和new operator是不一样的。我们经常使用到的new是new opeartor。它实际包括了，分配内存和构造对象两个过程。这个是不能重载的。 但可被显示分为两个过程，一个是分配内存（operator new），一个是构造对象（placement new）。 我们能重载的是operator new,这个函数仅仅负责分配内存，接收size_t类型，返回指向内存的void* 指针。 placement new无法被重载。 由于new operator会调用上面两个过程，因此我们可以重载operator new来自定义new operator部分行为。 同时，由于可以将分配内存和构造对象分开。在需要多次使用一个临时对象的场景下，可以开辟一个该空间重复构造。从而节省大量分配内存，释放内存的时间 同理，delete operator也分为析构对象和释放内存两个过程。对于不同分配方式的内存，需要不同地释放（operator new 和operator delete是对应的， placement new出来的对象需要手动析构）。 析构对象 当使用了placement new的时候，不能对那块内存使用delete operator，因为delete opertor会调用operator delete来释放内存。 但该内存的对象并非由operator new分配而来。因此对于placement new，我们只需要调用其对象的析构函数即可。 释放内存 heap内存就operator delete(ptr); stack内存就无需操作。 数组的new和delete遵循即可。 new对应delete new[] 对应 delete[] 异常：Exception条款9：利用destructors避免泄露资源 异常发生时，普通指针的delete操作可能不会被正常执行。 可以将其delete操作置于一个局部变量的destructor中。局部变量在离开作用域时会被析构。 即，smart pointer。 用智能指针的destructots释放其所指的heap内存。 条款10：在constructors内阻止资源泄露（rescource leak） 当内部需要heap资源时，需要注意，当构造函数中发生异常，可能会对已经分配好的heap资源无法析构释放。 理论上，该类的资源应该由该类的析构函数释放。但由于该对象未成功构造，因此无法被析构（C++规定不那么做）。 可以使用智能指针代替内置指针管理该类的成员，自动释放内存。 条款11：禁止异常流出destructors之外 有两点好处 避免terminate函数在exception传播过程的栈展开（stack-unwinding）机制中被调用。 保证destructor的所有步骤被执行。 条款12：了解”抛出一个exception与”传递一个参数“或调用一个”虚函数“之间的差异 exception objects总是会被复制（第一次抛出时一定被复制）。如果是以pass by value，会被复制更多次。 总共有三种传递方式catch by value\\ by reference\\ by pointer.(pass by value时可以是non-const，但函数传参不行)。 抛出的exception对象被允许的转型动作，比”被传递到函数去“的对象少。 抛出的exception对象pass by value时，总是根据其静态类型来copy。也有例外，见条款25。 exception objects匹配顺序由catch顺序决定。 条款13：以by reference方式捕捉exception 三种方式比较 catch by pointer 如果指向了局部变量，则导致undefined behavior，如果指向heap变量，便要纠结是否要删除该变量回收内存。 因此，不推荐这种方式。 catch by value 可以消除上述是否需要删除和局部变量的问题。但是，也会导致切割（slicing）。如 子类被基类捕获，则切割了子类特有部分。因此，调用的函数还是其基类的。 catch by reference 解决了catch by pointer的变量生存期和catch by value的slicing问题。 可以通过虚函数调用正确版本。 条款14：明智运用exception specifications 懂了大概意思，有些抽象。难以总结。 条款15：了解异常处理（exception handing）的成本 效率：Efficiency条款16：谨记80-20法则 针对20的代码做优化，那才是效率瓶颈。 选用更好的分析器并尽可能以最多的数据分析你的软件。 条款17：考虑使用lazy evaluation 需要用到时才进行相应操作。需要搭配其他技术如代理（proxy） 条款18：分期摊还预期成的计算成本 Over-eager evaluation： Caching：使用Cache缓存 Prefetching：一次取出磁盘的大部分内容（可能他们都会被用到），而不是一块一块地读（改随机读为顺序读）；vector扩张时直接扩1.5倍。 条款19： 了解临时对象的来源 局部对象（如用于swap交换的temp变量）不是临时变量。临时变量来源有 隐式类型转换 返回值 注意reference-to-const参数，常常用于临时变量。但reference-non-const则不会（编译器认为改变临时变量达不到程序员的预期，因此拒绝）。 条款20：协助完成”返回值优化“（RVO） return value optimization 编译器为节pass by value的开支，优化了临时变量作为返回值（相当于直接构造）。 条款21：利用重载（overlaod）避免隐式类型转换（implicit type conversions） 注意，重载运算符时，必须至少有一个是非内置类型。 比如不能定义Complex operator+(int lhs, int rhs);。改变了int加法的本来含义。 条款22：考虑以操作符复合形式（op&#x3D;）取代其独身形式（op） 通常独身形式一般基于符合形式实现，继续维护复合形式。 因此，复合形式具有更高效率。且，返回时，优先选择匿名对象。 条款23：考虑使用其他程序库 如stdio和iostream库的对比 条款24：了解virtual function、multiple inheritance、virtual base classes、runtime type identification的成本 对于多态，大部分编译器使用虚表（virtual tables）和虚表指针（virtual table pointers）实现。 具体实现见《深度探索C++对象模型》（Inside the C++ Object Model byStanley B.Lippman） 技术： Techniques, Idioms, Patterns条款25：将constructor虚化和non-member functions虚化 并非是把constructor声明为virtual，而是使用虚函数来实现virtual constructor的功能。 考虑这样一个场景。Base为消息，Derive有视频消息，文字消息等。使用基类指针来拷贝实际类型，就要根据实际类型来拷贝，即虚函数。 copy constructor class Base&#123; public: virtual Base* clone() const = 0; &#125;; class Derive1: public Base&#123; public: virtual Derive1* clone() const &#123; return new Derive1(*this); &#125; &#125;; class Derive2: public Base&#123; public: virtual Derive2* clone() const &#123; return new Derive2(*this); &#125; &#125;; non-member function class Base&#123; public: virtual ostream&amp; print(ostream&amp; s) const = 0; &#125;; class Derive1: public Base&#123; public: virtual ostream&amp; print(ostream&amp; s) const &#123; s &lt;&lt; &quot;Derived1&quot; &lt;&lt; endl; &#125; &#125;; class Derive2: public Base&#123; public: virtual ostream&amp; print(ostream&amp; s) const &#123; s &lt;&lt; &quot;Derived2&quot; &lt;&lt; endl; &#125; &#125;; inline ostream&amp; operator&lt;&lt;(ostream&amp; s, const Base&amp; o) &#123; return o.print(s); &#125; 条款26：限制某个class所能产生的对象 实现单例模式的一种简单想法是，将构造函数声明为private或 = delete,使用一个static函数（以下称为工厂函数）来创建该类的static对象，用于返回该类对象的引用。 工厂函数不能声明为inline，因为inline会在多处展开，生成多个副本，就破坏了单例。（注，后续已经修复。无需考虑这点问题） 另外一种限制数量的方式是，使用一个计数器。超过即抛出异常。仅仅从自身角度来说，这是可行的。 但要考虑其他两种情况。派生出子类和被其他类包含。这样，也会产生计数器的计数（调用了构造函数），就算他理论上不应该被计数（不是同一类东西）。 因此，需要将构造函数声明为private，结合工厂函数和智能指针管理。 另一种实现方式是，使用一个用于计算对象个数的Base Class，采用private inheritance，即has-a的形式。 条款27：要求（或禁止）对象产生于heap之中 太抽象了，且用法都比较Trick不具有移植性。 条款28：智能指针（Smart Pointers） 测试Smart Pointer是否为nullptr 一种做法是提供一个isNull函数，但为了尽可能模仿原指针的行为，另一种做法是，进行隐式转换。 但转换为其他类型（如bool，void*等）都不能避免不同类型的互相比较问题（由于隐式转换可能会转成相同的类型）。 C++标准库中，隐式转换为void*已经被bool取代，而operator bool总是返回operator!的反相。 源码中与nullptr的比较。 typedef decltype(nullptr) nullptr_t; template&lt;typename _Tp&gt; inline bool operator==(const shared_ptr&lt;_Tp&gt;&amp; __a, nullptr_t) noexcept &#123; return !__a; &#125; template&lt;typename _Tp&gt; inline bool operator==(nullptr_t, const shared_ptr&lt;_Tp&gt;&amp; __a) noexcept &#123; return !__a; &#125; 将Smart Pointer转换为Dumb Pointers 一种形式是，提供隐式类型转换。但容易导致意料之外的转换。 标准库提供get()来返回原指针。 Smart Pointers 和 ”与继承有关的“ 类型转换 指向基类的智能指针和指向子类的智能指针之间没有继承关系，无法隐式转换。 但我们可以使用template来实现。 template&lt;class newType&gt; operator SmartPtr&lt;newType&gt;() &#123; //template function, 用于隐式类型转换操作符。 return SmartPtr&lt;newType&gt; (rawPtr); &#125; 实际上，任何raw1指针可以转换成raw2指针的行为，对应的smart pointer也可以通过转成raw指针再实现转换。 Smart Pointer 与 Const raw指针所指之物可以被const修饰，但智能指针不行。取而代之的是SmartPtr&lt;const Obj&gt;; 如同上面template实现转换，const的转换也可以同理实现。 或者使用继承和C Part of C++中的Union实现。 条款29：Reference counting 实现一个Reference Counting基类，方便子类实现copy-on-write功能。 将计数的操作全部封装在基类之中，子类只需判断是否可以共享即可。 注：RCPtr可使用库Smart Pointer实现。 class RCObject&#123; public: void addReference(); void removeReference(); void makeUnsharable(); bool isShareable(); bool isShared(); protected: RCObject(); RCObject(const RCObject&amp; rhs); RCObject&amp; operator=(const RCObject&amp; rhs); virtual ~RCObject() = 0; private: int refCount; bool shareable; &#125;; class String&#123; public: String(const char *value= &quot;&quot;); const char&amp; operator[](int index) const; char&amp; operator[](int index); private: struct StringValue: public RCObject&#123; char *data; StringValue(const char *initValue); StringValue(const StringValue&amp; rhs); void init(const char *initValue); ~StringValue(); &#125;; shared_ptr&lt;StringValue&gt; value; &#125;; 同理，为了让已经实现好的类在不改变源代码的情况下，实现Reference Counting功能，只需再提供一层封装性。 需要实现一个间接智能指针，智能指针内含一个原生指针，该原生指针指向一个结构体，该结构体继承自RCObject，且内含有目的类的原生指针。 条款30：Proxy classes 使用Proxy可以用于区分operator []的读和写，使得copy-on-write技术更完善。但是，为了让Proxy Class尽可能地像原Class，需要重载大量操作符使得其像原Class（如&amp;，+=，+，-=等）。 同时，由于可能多一层隐式转换，使得原来能够实现的转换，在多一层的情况下，无法进行。 此外，Proxy Class需要承担一定的构造和析构成本。 条款31：让函数根据一个以上的对象类型来决定如何虚化 这条东西很多，主要关于”动态确定多个类型“，给出了一些解决方案。 虚函数+RTTI 只使用虚函数 自行仿真虚函数表 ”继承“ + ”自行仿真的虚函数表格“ 杂谈：Miscellany条款32：在未来时态下发展程序 考虑程序后续的扩展性，如被派生可能导致的问题。 条款33：将非尾端类（non-leaf-classes）设计为抽象类（abstract classes） 此条款里头讨论可能导致的问题，如 子类之间的部分赋值。 不同的子类之间的异型赋值。 挺抽象的，也没给出完美解决方案。 条款34：如何在同一个程序里头结合C++和C C无重载，编译器不会对函数名字进行修改。 但C++有重载，会有name Mangling现象。使用 extern ”c“来避免。 简单守则如下 C++与C的兼容需要编译器产出兼容的目标文件（Object file）； 双方函数都声明为extern ”C“； 如果可能，尽量在C++中撰写main delete和new，free和malloc需要配套。 C++ struct仅在无虚函数的情况下兼容C。 条款35：让自己习惯于C++语言 读者总结：Summary通篇读下来，C++给我的感觉是，一个很硬核的语言，可以自己定制各种功能，事实上，C++也是由各类开发者发展完善的（如Boost社区）。 实现一个具有优良性质的设计，需要很深厚的经验和长远考虑等。","categories":[{"name":"C++","slug":"C","permalink":"https://messenger1th.github.io/categories/C/"}],"tags":[]},{"title":"深入理解C++11","slug":"C++/深入理解C++11","date":"2024-07-24T14:47:33.911Z","updated":"2024-07-24T14:47:33.911Z","comments":true,"path":"2024/07/24/C++/深入理解C++11/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/C++/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3C++11/","excerpt":"","text":"深入理解C++11稳定性和兼容性宏定义 名称 作用 __STDC_HOSTED__ 判断是否拥有完整C库 __func__ 返回函数名称 __cplusplus 指出当前版本，用于版本兼容 构造方面继承构造函数 class Base &#123; public: Base(int val): val(val) &#123;&#125; private: int val; &#125;; class Derived: public Base &#123; public: //just do some function, no extra member value. use inherit constructor. using Base::Base; &#125;; 委托构造中对于异常的处理。看起来可能有点奇怪。 class base &#123; public: base(int i) try : base() &#123; &#125; catch(...) &#123; &#125; private: base() &#123; cout &lt;&lt; &quot;going to throw &quot; &lt;&lt; endl; throw 0; &#125; &#125;; 垃圾回收基本方式有 基于引用计数：reference counting garbage collector 基于追踪处理：tracing garbage collector Mark-Sweep Mark-Compact Mark-Copy 为什么C++支持垃圾回收的道路这么艰难呢？ 主要是因为C&#x2F;C++对于指针的放纵。看这个例子 int main() &#123; int *p = new int; p += 10; //移动到别的地址，即原来的地址就没有被引用了。 p -= 10; //移动回来，但此时可能已经垃圾回收了，这块地址就无效了。 *p = 20; //如果已经被回收，那么这样就是undefined behavior。 return 0; &#125; 类型推导auto推导：推导出类型，但不保留const，volatile，引用等属性。 template推导：推导规则大部分和auto相似。 decltype推导：能够保留const，volatile，引用等属性 特性decltype的妙用推导返回值 变长模板template&lt;typename... Args&gt; void f(Agrs... args) &#123; cout &lt;&lt; sizeof...(args) &lt;&lt; endl; //打印有多少个参数。 func(args...); //将args作为参数调用func。 func(args)... //对每一个参数都调用func。 &#125; 万能引用template&lt;typename T&gt; void f(T&amp;&amp; t); 完美转发在万能引用中的使用。template&lt;typename T&gt; void f(T&amp;&amp; t) &#123; func(std::forward&lt;T&gt;(t)）; //保留t原有类型，转发给对应函数。 &#125; 变长模板与万能引用template&lt;typename... Args&gt; void f(Agrs&amp;&amp;... args) &#123; &#125; 变长模板的完美转发template&lt;typename T&gt; void f(Args&amp;&amp;... args) &#123; func(std::forward&lt;Args&gt;(args)...）; //多参数也能进行完美转发。 &#125; 其他APIis_same&lt;&gt;::value; is_const&lt;&gt;::value; is_volatile&lt;&gt;::value； is_lvalue_reference&lt;&gt;::value; //判断是否左值引用 is_rvalue_reference&lt;&gt;::value; //判断是否右值引用","categories":[{"name":"C++","slug":"C","permalink":"https://messenger1th.github.io/categories/C/"}],"tags":[]},{"title":"C++ Primer","slug":"C++/C++ Primer","date":"2024-07-24T14:47:33.910Z","updated":"2024-07-24T14:47:33.910Z","comments":true,"path":"2024/07/24/C++/C++ Primer/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/C++/C++%20Primer/","excerpt":"","text":"C++ Primer第二章: Variable 头文件不应包含using声明，因为头文件会被copy到所有引用其的文件中。 decltype(expresssion) 类型推导 如果expression含括号，则一定是引用类型。 int i = 0; int&amp; j = i; decltype(i) a = 0; //int decltype(j) b = i; //b是引用 decltype((i)) c = a; //c是引用类型 第三章：String Vector ArrayString 列表初始化和拷贝初始化、直接初始化的区别 string::size_type和size_t有助于代码的可移植性。 根据不同平台，编译成不同大小。 Vector vector对象能高速增长，除了所有元素都一样的情况，没必要定义时指定容量。 Array 定义（有括号优先括号，其次右向左读） int *ptrs[10]; //是一个数组， 里头10个指针 int &amp;refs[10] = ; // 错误，不存在引用数组 int (*Parray)[10] = &amp;arr; // 指针，指向一个数组，数组包含10个元素 int (&amp;arrRef)[10] = arr; //引用，引用一个数组，数组包含10个元素 int *(&amp;array)[10] = ptrs //引用，引用一个数组，数组包含10个元素，数组元素是指针。 编译器编译,auto,为指针，decltype()为原类型。 int arr[] = &#123;0,1,2,3&#125;; auto arr2(arr); //指针 decltype(arr) arr3() = &#123;0,1,2,3&#125;; //int型数组 指针也是迭代器，可获取尾后迭代器遍历数组。但建议使用begin()和end()获取迭代器。 int arr[] = &#123;0,1,2,3,4&#125;; int *first = begin(arr); int *last = &amp;arr[5] //不建议 int *last = end(arr); //建议 指针相减得到数据类型ptrdiff_t, 为有符号类型 静态多维数组需要使用引用。 int arr[][2] = &#123;0,1,2,3&#125;; for (auto&amp; row: arr) &#123; //如果不是引用，编译器认为是 int*, col无法遍历。 for (auto col: row) &#123; cout &lt;&lt; col &lt;&lt;endl; &#125; &#125; 第四章：Expression 左值和右值 int a = 0; int *p = &amp;a; decltype(*p) //*p, 解引用。为int&amp; decltype(&amp;p) //&amp;p取地址为右值。为int** 求值顺序（CPP没有明确规定求值顺序，方便编译器优化） int i = f1() * f2(); //不确定先算f2还是f1，未定义行为。 //确定求值顺序运算符有四个：&amp;&amp; || , ? : 位运算符 int a = 1111; a &amp;= ~(a &lt;&lt; 1); sizeof int *p; sizeof (*p); //没错，实际不对p解引用。返回p指向的大小。在这为int类型大小 sizeof (p); //返回p指针本身大小 int arr[10] = &#123;1,2,3&#125;; sizeof arr; //返回10，数组所占大小。 string s&#123;&quot;Hello&quot;&#125;; sizeof s; // 返回其固有所占空间大小，不随s长度改变。vector同理 类型转换 隐式转换 显示转换static_cast&lt;&gt;()、const_cast&lt;&gt;()、dynamic_cast&lt;&gt;()、reinterrpret_cast&lt;&gt;() float a = 1.0; double res = static_cast&lt;double&gt;(a); // const char *pc; char *p = const_cast&lt;char*&gt; (pc)//去除底层const，但是通过p写值是未定义的行为。 第六章：Function initializer_list&lt;&gt;初始化列表 initializer_list&lt;int&gt; lst&#123;1,2,3,4&#125;; vector&lt;int&gt; vec(lst);//&#123;&#125;实际上是一个初始化列表。 //作为函数返回值，用于初始化被调用处的变量。 vector&lt;int&gt; fun1() &#123; return &#123;1,2,3,4&#125;;//实际上是一个初始化列表。 &#125; 返回数组指针 //方法1 int (*func(int i))[10]; //逐层理解 func(int i); //函数需要一个int参数 (*func(int i)); //函数返回值可以解引用 (*func(int i))[10]; //函数解引用得到一个大小为10的数组 int (*func(int i))[10]; //数组中的元素大小为10; //方法2：使用尾置返回类型 auto func(int i) -&gt; int (*)[10]; 调试帮助 #define NDEBUG //在源文件的第一句写,用于取消以下模式 //方法一 assert(expr); //expr为0则输出信息并终止程序. //方法二 #ifndef NDEBUG some opreation #endif 函数指针 bool (*pf)(const string&amp; a, const string&amp; b); //(*pf)代表是一个指针,右边的参数列表表示指向一个函数. 函数指针形参 void useBigger(bool (*pf)(const string&amp; a, const string&amp; b)); useBigger(func)//调用时直接传函数名即可. decltype(func) * funcPtr; //通过decltype得到函数类型,加上*变成函数指针. //可以如下重新声明useBigger函数 void useBigger(funcPtr); 返回指向函数的指针 //使用别名 using F = int(int*, int); //F是函数类型,不是指针. using PF = int(*)(int*, int); //PF是函数指针 PF f1 (int); F *f2(int); //F 是一个函数,加上*变成函数指针. //直接声明 int (*f1(int))(int*, int); //尾置返回 auto f3(int) -&gt; int (*)(int*, int); 第七章：Class 对于公共代码使用私有功能函数 避免在多处使用同样的代码 随着规模发展, 函数的功能可能变得更复杂, 修改时只需修改一处即可. 可能在开发时有调试信息, 发行版去除函数处的即可. 不带来额外开销, 类的函数定义在内部会隐式声明成inline类型. 函数的参数列表可以告诉编译器目前处于哪个作用域 void Window_mgr:: addScreen(const Screen &amp;s) &#123;&#125; // 但是返回值在这个作用域参数之前,因此需要指明. Window_mgr::ScreenIndex Window_mgr::addScreen(cosnt Screen &amp;s) &#123;return ...&#125; 编译器处理完所有声明才会处理成员函数的定义. 对于成员函数中的使用的名字, 可以使用类中所有的成员变量. 但对于声明, 返回值, 参数列表中使用的名字, 都必须保证使用前可见. typedef double Money; string bar; class Account&#123; public: //返回值类型是double, bar是下方的bar1.0, 而非上方的string. Money balance() &#123;return bar&#125;; private: Money bar = 1.0; &#125;; 成员初始化的顺序 实际顺序与其定义的顺序一致. 编码顺序可以不一致, 需要考虑如下问题 class X&#123; int i; int j; X(int val): j(val), x(j) &#123;&#125; //未定义行为, 因为实际顺序中, i先被初始化. &#125;; 委托构造（构造函数调用其他构造函数） class SaleData&#123; string id; double price; SaleData(string id, double price): id(id), price(price) &#123;&#125; SaleData(): SaleData(0, 0) &#123;&#125; saleData(string id): SaleData(id, 0) &#123;&#125; &#125;; 默认构造函数 SaleData obj(); //函数声明 SaleData obj; //对象声明, 调用默认构造函数. 转换构造函数 例子 string null_book = &quot;9-999-9999-9&quot;; //此处存在一次隐式转换 即const char *到string SaleData temp = null_book; SaleData temp = &quot;9-999-9999-9&quot;;// 不行, 只支持一步转换. explicit关键字 阻止隐式转换 聚合类 符合如下条件 所有成员都是public的 没有定义任何构造函数 没有类内初始值 没有基类, 也没有virtual函数 如 class Data &#123; public: int val; string s; &#125;; 可以如下初始化 Data data1 = &#123;0, &quot;Anna&quot;&#125;; //赋值顺序与定义顺序一致 字面值常量类(成员都是字面值的聚合类或者符合以下条件) 数据成员必须是字面值类型 类至少含有一个constexpr构造函数 类内初始值为常量表达式, 或者初始值使用自己的constexpr构造函数初始化. 析构函数必须默认 类的静态成员 定义在任何函数之外, 定义后存在于整个程序的生命周期. 建议把静态数据成员的定义与其他非inline函数的定义在同一个文件中. 一般来说,不应该在类内初始化, 但可以提供为const静态成员提供类内初始值(必须是字面值或constexpr) class Data &#123; public: constexpr static int cnt = 30; // 正确 static int count = 30; //报错, 非const的static变量的定义和初始化必须分开. &#125;; //正确 class Data &#123; public: static int count; //类内定义 &#125;; int Data::count = 30; //类外初始化 即使一个常量静态数据成员在类内部被初始化, 通常情况下也应该在类外定义一下. class Data &#123; public: constexpr static int cnt = 30; &#125;; constexpr int Data::cnt; 静态数据成员类型可以是不完全类型. 可以作为默认实参 class Screen &#123; public: Screen&amp; clear(char = bkground); private: static const char bkground; &#125;; mutable可以突破函数const的限制, 任何时候都可改; 第八章: IO Library 宽字符版本输入输出流 wcin, wcout,wcerr,与原版本在同一个头文件. 流状态管理 管理输出缓冲: 如果程序崩溃,输出缓冲区不会被刷新 cout &lt;&lt; unitbuf; //设置模式:任何输出都会立即刷新缓冲区 cout &lt;&lt; nounitbuf //恢复默认 关联输入和输出流 关联后, 任何输入流读取操作都会先刷新关联的输出流. cin &gt;&gt; ival; //标准库将cout和cin关联, 因此这会使得cout刷新. cin.tie(&amp;cerr); // 关联cerr流. 文件输入输出流 open和close, 文件流对象被销毁时.自动调用close string流 :istringstream, ostringstream 第九章: Sequential Container 顺序容器类型 vector; deque; list; //双向链表 forward_list; //单向链表 array; string; capacity和size capacity表示当前分配的空间最大容纳元素个数 size是当前容器存储元素个数. vector&lt;int&gt; vec; vec.reverse(n); //指定vec分配n个元素的内存空间. 此时capacity = n; 第十章: Generic Algorithm 只要元素支持相关操作,例如+, ==即可调用泛型算法. string sum = accumulate(v.cbegin(), v.end(), string(&quot;&quot;)); //支持+即可 equal(v.cbegin(). v.end(), v2.cbegin()); //支持==即可 算法不检查写操作 finll_n(vec.begin(), 10, 0); //若vec大小小于10, 则此操作未定义. lambda [capture list] (parameter list) -&gt; returnType &#123; function body &#125; //capture list只用于局部非static变量, lambda可以直接使用局部static变量和在它所在函数之外声明的名字 值捕获和引用捕获 int a = 42; //显式捕获 auto f = [a] &#123; return a;&#125; //value auto f2 = [&amp;a] &#123; return a;&#125; //reference //隐式捕获 auto f = [=] &#123; return a;&#125; //value auto f2 = [&amp;] &#123; return a;&#125;// reference //capture list [] [name1, names2...] [&amp;] [=] [&amp;, identifier_list] [=, identifier_lsit] bind 使用bind取代lambda 插入迭代器 back_inserter; front_inserter; inserter; 算法命名规范 find(beg, end); find(beg, end, comp); //参数都是三个,避免重载歧义, 提供不同名字版本 find_if(beg, end, pred); //拷贝和不拷贝 reverse(beg, end); reverse_copy(beg, end, dest); remove_if(beg, end, [] (int i) &#123;return i % 2 == 0;&#125;); remove_copy_if(beg, end, v2.beg(), [](int i) &#123;return i % 2 ==0;&#125; ); 特定容器算法 对于list和forward_list优先使用成员算法. sort; merge; remove; reverse; unique; 链表的特有操作会改变容器 第十一章: Associative Container 8种 map; set; multimap; multiset; unordered_map; unordered_set; unordered_multimap; unoreered_multiset; 有序容器的元素需要提供&lt;运算, 无序容器需要提供hash function和== class Sale_data&#123; public: string isbn; &#125;; size_t hashFunc(const Sale_data &amp;t) &#123; return hash&lt;string&gt; () (t.isbn); &#125; bool eqOp(const Sale_data &amp;t1, const Sale_data &amp;t2) &#123; return hashFunc(t1) == hashFunc(t2); &#125; int main() &#123; unordered_set&lt;Sale_data, decltype(hashFunc)*, decltype(eqOp)*&gt; test; cout &lt;&lt; test.size() &lt;&lt; endl; return 0; &#125; 无序容器桶管理 第十二章: Dynamic Memory 动态内存与智能指针 shared_ptr; unique_ptr; shared_ptr&lt;int&gt; p = make_shared&lt;int&gt;(42); auto p1 = make_shared&lt;int&gt;(42); //分配动态内存与删除 int *p = new int[10]; delete [] p; //数组要加[] 使用动态内存的原因是允许多个对象共享相同的状态. 相关shared_ptr的定义和修改 shared_ptr&lt;T&gt; p(q); //q是new出来的内存, 且能转成T* shared_ptr&lt;T&gt; p(u); //u是unique_ptr, 从u处接管对象所有权. u置空. shared_ptr&lt;T&gt; p(q, d); //q是内置指针,p接管其内存, 同时用d来代替delete来释放内存. shared_ptr&lt;T&gt; p(p2, d);//接管shared_ptr p2, 并用d释放内存. p.reset(); p.reset(q); p.reset(q, d); 传递删除器 unique_ptr&lt;objT, decT*&gt; p (new ObjT, fcn); weark_ptr 智能指针与动态数组 unique_ptr&lt;int[]&gt; up(new int[10]); up.release();//自动调用delete[]销毁其指针 //shared_ptr 与 unique_ptr不同, 不支持管理动态数组, 需要自定义删除器. shared_ptr&lt;int&gt; sp(new int[10], [](int *p) &#123;delete[] p&#125;); allocator 分配未构造的内存, 将内存分配与对象构造分隔开. 分配与回收, 构造与析构 拷贝和填充分配但未构造的内存 第十三章: Copy Control 拷贝构造函数和拷贝赋值运算符 class Foo &#123; public: Foo() &#123;&#125; Foo(const Foo&amp; o) &#123;&#125; //拷贝构造函数, 形参必须是引用, 不然会无限拷贝 Foo&amp; operator=(const Foo&amp; o) &#123;&#125;//拷贝赋值 //或默认生成, synthesized copy constructor //或显示赋值default, 如下 Foo() = default; Foo(const Foo&amp;) = default; Foo&amp; operator=(const Foo&amp; o); //在类外 ~Foo() = default; //或删除 Foo() = default; Foo(const Foo&amp;) = delete; Foo&amp; operator=(const Foo&amp; o) = delete; ~Foo() = default; &#125;; Foo&amp; Foo::operator=(const Foo&amp; o) = default; //防止inline. 需要析构函数的类也需要拷贝和赋值操作（显式生成拷贝构造函数、重载&#x3D;运算符）,需要拷贝的类也需要赋值操作，反之亦然。 类值拷贝赋值运算符 //需要注意当左右两侧是同一个对象时, 保证正确性和异常安全. HasPtr&amp; HasPtr::operator=(const HasPtr&amp; rhs) &#123; delete ps; // 释放ps指向的动态内存 //如果rhs和*this是同一对象, 行为未定义 ps = new string (*(rhs.ps)); return *this; &#125; //copy and swap HasPtr::operator=(const HasPtr rhs) &#123; swap(*this, rhs); return *this; &#125; 自定义swap函数而非std::swap交换指针, 防止冗余拷贝. 右值引用 &amp;&amp; 对象移动 容器保存的类不必可以拷贝, 但一定要可以移动. 移动构造函数(需要dynamic memory除外, 可能分配失败)通常不会抛出异常, 需要声明成noexcept, 原因如下: public: StrVec(StrVec&amp;&amp;) noexcept &#123;&#125; &#125;;// 类头文件声明, 和定义都指定noexcept StrVec::StrVec(StrVec &amp;&amp;o) noexcept: &#123;...&#125;; 原因: 移动构造时, 在当前对象已经移动部分, 但未完全移动时发生异常, 容器就会发生改变.因此 容器就不会选用会抛出异常的移动构造函数, 而选用拷贝构造, 因为拷贝构造构造发生异常时, 旧元素仍然存在, 仅需释放新元素内存即可保持容器不变. 移动赋值运算符 类似拷贝赋值, 需要确保自己给自己赋值的正确性. 五个拷贝控制成员应该看成一个整体. 构造析构移动: 赋值, 拷贝: 第十四章: Overload Operator &amp; Type Conversion function类型 可通过函数, 函数指针 ,lambda, 函数对象构造. 类型转换运算符 class SmallInt&#123; public: SmallInt(int i = 0): val() &#123;&#125; operator int() const &#123;&#125; //转换成int, 通常设置成const private: int val; &#125;; 不要设计两个可以转换的类, 一个转换构造一个定义类型转换运算符 不要定义多种内置算术类型的类型转换. 转换构造和类型转换可能产生二义性，因此推荐转换构造 第十五章: Object Oriented Programming virtual 动态绑定 final 防止被该类继承 多态: polymorphism 纯虚函数pure virtual, 有该类函数的类称为抽象基类abstract base class, 无法被直接定义. class Disc_quete: public Quote &#123; public: Disc_quote() = default; double net_price(std::size_t) const = 0; //纯虚函数只需声明, = 0即可 &#125; 派生类的成员或友元只能通过派生类对象来访问基类的受保护成员. 基类对象不行. class Base &#123; protected: int prot_mem; &#125; class Sneaky : public Base &#123; friend void clobber (Sneaky&amp;); //能访问 friend void clobber (Base&amp;);//不能通过基类对象访问 &#125;; 继承方式:public,proteced&amp;private; 不影响基类的访问权限. 仅仅控制派生类对象对基类的访问. 通过using改变个别成员的可访问性. 前提是该成员可在派生类内访问. class Derived: private Base &#123; public: using base::var;//改变base基类的var变量访问权限为public &#125; friend不能继承给派生类 名字查找先于类型检查, 因此内层作用域的函数会隐藏外层的函数, 即使他们参数列表不一致, 因此虚函数一定要有相同的参数列表. 内层同名函数会隐藏所有外层同名函数(可能是重载函数,因此可能有多个),可通过基类::访问. 虚析构函数 一个基类总是需要虚析构函数 会阻止合成移动操作.因此使用移动操作时, 实际使用的是拷贝操作. 移动操作与继承 基类操作 class Base&#123; public: virtual ~Base() = default; //基类通常需要定义虚析构函数 //定义析构函数后, 不会默认合成移动操作. 需要显式定义,如下. Base() = default; Base(const Base&amp; t) = default; Base(Base&amp;&amp; t) = default; Base&amp; operator=(const Base&amp; t) = default; Base&amp; operator=(Base&amp;&amp; t) = default; &#125;; 派生类操作 class D: public: Base &#123; public: //D(const D&amp; t) = default; //=default会使用默认初始化, 与我们的期望相违背. D(const D&amp; t) = default; D(D&amp;&amp; t) noexcept : Base(std::move(t)) &#123;&#125;; D&amp; operator=(const D&amp; t); D&amp; operator=(const D&amp;&amp; t); &#125; //拷贝和赋值 D&amp; D::operator=(const D&amp; t) &#123; Base::operator=(t); //... return *this; &#125; D&amp; D::operator=(D&amp;&amp; t) &#123; Base::operator=std::move(t); //... return *this; &#125; “继承”构造函数, 继承除了 默认, 拷贝, 移动构造函数 派生类中与基类参数列表相同的构造函数. class D: public Base &#123; public: //复制基类的构造函数到派生类, 派生类的成员执行默认初始化. //且不影响派生类默认构造函数的生成. using Base::Base; //之前的using声明改变了访问权限, 此处不改变, 编译器仅生成代码. &#125;; 容器与继承 在容器中放置(智能)指针而非对象. 模拟虚拷贝: new Base(obj) obj可能是派生类, 因此可能会仅拷贝Base的部分 virtual Base* clone() const &amp; &#123; return new Quote(*this); &#125; virtual Base* clone() &amp;&amp; &#123; return new Quote(std::move(*this)) &#125;","categories":[{"name":"C++","slug":"C","permalink":"https://messenger1th.github.io/categories/C/"}],"tags":[]},{"title":"Effective C++","slug":"C++/Effective C++","date":"2024-07-24T14:47:33.910Z","updated":"2024-07-24T14:47:33.910Z","comments":true,"path":"2024/07/24/C++/Effective C++/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/C++/Effective%20C++/","excerpt":"","text":"Effective C++熟悉C++ Accustoming Yourself to C++条款1：View C++ as a federation of languages. C Objected-Oriented C++ Template C++ STL 根据要使用的C++部分，来遵守相应的高效编程守则。 条款2：Prefer consts， enums, and inlines to #defines. #define是预处理命令，编译器看不它的存在。 对于常量， 最好用const对象或者enums替换#define 对于形似函数的宏，改用inline函数。 条款3：Use const whenever possible char greeting[] = &quot;Hello&quot;; char* p1 = greeting; //non-const pointer, non-const data const char* p2 = greeting;//non-const pointer, const data char* const p3 = greeting;//const pointer, non-const data const char* const p4 = greeting; //const pointer, const data 必要时，使用mutable修饰变量，使其不受const限制。 条款4：Make sure that objects are initialized before they’re used. 区分assignment和initialization，并推荐使用列表初始化。 为了避免跨单元之初始化次序的问题，请使用local static对象替换non-local 构造&#x2F;析构&#x2F;赋值运算 Constructor，Destructor，and Assignment Operators条款5：Know what functions C++ silently writes and calls. 编译器可以默认创建default constructor,copy constructor,copy assignment,destrutor 除了含有const或者是声明为private的父类函数需要被调用时. 条款6：Explicitly disallow the use of complier-generated functions you do not want. 为了防止编译器自动生成上述函数，可以将成员函数声明为private并不予实现。 条款7：Declare destructors virtual in polymorphic base classes. 让声明virtual析构函数被动态绑定，防止子类资源没有释放。 条款8：Prevent exceptions from leaving destructors. 以防止 未定义的行为 程序过早地结束 条款9： Never call virtual functions during construction or destruction. 在构造期间， virtual函数不是virtual函数。 因为基类构造时，意味着子类还未初始化， 如果调用的是子类virtual版本，则会导致未定义的行为。 析构函数同理。 如果要实现virtual函数的功能，可在构造时，由子类向父类传递信息。 *条款10：Have assignment operators return a reference to this. 如 operator&#x3D;，+&#x3D;, &#x2F;&#x3D;, *&#x3D;&#x2F;, -&#x3D;。 int x, y, z; x = y = z = 15; 为了实现连锁复制。 条款11：Handle assignment to self in operator&#x3D;. 考虑异常安全和自我赋值安全（释放资源前保证以后不再使用，如释放自己再使用自己的资源）； 使用copy and swap计数。 条款12：Copy all parts of an object Copying函数应该确保复制“对象内的所有成员变量”以及“所有base class”成分。 不要尝试以某个copying函数实现另一个copying函数。应该将共同部分放在第三个函数， 并由Copying函数调用。 资源管理 Resource Management条款13：Use objects to manage resources. 为了防止资源泄露，请使用RAII对象。构造时获取资源，析构时自动释放资源。 两个常用的RAII是tr1::shared_ptr和auto_ptr。auto_ptr复制动作会使原对象指向null；注：**unique_ptr已经取代auto_ptr** 条款14：Think carefully about copying behavior in resource-managing classes. 复制RAII对象必须一并复制它所管理的资源，其copying行为由资源的copying行为决定。 常见RAII class copying 行为是：抑制copying、使用reference counting 条款15：Provide access to raw resource-managing classes. APIs往往要求访问raw resource，所以RAII需要提供接口。 对row resource的访问可能仅由显示转换或隐式转换。 条款16：Use the same form in corresponding uses of new and delete. 如new int[] 对应delete[] 条款17：Store newed objects in smart pointers in standalone statements. 为了防止资源new之后，还未放入RAII的时间内， 由于其他函数的异常导致的资源泄露 请将资源new和放入RAII的操作放在独立语句中。 设计与声明 Design and Declaration条款18：Make interfaces easy to use correctly and hard to use incorrectly 使用已经成熟类封装数据，如Month,Day,Year类来封装日期。 一旦类型的值是确定的，就可以限制其取值。如一年12个月，使用预定义的12个static函数返回对象。 限制类型内可做的事情。如a * b = c，让a * b返回一个const. 保持接口一致性，如命名规范，大小统一命名为size. 预判使用者的行为导致的一些错误。如使用者忘记释放资源。可以先发制人，直接返回一个smart pointer 综上，“促进正确使用”：接口一致性，与内置类型兼容。“阻止误用”：建立新类型限制类型上的操作，限制对象的取值，消除客户的资源管理责任。 tr1:shared_ptr支持定制删除器custom deleter。可以防范DLL问题，可被用来自动解除互斥锁。 条款19：Treat class design as type design 如何被构造和析构，涉及到资源分配和资源释放的设计。 初始化和赋值行为有什么区别。 对象如果被passed by value意味着什么？ copy构造函数用于定义一个type的pass by value该如何实现？ 考虑合法值的取值。并限制非法值。 是否需要配合继承体系？ 需要什么样的类型转换？ 什么样的操作符和函数对此type是合理的？ 什么样的标准函数应该被驳回？那些必须声明为private 哪个成员是public,protected,private,friend. 什么是新type的未声明接口？ 是否要定义为class template 真的需要一个新type吗， 还是只是新的derived class? 条款20： Prefer pass-by-reference-to-const to pass-by-value 无需拷贝，更为高效，且可以避免切割问题（子类传递后拷贝为父类）。 但内置类型以及STL的迭代器和函数对象，通常使用 pass-by-value更为高效。 条款21：Don’t try to return a reference when you must return an object 绝不要返回pointer或reference指向一个local stack对象。 考虑返回reference指向一个heap-allocated对象. 考虑拷贝返回。 条款22：Declare data members private 尽可能将成员变量声明为private. protected并不比public更有封装性。 条款23：Prefer non-member non-friend function to member functions 条款24：Declare not-member functions when type conversions should apply to all parameters. Rational oneHalf(1, 2); Rational result = 2 * oneHalf; Rational result = oneHalf * 2; 重载operator*并让隐式转换成两个Rational对象相乘。对接上一个non-member function. 条款25：Consider support for a non-throwing swap 当std::swap对你的类型效率不高时，提供一个swap成员函数，并确定它不抛出异常。 如果你提供一个member swap，也该提供一个non-member swap来调用前者 调用swap应该针对std::swap使用using声明式，然后调用swap并且不带任何“命名空间修饰”。 为“用户自定义类型”进行std templates全特化是好的，但不要在std内加入。 实现 Implement条款26：Postpone variable definitions as long as possible 可以的话，直接初始化。而不是默认初始后再赋值。 考虑循环里头直接构造，还是在外头构造，循环内赋值的成本。 条款27：Minimize casting const_cast&lt;T&gt;(expression) 移除const。 dynamic_cast&lt;T&gt;(expression) reinterpret_cast&lt;T&gt;(expression) static_cast&lt;T&gt;(expression) 强迫转型，如int转成double。pointer-to-base转成pointer-to-derived. 条款28：Avoid returning “handles” to object internals. 可能会降低封装性。 可能会导致使用已经释放的资源。 条款29：Strive for exception-safe code 基本保证：不发生资源泄露和数据败坏。 强烈保证：要么执行成功，要么直接回滚到不执行的状态。 不抛出保证。 条款30：Understand the ins and outs of inlining inline函数在编译器直接将函数本体到替换到调用处。 因此，对于非inline函数来说，修改后重新编译链接这一个文件即可。而inline函数是需要重新编译所有调用文件的。 构造函数和析构函数含有不少代码，不建议inline 条款31：Minimize compilation dependencies between files 支持”minimize compilation dependencies “的一般构想是：相依与声明式，不要相依与定义式。 程序库头文件应该以”完全且仅有声明式子“（full and declaration-only forms）的形式存在。这种做法不论是否涉及templates都适用。 继承与面向对象设计 Inheritance and Object-Oriented Design条款32：Make sure public inheritance models “is-a” “public继承”意味着is-a; 条款33：Avoid hiding inherited names. derived classes内的名词会掩盖base classes的名称，即名字查找先于类型检查。 要用到被掩盖的名称，可以使用 using声明（全部显形）或者转交函数（forwarding function）（指定显形）。 条款34：Differentiate between inheritance of interface and inheritance of implementation pure virtual函数在基类可以有定义，但子类仍需要重写，必要时可以显示调用基类的定义。 条款35：Consider alternatives to virtual functions NVI: non-virtual interface 基类中实现一个函数，调用相应virtual。 Strategy 使用可调用的方式来替代virtual函数如 使用函数指针（但只能访问类中public的内容），或使用tr1:function调用（可调用物：可以是某个函数，函数对象，成员函数）。 条款36：Nevenr redefine an inherited non-virtual function 如果override一个 non-virtual function， 使用基类的指针或引用指向子类时候，调用的是基类（即声明类型）的版本（静态绑定）。 从 is-a的角度，基类的 non-virtual function应该具有不变性。不可被改变。 条款37：Never redefine a functions’ inherited default parameter value 默认参数在编译期已经确定，是静态的。 由于 default parameter value是静态的，取决于声明类型，而virtual function则是动态的，重定义默认参数会导致使用动态的function却使用了声明类型的默认参数。 解决办法是 条款35中的替代virtual的方案。 条款38： Model “has-a” or “is-implemented-in-terms-of” through composition has-a 如一个人有名字，身份证号码，这些是 has-a的关系。 is-implemented-in-terms-of 如一个set可以由list来实现。 条款39：Use private inheritance judiciously private inheritance意味着 is-implemented-in-terms-of 。它通常比 composition的级别低。但是当 derived class需要访问 protected base class的成员，或重新定义 virtual函数的时候，这样做是合理的。 较于 composition，private继承可以使得 empty base最优化，占用更少空间。 条款40：Use multiple inheritance judiciously 多重继承比单一继承复杂。可能导致新的歧义性，以及对virtual继承的需要。 virtual继承会增加大小、速度、初始化（及赋值）复杂度等等成本。如果virtual base classes不带任何数据，将是最具有使用价值的情况。 多重继承的确有正当用途。如“涉及public继承某个interface class”和“private继承某个协助实现的class” 模板与泛型编程 Template and Generic Programming条款41：Understand implicit interfaces and compile-time polymorphism classes 和 templates 都支持接口（interface）和多态（polymorphism）。 对classes而言接口是显式的（explicit），以函数签名为中心。而多态则是通过 virtual 函数发生与运行期。 对template参数而言，接口是隐式的（implicit），基于有效表达式。多态则是通过template具现化和函数重载解析发生于编译期。 条款42：Understand the two meanings of typename 声明template参数时，前缀关键字class和typename可互换。 请用typename标识嵌套从属类型（如typename std::interator...）。但不得在基类列表或者成员初值列内作为 base class修饰符。 条款43：Know how to access names in templatized base classes 由于 template class可能被特例化而缺少共同函数，因此 derived template class会默认不寻找基类的函数。 解决办法3种： 使用this-&gt;修饰该函数。 使用using告诉编译器去基类寻找。 使用::明确寻找哪个函数。 条款44： Factor parameter-independent code out of templates 这块我的代码量不够，没咋看懂。 条款45：Use member function templates to accept all compatible types 请使用 member function templates生成“可接受所有兼容类型”的函数。 如果你声明 member templates用于“泛化copy构造”或“泛化assignment”。你还需要声明 non-template版本，否则编译器会帮你生成。 条款46：Define non-member functions inside templates when type conversions are desired template实参推导从不将隐式类型转换考虑在内。如条款24的例子在template的情况下行不通。 friend的其他用法。 条款47：Use traits classes for information about types Trait classes 使得“类型相关信息”在编译器可用。它们以 templates 和 ”template特化“实现。 overloading使得 ， trains classes可能在编译期对类型执行 if…else测试。 条款48： Be aware of template metaprogramming Template metaprogramming(TMP 模板元编程)可将工作由运行期移往编译期。得以实现早期错我侦测和更高的执行效率。 TMP可被用来生成”基于政策选择组合“（based on combinations of policy choices)的客户定制代码，也可用于避免生成对某些特殊类型并不适合的代码。 定制new和delete条款49：Understand the behavior of the new-handler 条款50：Understand when it makes sense to replace new and delete 有许多理由需要写一个自定的new和delete，包括改善效能、对heap运用错误进行调试、收集heap使用信息。 条款51：Adhere to conversion when writing new and delete operator new应该内含一个无穷循环，并在其中尝试分配内存。如果无法满足内存需求，就该调用 new-handler。它也应该有能力处理0 bytes申请。Classes专属版本则还应该处理”比正确大小更大的（错误）申请“。 operator delete应该在收到null指针时不做任何事。Classes专属版本则还应该处理”比正确大小更大的（错误）申请“。 条款52：Write placement delete if you write placement new 写了placement operator new，要写对应版本的delete。 当你写了placement new 和 placement delete，请确定不要无意识地遮掩他们正常的版本。 杂谈：Miscellany条款53：Pay attention to compiler warnings. 条款54：Familiar yourself with the standard library，including TR1 条款55：Familiarize yourself with Boost Boost 读者总结前面几部分是容易接受的，直到模板这里头涉及文件的依赖性、元编程。以及new和delete部分。 模板这块代码量不够，不能彻底理解。new和delete也是。","categories":[{"name":"C++","slug":"C","permalink":"https://messenger1th.github.io/categories/C/"}],"tags":[]},{"title":"Effective Modern C++","slug":"C++/Effective Modern C++","date":"2024-07-24T14:47:33.910Z","updated":"2024-07-24T14:47:33.911Z","comments":true,"path":"2024/07/24/C++/Effective Modern C++/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/C++/Effective%20Modern%20C++/","excerpt":"","text":"Effective Modern C++第一章：类别推导条款1：理解模板类型推导 函数声明。 template&lt;typename T&gt; void f(ParamType param); 函数调用 void f(expr); 情况1：ParamType含引用或指针。 template&lt;typename T&gt; void f([const] T&amp; param); template&lt;typename T&gt; void f([const] T* param); 模板推导出来也一定是指针或者引用。 不含const模板可以推导出含const的expr调用。 template&lt;typename T&gt; void f(T* val) &#123; printf(&quot;void f(T* %d)\\n&quot;, *val); &#125; int main() &#123; int* a = new int(1); f(a); const int* b = new int(2); f(b); &#125; /* result void f(T* 1) void f(T* 2) */ 但注意，如果函数违法了const，会报错。 template&lt;typename T&gt; void f(T* val) &#123; *val = 10; //Read-only variable is not assignable printf(&quot;void f(T* %d)\\n&quot;, *val); &#125; int main() &#123; const int* b = new int(2); f(b); &#125; 情况2: ParamType是个万能引用。 template&lt;typename T&gt; void f(T&amp;&amp; param); 如果expr为 左值，则参数类型最终为[const] T&amp;。 右值，则参数类型最终为[const] T&amp;&amp;。 即，万能引用能够推导是左值还是右值。 const的推到类似情况一，根据expr是否有const决定。 情况3: 按值传递 template&lt;typename T&gt; void f(T param); 通过copy constructor构造处理 由于是副本，因此该expr本身的 const 引用 volatile 都会被忽略（对它的副本改变并不破坏它本身的const）。 值得一提的是，仅仅会移除形参本身的const。 const char* const ptr = &quot;Fun with pointers&quot;; f(ptr); //推到类型为 const char* 即，函数参数是一个const char*，是ptr的副本。 数组实参 类似C中语法，数组会退化成首元素指针。 const char arr[] = &quot;array&quot;; template&lt;typename T&gt; void f(T Param) f(arr); arr是个数组，会被推导成指针。 但如果是引用，则正常推导。 template&lt;typename T&gt; void f(T&amp; Param) f(arr); //推导成 const char (&amp;)[size] 类型，其中size是arr的大小 + 1 (\\0)。 获取数组大小。 template&lt;typename T, std::size_t N&gt; constexpr std::size_t arraySize(T (&amp;)[N]) &#123; retur N; &#125; 函数实参 除了数组退化成指针，函数和数组处理相同。 void someFunc(int, double); template&lt;typename T&gt; void f1(T param); template&lt;typename T&gt; void f2(T&amp; param); f1(someFunc); //函数指针 void (*)(int, double); f2(someFunc); //函数引用 void (&amp;)(int, double); 条款2：理解auto类别推导 总的来说，auto推导和模板推导是一个原理。 仅有一处例外：auto能够推导出initializer_list,而模板不能。 auto x = &#123;1, 2, 3&#125;; //x type : initializer_list template&lt;typename T&gt; void f(T param); f(&#123;1, 2 ,3&#125;); // error can&#x27;t detect. 不过，模板可以推导initializer_list&lt;T&gt; T 的类型。 template&lt;typename T&gt; void f(std::initializer_list&lt;T&gt; initList); f(&#123;1, 2, 3&#125;); 但在如下情况，auto也不能推导。 函数返回值。 auto createInitList() &#123; return &#123;1, 2, 3, 4&#125;; //error &#125; lambda函数形参 auto resetV = [&amp;v](const auto&amp; newValue) &#123; v = newValue; &#125;; resetV(&#123;1, 2, 3&#125;); //error 条款3：理解decltype 一般来说，decltype推导出来的就是被推导的类型，包括const，volatile、引用等特性。 template&lt;typename Container, typename Index&gt; auto authAndAccess(Container&amp; c, Index i) -&gt; decltype(c[i]) &#123; //有问题，auto会移除引用的特性 return c[i]; &#125; vector&lt;int&gt; vec&#123;1, 2, 3&#125;; authAndAccess(vec, 1) = 10; //会出问题，因为返回值移除了引用特性，等号左边是一个右值。 //(读者注：本人测试的时候，authAndAccess返回的是引用类型。 搭配decltype即可保留引用的特性。 template&lt;typename Container, typename Index&gt; decltype(auto) authAndAccess(Container&amp; c, Index i) &#123; //C++14 feature。 return c[i]; &#125; 值得一提的是，decltype在如下情况不是预期值。 C++硬性规定最小取址单位为字节，vector&lt;bool&gt;的元素不是bit大小，使用的是代理类模拟其他vector实现的功能。 对对变量加上小括号即为引用类型。 int x = 10; decltype((x)) ref = x;//ref&#x27;s type is int&amp; 条款4：掌握查看类别推到结果的方法 利用IDE、type_inex查看类型，但有可能出错。 第二章：auto条款5：优先选用auto，而非显示类别声明 auto变量必须初始化，可以避免一些打字出错导致的隐式类型转换。也可以简化重构流程。 auto变量具有条款2和条款6所说的毛病。 条款6：当auto推导不符合要求时，显式声明 隐私类型转换会导致auto推导不符合预期。如条款2中提到的vector&lt;bool&gt;元素，不能使用auto。 使用static_cast强制类型转换成预期类型。 第三章： 转向现代C++条款7：在创建对象时区分()和&#123;&#125; 大括号初始化可以阻止隐式窄化类别转换，还有解析语法友好。 在构造函数重载决议期间，含initializer_list的f构造函数有特别高的匹配优先级。 条款8：优先选用nullptr，而非0或NULL 防止模板推导和一些隐式转换的问题。 条款9：优先选用别名声明，而非typedef tyepdef不支持模板化，但类型别名using支持。 别名模板可以免写::type后缀，内嵌时也需要加上typename前缀。 条款10：优先选用限定作用域的枚举类型，而非不限作用域的枚举类型 限定作用域的枚举类型仅在枚举类别内可见。它们只能通过强制类型转换到其他类型。 两种都支持指定底层类型。限定作用域的默认为int，而不限的则没有默认的。 限定作用域的可以前置声明，而不限范围的不行。 条款11：优先选用删除函数，而非private未定义 任何函数都可以删除，包括非成员函数和模板特例。 条款12：为意在重写的函数添加override 成员函数引用饰词（&amp; 和 &amp;&amp;）使得对于左值和右值对象（*this）能够区分。 auto val = makeWidget().data(); //对于右值应该有不一样的行为。 class Widget&#123; void f() &amp;; //自身是左值Widget左值调用 void f() &amp;&amp;; //自身是右值Widget右值调用 &#125;; 条款13：优先选用const_iterator，而非iterator 由于C++11未对某些容器做const_iterator(C++14有), 对于特定情况下可用非成员版本的begin，end和rbegin等。 条款14：只要函数不会发射异常，就为其加上noexcept声明 对于移动操作，swap，内存释放函数和析构函数最有价值。 条款15：只要有可能使用constexpr，就用 条款16：保证const成员函数的线程安全性 条款17：理解特殊成员函数的生成机制 含默认构造函数，析构函数，复制操作（复制构造和复制赋值），移动操作（移动构造和移动赋值）。生成的前提都是没有显式生成。 默认构造函数：没有显示声明任何构造函数。 复制构造：没有声明移动操作，但已经存在析构或复制赋值情况下生成已成为被废弃（deprecated）的行为 复制赋值：没有声明移动操作，但已经存在析构或复制构造情况下生成已成为被废弃（deprecated）的行为。 移动操作：五个函数都不含。 成员模板在任何情况下都不会抑制特殊成员函数的生成（如完美转发可能出现的问题）。 第四章：智能指针条款18：使用unique_ptr 小巧、高速、只移的智能指针。 推荐使用工厂方法make_unique生成，但不能指定删除器。 可转化为shared_ptr 条款19：使用shared_ptr std::enable_shared_from_this&lt;T&gt;的使用。 class Widget; vector&lt;shared_ptr&lt;Widget&gt;&gt; task; class Widget &#123; void process(vector&lt;int&gt;&amp; ) &#123; /* * do some init work; */ task.emplace_back(this); // wrong!!! // this will create more than one shared_ptr from the same raw ptr; // delete more than once. &#125; &#125;; 用法 class Widget; vector&lt;shared_ptr&lt;Widget&gt;&gt; task; class Widget: public std::enable_shared_from_this&lt;Widget&gt; &#123; void process(vector&lt;int&gt;&amp; ) &#123; /* * do some init work; */ task.emplace_back(shared_from_this); &#125; &#125;; 条款20：对于类似但可能空悬的指针使用std::weak_ptr Usage: std::weak_ptr&lt;Widget&gt; wpw(spw); spw = nullptr; //deconstructor. if (wpw.expired()) &#123; ... &#125; std::shared_ptr&lt;Widget&gt; spw1 = wpw.lock(); //若wpw失效， 则spw1为nullptr。 atuo spw2 = wpw.lock(); //同上 std::shared_ptr&lt;Widget&gt; spw3(wpw); //若wpw失效，则抛出异常。 优势 缓存读取 观察者列表 避免环路 条款21：优先选用std::make_unique和 std::shared_ptr而非直接构造。 将new和智能指针的步骤整合。但无法自定义析构器 由于经过了一次完美转发，因此无法使用大括号初始化（见条款2）。 条款22：使用Pimpl习惯用法时，将特殊成员的定义放在实现文件中 Pimpl模式降低类的设计者和使用者的依赖性 使用采用std::unique_ptr来实现pImpl指针，须在类的头文件中声明特种成员函数，但在实现文件中实现他们。即使默认的函数具有正确的行为。 上述建议仅仅适用unique_ptr但不适用shared_ptr 第五章：右值引用、移动语义和完美转发条款23：std::move和 std::forward move实施的是无条件的强制右值转换，就本身而言，并不执行移动操作。 仅当传入的实参被绑定到右值时，std::forward才执行该实参向右值类型的强制类型转换。 运行期，std::move和std::forward都不会执行任何操作。 条款24：区分万能引用和右值引用 如果函数模板具备T&amp;&amp;类型并且T的类别由推导而来，或如果对象使用auto&amp;&amp; 推导，则为万能引用。 反之为右值引用。 万能引用：区分左值右值，左值推导为左值，右值推导为右值。 条款25：针对右值引用使用std::move,万能引用使用std::forward 条款26：避免依万能引用进行重载 把万能引用作为重载候选类别时，几乎总会意外被调用。 特别是完美转发构造函数。 条款27：条款26的替代方案 略… 条款28：理解引用折叠 在四种语境下：模板实例化，auto类型推导，创建和使用typedef和别名(using)声明，以及decltype 上述语境下，引用的引用会折叠为一个引用。 条款29：假定移动操作不存在、成本高、未使用 提高兼容性 如果明确支持移动，则无需假定。 条款30：完美转发失败的情形 大括号初始化物&#123;&#125; 0和NULL作空指针。 仅有声明的整形static const成员变量（常量无法取址，由于引用底层实际是指针，需要地址）。 转发给重载的函数名字和模板名字（可手动指定static_cast成指定函数）。 位域（位域单位为bit，C++规定非const不能指定到单个bit，因为操作最小单位为1byte）。 第六章：lambda表达式条款31：避免默认捕获模式 在类中捕获成员，实际捕获的是this。当该对象被析构时，行为未定义。 （经测试，有些编译器会给出编译错误: “‘this’ cannot be implicitly captured in this context”）。 vector&lt;function&lt;void()&gt;&gt; vec; //经测试，读者的编译器会给出编译错误: &quot;&#x27;this&#x27; cannot be implicitly captured in this context&quot;。 class Widget &#123; public: int val = 10; void f() &#123; vec.emplace_back([] () &#123; cout &lt;&lt; val &lt;&lt; endl; &#125;); &#125; &#125;; //error class Widget &#123; public: int val = 10; void f() &#123; vec.emplace_back([=] () &#123; cout &lt;&lt; val &lt;&lt; endl; &#125;); &#125; &#125;; 解决办法: //本地copy class Widget &#123; public: int val = 10; void f() &#123; int copy = this-&gt;val; vec.emplace_back([=] () &#123; cout &lt;&lt; copy &lt;&lt; endl; &#125;); &#125; &#125;; //初始化捕获，也称广义捕获 class Widget &#123; public: int val = 10; void f() &#123; vec.emplace_back([val = this-&gt;val] () &#123; cout &lt;&lt; val &lt;&lt; endl; &#125;); &#125; &#125;; 条款32：使用初始化捕获将对象移入闭包 //初始化捕获，也称广义捕获 class Widget &#123; public: int val = 10; void f() &#123; vec.emplace_back([val = this-&gt;val] () &#123; cout &lt;&lt; val &lt;&lt; endl; &#125;); &#125; &#125;; 条款33：对auto&amp;&amp;类别的形参使用decltype和forward forward&lt;decltype(param)&gt;(param); 条款34：优先选用lambda，而非bind 第七章：并发API这部分建议阅读：C++ Concurrency in Action: Practical Multithreading by Anthony Williams. My Note: messenger1th&#x2F;Concurrency (github.com) 条款35：优先选用基于任务而非基于线程的程序 任务是更高层的API，可以获取运算线程的结果。而基于线程，则无返回值。 基于线程，需要手动管理线程耗尽，超订，负载均衡，以及新平台适配。 基于任务，启动方式多样，更自由。 条款36：如果异步是必要的，则指定std::launch::async 条款37：使std::thread型对象所在路径皆不可联结 条款38：对变化多端的线程句柄析构函数行为保持关注 条款39：考虑针对一次性时间通信使用void为模板类型实参的promise 条款40：对并发使用std::atomic,特种内存使用volatile 第八章：微调条款41：针对可复制的形参，在移动成本低且一定会被复制的前提，考虑按值传递 实际上，需要对应用场景进行具体评估。 条款42：考虑emplace而非插入 直接使用参数构造，而非构造后移动或复制。 读者总结前面几章能够理解，后面的并发有些抽象和底层了，我感觉不如C++ Concurrency In Action来的透彻。","categories":[{"name":"C++","slug":"C","permalink":"https://messenger1th.github.io/categories/C/"}],"tags":[]},{"title":"reader-writer control","slug":"Articles/reader-writer control","date":"2024-07-24T14:47:33.905Z","updated":"2024-07-24T14:47:33.906Z","comments":true,"path":"2024/07/24/Articles/reader-writer control/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Articles/reader-writer%20control/","excerpt":"","text":"读者写者-处理的多种方式第一种：最省事的互斥锁使用C++11的thread和&#96;&#96;mutex&#96;库的互斥量和锁和多线程来实现。 #include &lt;iostream&gt; #include &lt;thread&gt; #include &lt;mutex&gt; int val = 0; std::mutex mutex; void read() &#123; std::cout &lt;&lt; &quot;I&#x27; m reading val: &quot; &lt;&lt; val &lt;&lt; std::endl; &#125; void write() &#123; ++val; std::cout &lt;&lt; &quot;I&#x27; m writing val: &quot; &lt;&lt; val &lt;&lt; std::endl; &#125; void reader() &#123; while (true) &#123; std::unique_lock&lt;std::mutex&gt; lock(mutex); read(); &#125; &#125; void writer() &#123; while (true) &#123; std::unique_lock&lt;std::mutex&gt; lock(mutex); write(); &#125; &#125; int main() &#123; std::thread read_thread(&amp;reader); std::thread write_thread(&amp;writer); read_thread.join(); write_thread.join(); return 0; &#125; 使用互斥锁有一个很明显的问题，虽然读写是互斥，但也把读读也给互斥了。因此，这点可以改进一下，于是就有了读写锁。 第二种：读写锁使用C++17的thread和&#96;&#96;shared_mutex&#96;库中的读写锁和多线程来实现。 #include &lt;iostream&gt; #include &lt;thread&gt; #include &lt;shared_mutex&gt; #include &lt;condition_variable&gt; int val = 0; std::shared_mutex mutex; void read() &#123; std::cout &lt;&lt; &quot;I&#x27; m reading val: &quot; &lt;&lt; val &lt;&lt; std::endl; &#125; void write() &#123; ++val; std::cout &lt;&lt; &quot;I&#x27; m writing val: &quot; &lt;&lt; val &lt;&lt; std::endl; &#125; void reader() &#123; while (true) &#123; std::shared_lock&lt;std::shared_mutex&gt; reader_lock(mutex); read(); &#125; &#125; void writer() &#123; while (true) &#123; std::unique_lock&lt;std::shared_mutex&gt; writer_lock(mutex); write(); &#125; &#125; int main() &#123; std::thread read_thread(&amp;reader); std::thread write_thread1(&amp;writer); std::thread write_thread2(&amp;writer); read_thread.join(); write_thread1.join(); write_thread2.join(); return 0; &#125; 写到这里，多线程读的问题总是解决了。 欸，那我要是想让读有更高的优先级呢？ PV信号量信号量是操作系统提供的一种协调共享资源访问的方法。 通常信号量表示资源的数量，对应的变量是一个整型（sem）变量。 另外，还有两个原子操作的系统调用函数来控制信号量的，分别是： P 操作：将 sem 减 1，相减后，如果 sem &lt; 0，则进程&#x2F;线程进入阻塞等待，否则继续，表明 P 操作可能会阻塞； V 操作：将 sem 加 1，相加后，如果 sem &lt;= 0，唤醒一个等待中的进程&#x2F;线程，表明 V 操作不会阻塞； 操作系统是如何实现 PV 操作的呢？ 信号量数据结构与 PV 操作的算法描述如下图： 作者采用posix标准的semaphore和pthread库来实现以下锁和同步，由于是posix标准，Windows上做了相应的移植库，因此Unix（Linux）和Windows系统都可以运行。 而posix标准中与PV、信号量的对应关系。 信号量：sem_t, 注意使用sem_init来初始化。 P操作：sem_wait V操作：sem_post 实现锁根据上面的叙述，要使得P操作互斥，我们需要设置信号量的初值为1. 对于两个并发线程，互斥信号量的值仅取 1、0 和 -1 三个值，分别表示： 如果互斥信号量为 1，表示没有线程进入临界区； 如果互斥信号量为 0，表示有一个线程进入临界区； 如果互斥信号量为 -1，表示一个线程进入临界区，另一个线程等待进入。 通过互斥信号量的方式，就能保证临界区任何时刻只有一个线程在执行，就达到了互斥的效果。 读优先#include &lt;semaphore.h&gt; #include &lt;pthread.h&gt; #include &lt;stdio.h&gt; sem_t data_mutex; sem_t reader_count_mutex; int reader_count = 0; void* writer(void* arg) &#123; while (1) &#123; sem_wait(&amp;data_mutex); //operate writing printf(&quot;I&#x27; m writer\\n&quot;); sem_post(&amp;data_mutex); &#125; &#125; // reader is prior. void* reader(void* arg) &#123; while (1) &#123; sem_wait(&amp;reader_count_mutex); if (reader_count == 0) &#123; sem_wait(&amp;data_mutex); &#125; ++reader_count; sem_post(&amp;reader_count_mutex); //unlock to let later reader in. //operate reading printf(&quot;I&#x27;m reader\\n&quot;); sem_wait(&amp;reader_count_mutex); //lock to decrement reader_clount. --reader_count; if (reader_count == 0) &#123; sem_post(&amp;data_mutex); &#125; sem_post(&amp;reader_count_mutex); &#125; &#125; int main() &#123; sem_init(&amp;data_mutex, 0, 1); sem_init(&amp;reader_count_mutex, 0, 1); pthread_t reader_t1, reader_t2, writer_t; pthread_create(&amp;reader_t1, NULL, reader, NULL); pthread_create(&amp;reader_t2, NULL, reader, NULL); pthread_create(&amp;writer_t, NULL, writer, NULL); pthread_join(reader_t1, NULL); pthread_join(reader_t2, NULL); pthread_join(writer_t, NULL); return 0; &#125; 只要有读者正在读的状态，后来的读者都可以直接进入，如果读者持续不断进入，则写者会处于饥饿状态。 那我要是想要写优先呢？ 写优先#include &lt;semaphore.h&gt; #include &lt;pthread.h&gt; #include &lt;stdio.h&gt; int reader_count = 0; sem_t reader_count_mutex;//make counter exclusive. int writer_count = 0; sem_t writer_count_mutex;//make counter exclusive. sem_t read_mutex; //make read shared. sem_t write_mutex; //make write exclusive. //writer prior void* writer(void* arg) &#123; while (1) &#123; sem_wait(&amp;writer_count_mutex); if (writer_count == 0) &#123; sem_wait(&amp;read_mutex); &#125; ++writer_count; sem_post(&amp;writer_count_mutex); sem_wait(&amp;write_mutex); //operating write; printf(&quot;I&#x27; m writing\\n&quot;) ; sem_post(&amp;write_mutex); sem_wait(&amp;writer_count_mutex); --writer_count; if (writer_count == 0) &#123; sem_post(&amp;read_mutex); &#125; sem_post(&amp;writer_count_mutex); &#125; &#125; void* reader(void* arg) &#123; while (1) &#123; sem_wait(&amp;read_mutex); sem_wait(&amp;reader_count_mutex); if (reader_count == 0) &#123; sem_wait(&amp;write_mutex); &#125; ++reader_count; sem_post(&amp;reader_count_mutex); sem_post(&amp;read_mutex); //opeating read printf(&quot;I&#x27;m reading\\n&quot;); sem_wait(&amp;reader_count_mutex); --reader_count; if (reader_count == 0) &#123; sem_post(&amp;write_mutex); &#125; sem_post(&amp;reader_count_mutex); &#125; &#125; int main() &#123; sem_init(&amp;writer_count_mutex, 0, 1); sem_init(&amp;reader_count_mutex, 0, 1); sem_init(&amp;write_mutex, 0, 1); sem_init(&amp;read_mutex, 0, 1); pthread_t writer1_t, writer2_t, reader_t; pthread_create(&amp;writer1_t, NULL, writer, NULL); pthread_create(&amp;writer2_t, NULL, writer, NULL); pthread_create(&amp;reader_t, NULL,reader, NULL); pthread_join(writer1_t, NULL); pthread_join(writer2_t, NULL); pthread_join(reader_t, NULL); return 0; &#125; 注意，这里 read_mutex 的作用，开始有多个读者读数据，它们全部进入读者队列，此时来了一个写者，执行了 P(rMutex) 之后，后续的读者由于阻塞在 rMutex 上，都不能再进入读者队列，而写者到来，则可以全部进入写者队列，因此保证了写者优先。 同时，第一个写者执行了 P(read_mutex) 之后，也不能马上开始写，必须等到所有进入读者队列的读者都执行完读操作，通过 V(write_mutex) 唤醒写者的写操作。 那想实现读写按先后顺序呢？ 时间顺序#include &lt;semaphore.h&gt; #include &lt;pthread.h&gt; #include &lt;stdio.h&gt; sem_t data_mutex; int reader_count = 0; sem_t reader_count_mutex; sem_t higher_mutex; void* writer(void* arg) &#123; while (1) &#123; sem_wait(&amp;higher_mutex); sem_wait(&amp;data_mutex); //operate writing printf(&quot;I&#x27; m writing\\n&quot;); sem_post(&amp;data_mutex); sem_post(&amp;higher_mutex); &#125; &#125; // reader is prior. void* reader(void* arg) &#123; while (1) &#123; sem_wait(&amp;higher_mutex); sem_wait(&amp;reader_count_mutex); if (reader_count == 0) &#123; sem_wait(&amp;data_mutex); &#125; ++reader_count; sem_post(&amp;reader_count_mutex); //unlock to let later reader in. sem_post(&amp;higher_mutex); //operate reading printf(&quot;I&#x27;m reading\\n&quot;); sem_wait(&amp;reader_count_mutex); //lock to decrement reader_clount. --reader_count; if (reader_count == 0) &#123; sem_post(&amp;data_mutex); &#125; sem_post(&amp;reader_count_mutex); &#125; &#125; int main() &#123; sem_init(&amp;data_mutex, 0, 1); sem_init(&amp;reader_count_mutex, 0, 1); sem_init(&amp;higher_mutex, 0, 1); pthread_t reader_t1, reader_t2, writer_t; pthread_create(&amp;reader_t1, NULL, reader, NULL); pthread_create(&amp;reader_t2, NULL, reader, NULL); pthread_create(&amp;writer_t, NULL, writer, NULL); pthread_join(reader_t1, NULL); pthread_join(reader_t2, NULL); pthread_join(writer_t, NULL); return 0; &#125; 看完代码不知你是否有这样的疑问，为什么加了一个信号量 higher_muex，就实现了公平竞争？ 对比方案一的读者优先策略，可以发现，读者优先中只要后续有读者到达，读者就可以进入读者队列， 而写者必须等待，直到没有读者到达。 没有读者到达会导致读者队列为空，即 read_count==0，此时写者才可以进入临界区执行写操作。 而这里 higher_mutex 的作用就是阻止读者的这种特殊权限（特殊权限是只要读者到达，就可以进入读者队列）。 比如：开始来了一些读者读数据，它们全部进入读者队列，此时来了一个写者，执行 P(higher_mutex) 操作，使得后续到来的读者都阻塞在 higher_mutex 上，不能进入读者队列，这会使得读者队列逐渐为空，即 read_count 减为 0。 这个写者也不能立马开始写（因为此时读者队列不为空），会阻塞在信号量 data_mutex 上，读者队列中的读者全部读取结束后，最后一个读者进程执行 V(data_mutex)，唤醒刚才的写者，写者则继续开始进行写操作。 总的来说，在读优先的情况下，写者没有一个有效的手段（锁）来限制读者的无限制增加，而此处的higher_mutex起到的就是这样的作用。 实现同步信号量不仅可以实现临界区的互斥访问控制，还可以线程间的事件同步。 根据同步的定义，我们不难知道，一个线程等待一个条件成立，需要另一个来通知，而sem&lt;=0唤醒会线程（即同步），所以，是通过V操作来唤醒线程。而P操作会使得等待的线程睡眠，因此，要实现同步的步骤就很明了了。 等待线程：waiting_thread P(sem) do some work V(sem) 通知线程：notify_thread V(sem) P(sem) 具体实现代码如下： #include &lt;semaphore.h&gt; #include &lt;pthread.h&gt; #include &lt;stdio.h&gt; sem_t sem; void* waiting_thread(void* arg) &#123; while (1) &#123; sem_wait(&amp;sem); //do something printf(&quot;I&#x27; got it.\\n&quot;); sem_post(&amp;sem); &#125; &#125; // notify_thread is prior. void* notify_thread(void* arg) &#123; while (1) &#123; sem_post(&amp;sem); //notify waiting thread. printf(&quot;notified&quot;); sem_wait(&amp;sem); //hang-up waiting thread. &#125; &#125; int main() &#123; sem_init(&amp;sem, 0, 0); pthread_t notify_t, waiting_t; pthread_create(&amp;notify_t, NULL, notify_thread, NULL); pthread_create(&amp;waiting_t, NULL, waiting_thread, NULL); pthread_join(notify_t, NULL); pthread_join(waiting_t, NULL); return 0; &#125; 总结从上述过程来说，PV信号量不仅可以实现锁还可以实现同步. posix下的锁和pthread_cond_t， C++下的锁和condition_variable的都可以用PV信号量来实现。","categories":[{"name":"Articles","slug":"Articles","permalink":"https://messenger1th.github.io/categories/Articles/"}],"tags":[]},{"title":"Union-Find","slug":"Articles/Union-Find","date":"2024-07-24T14:47:33.903Z","updated":"2024-07-24T14:47:33.903Z","comments":true,"path":"2024/07/24/Articles/Union-Find/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Articles/Union-Find/","excerpt":"","text":"Union-Find也称Disjoint-set structure。 基于树数组实现树 + 按rank合并 + 路径压缩 class UnionFind&#123; public: UnionFind(int n): setNum(n), rank(n, 1) &#123; parent.reserve(n); for (int i = 0; i &lt; n; ++i) &#123; parent.emplace_back(i); &#125; &#125; int find(int x) &#123; if (x != parent[x]) &#123; parent[x] = find(parent[x]); &#125; return parent[x]; &#125; void unite(int x, int y) &#123; int rootX = find(x); int rootY = find(y); if (rootX != rootY) &#123; --setNum; if (rank[rootX] == rank[rootY]) &#123; parent[rootX] = rootY; ++rank[rootY]; &#125; else if (rank[rootX] &lt; rank[rootY]) &#123; parent[rootX] = rootY; &#125; else &#123; parent[rootY] = rootX; &#125; &#125; &#125; bool isConnected(int x, int y) &#123; return find(x) == find(y); &#125; int getsetNum() &#123; return setNum; &#125; private: vector&lt;int&gt; parent; vector&lt;int&gt; rank; int setNum; &#125;; 时间复杂度 find(): $O(1)$。比对数小，接近线性。但多次操作后，经路径压缩变成 $O(1)$; unite(int x, int y): $O(n)$ 空间复杂度：$O(n)$ 基于链表class Node&#123; public: Node* nodeSet; Node* prev; Node* next; Node() &#123; this-&gt;prev = this-&gt;next = this-&gt;nodeSet = this; &#125; &#125;; class UnionFind&#123; public: UnionFind(int n):nodes(n), SetNum(n) &#123;&#125; bool isSameSet(int x, int y) &#123; return nodes[x].nodeSet == nodes[y].nodeSet; &#125; void unite(int x, int y) &#123; if (!isSameSet(x, y)) &#123; Node* xHead = nodes[x].nodeSet; Node* yHead = nodes[y].nodeSet; Node* xTail = xHead-&gt;prev; Node* yTail = yHead-&gt;prev; xTail-&gt;next = yHead; yHead-&gt;prev = xTail; xHead-&gt;prev = yTail; yTail-&gt;next = xHead; Node* p = yHead; while (p != xHead) &#123; p-&gt;nodeSet = xHead; p = p-&gt;next; &#125; --SetNum; &#125; &#125; private: vector&lt;Node&gt; nodes; int SetNum; &#125;; 时间复杂度： isSameSet(): $O(1)$ unite(int x, int y): $O(n)$ 空间复杂度：$O(n)$ 题目 547. 省份数量 200. 岛屿数量 130. 被围绕的区域 685. 冗余连接 II 778. 水位上升的泳池中游泳 399. 除法求值、","categories":[{"name":"Articles","slug":"Articles","permalink":"https://messenger1th.github.io/categories/Articles/"}],"tags":[]},{"title":"distributed-system","slug":"Articles/distributed-system","date":"2024-07-24T14:47:33.903Z","updated":"2024-07-24T14:47:33.903Z","comments":true,"path":"2024/07/24/Articles/distributed-system/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Articles/distributed-system/","excerpt":"","text":"分布式、集群属性可靠性可靠性（Reliability）是指系统可以无故障地持续运行。与可用性相反，可靠性是根据时间间隔而不是任何时刻来进行定义的。可靠性相关的几个指标如下： 可靠性（Reliability）是指系统可以无故障地持续运行。与可用性相反，可靠性是根据时间间隔而不是任何时刻来进行定义的。可靠性相关的几个指标如下： MTBF（Mean Time Between Failure） 即平均无故障时间，是指从新的产品在规定的工作环境条件下开始工作到出现第一个故障的时间的平均值。MTBF越长表示可靠性越高，正确工作能力越强 。 MTTR（Mean Time To Repair） 即平均修复时间，是指可修复产品的平均修复时间，就是从出现故障到修复中间的这段时间。MTTR越短表示易恢复性越好。 MTTF（Mean Time To Failure） 即平均失效时间。系统平均能够正常运行多长时间，才发生一次故障。系统的可靠性越高，平均无故障时间越长。 这些指标跟可用性关系 Availability &#x3D; UpTime&#x2F;(UpTime+DownTime) &#x3D; MTBF &#x2F; (MTBF + MTTR) 可用性可用性（Availability）被定义为系统的一个属性，它说明系统已准备好，马上就可以使用。换句话说，高度可用的系统在任何给定的时刻都能及时地工作。关注的是服务总体的持续时间，系统在给定时间内总体的运行时间越长，可用性越高。 一致性区分可靠性和可用性的区别我们举个一个例子来说明二者的区别。如果系统在每小时崩溃1ms，那么它的可用性就超过99.9999%，但是它还是高度不可靠，因为它只能无故障运行1小时。与之类似，如果一个系统从来不崩溃，但是每年要停机两星期，那么它是高度可靠的，但是可用性只有96%。 简单来说，可靠性强调正常运行的持续时长，而可用性关注正常运行时间的比例。 分布式和集群的区别形式从形式上来说，集群是个物理形态，分布式是一种工作模式。他们并不是同一个维度的概念。 集群一般是物理集中、统一管理的，而分布式则不关心这一点。 分布式是相对中心化而来的，强调的是任务在多个物理隔离的节点上进行。中心化带来的问题是可靠性和可用性，一但中心出问题，整个系统不可用。分布式主要解决这个问题，除此之外，也通常倾向分散负载。但分布式也会带来问题，最主要的是一致性问题。 用通俗的话来说，就是“分头做事”和”一群人“的区别。 作用 分布式：不同的业务模块部署在不同的服务器上或者同一个业务模块分拆多个子业务，部署在不同的服务器上，解决高并发的问题 集群：同一个业务部署在多台机器上，提高系统可用性 分布式是以缩短单个任务的执行时间来提升效率的，而集群则是通过提高单位时间内执行的任务数来提升效率。 Replication TypeSingle Leader Synchronous Replication Asynchronous Replication Semisynchronous Replication 起因什么是分布式系统？ 相较于单服务器来说，分布式系统就是拥有多个服务器。多个服务器之间互相通过网络同步，从外界看来就像是使用单机服务器。 为什么要设计分布式系统？ 提高性能 更高容错 更易扩展 分布式系统分类 同步系统：synchronous 异步系统：asynchronous 半同步系统：semi-synchronous 分布式的难点 由于是多个服务器，就有多份数据副本，多个副本就理所当然的需要数据同步，数据怎么同步，什么时候同步，这就涉及一致性的问题。 由于分布式不是单机，是遍布各地多个服务器，就需要涉及网络来同步数据，这就涉及到网络的所有可能出现的问题，比如 网络延迟 数据丢失 网络分区 分析下来，主要难点是数据一致性和网络分区的问题。 当如还有其他问题，如 部分服务器故障 服务器没有统一时钟 一致性：Consistency一致性最早并不是在分布式系统领域提出，而是并发领域。如CPU的缓存一致性，为了缓解CPU和内存的速度差异而出现的CPU缓存，而CPU衍生出多核CPU就出现了CPU缓存一致性的问题。本质是就是多个副本的同步问题。那为什么CPU一致性没有分布式那么难以解决呢？主要是CPU缓存同步不涉及网络，延迟和分区的问题是可以保证的，仅仅通过总线嗅探和MESI协议就可以实现缓存一致性。 以下讨论以分布式系统为例。 一致性模型有如下常用的模型 线性一致性：Linearizable Consistency 顺序一致性：Sequential Consistency 因果一致性：Causal Consistency 最终一致性：Eventual Consistency 上面提到，数据同步的问题。而一致性就是系统给予用户对于数据的保证。这个怎么理解呢？ 拿线性一致性来说，系统会将所有用户的请求按顺序进行操作，这就保证了所有用户都能看到最新的结果，是最符合咱们理解的一致性。 而顺序一致性只保证了当个用户的请求的顺序，系统保证了某 用户的请求的顺序。但是不同用户的请求的顺序不能保证。举个例子，你的好友A优先请求，随后你看到A请求了，跟着请求。但系统的执行顺序可能是有限执行你的请求。但你的下一个请求，一定是在你的上一个请求之前执行。 因果一致性就只保证了有逻辑关系的请求的顺序。 最终一致性只保证所有服务器最终会达成相同状态。 以上的一致性都是站在多个客户端的角度来说的，还有一部分一致性模型是以客户端为中心的模型，如 单调读：每次读都保证后续的读读到非历史的值。 单调写 读你所写 PRAM（Pipelined RAM） 读后写 一致性与现实顺序一致性：拿网购为例，现在我和A都在抢一个商品，商品仅剩一件。如果我优先发起订单，按照常理来说，一定是我买到了这件商品。但是，如果没有一致性保证，就不一定是我买到了。例如，顺序一致性。它可能优先处理A的订单，也就导致虽然我先发起订单，但没有买到，反而是后发起订单的A买到了该商品。 最终一致性：再举个例子，假如你账户上余额为0元，你给账户充值了100，然后查询，看到自己账户余额已经变成了100，安心离开。过一会你想取点钱，一查，账户变为0元了。这时你会怎么想？我明明已经充值了100，会不会是被盗刷了？而实际上，可能是系统返回了之前账户充值100元之前的余额，也就是0元。 要研究一致性，科研人员提出了一些定理对于一致性进行约束。 告诉什么情况是不可能的，不要在这方面浪费时间精力，如CAP， FLP，PACELC等定理。 给出了一些建议性的定理，如BASE，Quorum定理。 CAP定理CAP指的如下三个性质 Consistency（一致性（在这里指线性一致性））：每次都能获取最新数据。 Availability（可用性）：每次请求都能获取到非错的响应，但可能不是最新。 Partition Tolerance：分区容错性。如果网络分区（网路不可达），就需要在C和A之间做出取舍。 CAP指出，对于分布式系统只能满足三项中的两项而不可能满足全部三项。 当没有分区时，就可以满足C和A。但出现网络分区时，要保证分区容错的话，就只能C和A二选一。 举个例子，服务器A接到新请求，准备同步给其他服务器，但此时A，B之间发生了网络分区。A接到的新请求无法被B看见，此时，B服务器来了个一个查看请求，就需要在Consistency和Availability之前做取舍，是选择Availability，直接返回当前查询的结果（不是最新的），还是保证Consistency，即等服务器A和B之前的网络分区消失，网络恢复正常，B再返回最新的结果。 CAP定理告诉我们不要将精力浪费在如何设计能满足三者的完美分布式系统，而是应该进行取舍。 PACELC定理PACELC定理是CAP定理的扩展，字母PAC即CAP， 而E是else， L代表Delay， C是Consistency。 CAP主要说的是网络分区时的取舍，PACELC还扩展了非分区的情况。 网络分区时，选择Consistency还是Availability。 网络正常时，选择Delay（网络延迟）还是Availability。 还是上面那个服务器AB的例子，当A接受到新请求时，B随后接受到查询请求，这时候B是选择直接返回当前结果（Availability），还是等A同步完数据再返回。（Delay）。 BASE定理BASE（Basically Availability, Soft State, Eventual Consistency.）是基本可用、软状态、最终一致性的首字母缩写。是在网络分区时，采用最终一致性，选择了高可用性。 虽然网络分区听起来很严重，但大部分情况只会存在一小段时间，可能几秒或者几分钟。所以最终一致性是一种可以接受的方案，适用于一些允许延迟的场景，如帖子点赞数等。 Quorum冗余机制Quorum指的是，在一个由N个节点组成的系统中，我们要求至少W个节点写入成功，并且需要同时从R个节点读取数据，只要W+R &gt; N且W &gt; N &#x2F; 2, 则读取的R个返回值至少包含一个最新的值。 **简单说明: ** 由N个节点和至少W个节点写入成功，则失败的最多为 N - W个，而读取要求是 W+R &gt; N即， R &gt; N - W，这就保证了读取的R个数据中至少包含一个最新的数据。 而W &gt; N &#x2F; 2 是为了节点们只能同时决策一个请求，用于串行化。 共识：Consensus共识指的是分布式中服务器对一个数据达成一致。 共识算法指的是分布式系统同步数据，达成共识的方式。 共识可以解决分布式系统的一些困难，如 原子提交 选主 互斥 FLP不可能定理FLP不可能定理指的是，在一个完全异步的网络环境中，即使只有一个进程出现故障，也无法实现任何安全的共识算法。 FLP强调的是一个在一个完全异步的网络环境，因此，对于同步网络是可以设计算法达成共识的。 于是，有了如下方式改异步为同步，绕过FLP不可能定理。 故障屏蔽。例如，如果一个进程崩溃，很长没收到回应。也认为他会恢复后（自动重启或者人工恢复）回应，只不过可能时间长一点。 使用故障检测器。例如超时故障检测，当一段时间内服务器没有回应，就认为该服务器崩溃。 使用随机性算法 条件要设计一种分布式共识算法，需要满足以下三个条件 Termination: 所有正常的进程都会认同同一个值，不会出现一直在循环的进程。 Agreement: 所有正常的进程选择的值都是一样的。 Validity: 任何正常的进程确定的值v’, 那么v’肯定是某个进程提交的。比如随机数生成器就不满足这个性质. 后来演变成更精炼、更常用的两个属性 Safety：安全性，即所有正确的进程都认同一个值 Liveness：活性，即分布式系统最终会认同某一个值。 RaftRaft是一种分布式共识算法。 解决分布式难题上面我们提到三个分布式系统设计的难题， 部分服务器故障 服务器没有统一时钟 网络延时 而Raft采用状态机复制解决上述问题 网络延时、分区、丢包、重复、和重排序的情况下，不会返回错误的结果。 状态机不依赖时钟。 服务器故障问题，高可用性。一般来说，只要集群中超过半数节点正常运行，能够互相通信且同客户端通信，该集群就可用。 那Raft是怎么保证安全性和活性的呢？ 安全性 活性 选主活性：每个节点的选举超时时间都在一个范围随机波动，让无限次分割选票的概率无限小。 日志活性：总有一个有效的leader被选出，而leader会将日志复制到其他节点。 状态机活性：状态机 会将已提交的日志应用到状态机。 总结一致性和共识的关系一致性指的是多个节点数据之间的相同性。由于节点之间需要网络来同步数据，引入网络来同步数据的同时也引入了一些困难，而共识算法就是设计算法来解决这种些困难，保证数据的一致性。 即，一致性依赖于共识算法。 为什么要区分这两者呢？ 从用户角度来说，只需要了解该分布式系统提供了怎么样的一致性，而无须关心怎么实现（共识算法）。 一致性哈希要了解一致性哈希，就要了解它解决了什么问题。此次引用小林的文章。 作者：小林coding 原文地址：https://xiaolincoding.com/os/8_network_system/hash.html 哈希算法可以用于数据分片的分布式系统的负载均衡，将请求哈希后取模映射到对于的服务器节点上。 但普通的哈希算法，在应对节点扩容时，需要移动大量数据到新位置，最差情况下所有的数据都要移动。 一致性哈希就是为了解决这种问题。 一致性哈希要进行两步哈希： 第一步：对存储节点进行哈希计算，也就是对存储节点做哈希映射，比如根据节点的 IP 地址进行哈希； 第二步：当对数据进行存储或访问时，对数据进行哈希映射； 对数据哈希映射后，顺时针找到第一个节点，即该数据的服务节点。 一致性哈希是怎么解决节点增删的问题呢？ 我们只需要将新节点加入哈希环，顺指针寻找上一个服务器，将自己负责的那部分数据复制过来，上一个服务器即可删除。删除节点同理，就完成了节点增删的过程。 从上述过程中不难发现，一致性哈希仅涉及一个原节点的数据变更。 但是一致性哈希算法并不保证节点能够在哈希环上分布均匀，这样就会带来一个问题，会有大量的请求集中在一个节点上。 这时候有一半以上的数据的寻址都会找节点 A，也就是访问请求主要集中的节点 A 上，这肯定不行的呀，说好的负载均衡呢，这种情况一点都不均衡。 另外，在这种节点分布不均匀的情况下，进行容灾与扩容时，哈希环上的相邻节点容易受到过大影响，容易发生雪崩式的连锁反应。 比如，上图中如果节点 A 被移除了，当节点 A 宕机后，根据一致性哈希算法的规则，其上数据应该全部迁移到相邻的节点 B 上，这样，节点 B 的数据量、访问量都会迅速增加很多倍，一旦新增的压力超过了节点 B 的处理能力上限，就会导致节点 B 崩溃，进而形成雪崩式的连锁反应。 所以，一致性哈希算法虽然减少了数据迁移量，但是存在节点分布不均匀的问题。 于是，就有了引入虚拟节点的一致性哈希算法。 虚拟节点一个服务器节点不是对应单个哈希环中的节点，而是对应多个虚拟节点。 映射到虚拟节点的数据都交给对应服务器节点处理。 多个虚拟节点就更好的均匀了哈希环。 除此之外，还可以根据不同服务器的性能，给不同服务器分别不同的虚拟节点个数，性能更高的分配更多的虚拟节点，更好地实现负载均衡。 因此，带虚拟节点的一致性哈希方法不仅适合节点规模会发生变化的场景，而且适合硬件配置不同的节点的场景。","categories":[{"name":"Articles","slug":"Articles","permalink":"https://messenger1th.github.io/categories/Articles/"}],"tags":[]},{"title":"Process Communication","slug":"Articles/Process Communication","date":"2024-07-24T14:47:33.901Z","updated":"2024-07-24T14:47:33.901Z","comments":true,"path":"2024/07/24/Articles/Process Communication/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Articles/Process%20Communication/","excerpt":"","text":"进程通信线程之间共享全局变量、文件描述符表、堆区资源等。通信较为方便，但进程之间通信需要跨越虚拟内存的鸿沟。 进程之间通信种方式有 管道 消息队列 共享内存 信号量 信号 Socket 接下来分别介绍他们和在Linux下的实现。 管道匿名管道 在Linux下，命令中传递参数用的|就是匿名管道，例如 ps aux | grep mysql 它将前一个命令ps aux的结果传递给下一个命令grep mysql作为输入。 命令管道&#x2F;FIFO 使用命令mkfifo创建命名管道，也称FIFO，因为符合先入先出的规律。 mkfifo my_pipe 在当前目录下创建一个管道文件my_pipe 可以向这个管道写入数据，例如echo echo &quot;hello&quot; &gt; my_pipe 你操作了后，你会发现命令执行后就停在这了，这是因为管道里的内容没有被读取，只有当管道里的数据被读完后，命令才可以正常退出。 于是，我们执行另外一个命令来读取这个管道里的数据： cat my_pipe hello 可以看到，管道里的内容被读取出来了，并打印在了终端上，另外一方面，echo 那个命令也正常退出了。 我们可以看出，管道这种通信方式效率低，不适合进程间频繁地交换数据。当然，它的好处，自然就是简单，同时也我们很容易得知管道里的数据已经被另一个进程读取了。 那么如何在咱们的代码中创建管道呢？ 需要用到下面这个系统调用 int pipe(int fd[2]); 这里表示创建一个匿名管道，并返回了两个描述符，一个是管道的读取端描述符 fd[0]，另一个是管道的写入端描述符 fd[1]。注意，这个匿名管道是特殊的文件，只存在于内存，不存于文件系统中。 普通的pipe就只能在单进程里头使用，如下图 但结合fork即可在父进程和子进程之间通信。 父进程Linux示例代码：父进程写，子进程读为例。 #include &lt;iostream&gt; #include &lt;string&gt; #include &lt;unistd.h&gt; int main() &#123; int fd[2]; pipe(fd); auto ret = fork(); if (ret == 0) &#123; close(fd[1]); printf(&quot;I&#x27; child.\\n&quot;); char buf[1024]; read(fd[0], buf, 1024); //阻塞在这， 等有数据再读。 printf(&quot;get messege: %s\\n&quot;, buf); &#125; else &#123; close(fd[0]); printf(&quot;I&#x27;m parent.\\n&quot;); sleep(5); //让读进程阻塞。 const std::string s = &quot;Hello pipe reader&quot;; write(fd[1], s.c_str(), s.size()); &#125; return 0; &#125; 实际上，fork出来的子进程的fd是和父进程相同的。因此，父子进程操作的是同一个管道，即不能同时地双向通信。要双向通行可以创建两个管道。 总的来说，对于匿名管道，由于没有文件名，只有描述符，仅能通过fork复制fd来实现父子进程通信。 而命名管道则是一个实实在在的文件，有文件名。因此，两个进程可以通过文件名找到该管道来通信。 值得一提的是，不管是匿名管道还是命名管道，进程写入的数据都是缓存在内核中，另一个进程读取数据时候自然也是从内核中获取，同时通信数据都遵循先进先出原则，不支持 lseek 之类的文件定位操作。 此外，匿名管道和FIFO读写都是默认阻塞的，如果要使用非阻塞模式，需要在pipe和open的第二个参数指定O_NONBLOCK，并根据返回值和错误号来判断具体情况做后续处理。 消息队列前面提到管道的写方需要阻塞到数据被读取才能够返回，而消息队列则不需要。 对于写方，只需要写完数据即可。 对于读方，读取时需要阻塞到数据来临。 实例代码 // Message Queue (Writer Process) #include &lt;stdio.h&gt; #include &lt;sys/ipc.h&gt; #include &lt;sys/msg.h&gt; #define MAX 10 // structure for message queue struct mesg_buffer &#123; long mesg_type; char mesg_text[100]; &#125; message; int main() &#123; key_t key; int msgid; // ftok to generate unique key key = ftok(&quot;progfile&quot;, 65); // msgget creates a message queue // and returns identifier msgid = msgget(key, 0666 | IPC_CREAT); message.mesg_type = 1; printf(&quot;Write Data : &quot;); fgets(message.mesg_text,MAX,stdin); // msgsnd to send message msgsnd(msgid, &amp;message, sizeof(message), 0); // display the message printf(&quot;Data send is : %s \\n&quot;, message.mesg_text); return 0; &#125; // Message Queue (Reader Process) #include &lt;stdio.h&gt; #include &lt;sys/ipc.h&gt; #include &lt;sys/msg.h&gt; // structure for message queue struct mesg_buffer &#123; long mesg_type; char mesg_text[100]; &#125; message; int main() &#123; key_t key; int msgid; // ftok to generate unique key key = ftok(&quot;progfile&quot;, 65); // msgget creates a message queue // and returns identifier msgid = msgget(key, 0666 | IPC_CREAT); // msgrcv to receive message msgrcv(msgid, &amp;message, sizeof(message), 1, 0); // display the message printf(&quot;Data Received is : %s \\n&quot;, message.mesg_text); // to destroy the message queue msgctl(msgid, IPC_RMID, NULL); return 0; &#125; 消息队列生命周期随内核，如果没有释放消息队列或者没有关闭操作系统，消息队列会一直存在，而前面提到的匿名管道的生命周期，是随进程的创建而建立，随进程的结束而销毁。 消息这种模型，两个进程之间的通信就像平时发邮件一样，你来一封，我回一封，可以频繁沟通了。 但邮件的通信方式存在不足的地方有两点，一是通信不及时，二是附件也有大小限制，这同样也是消息队列通信不足的点。 消息队列不适合比较大数据的传输，因为在内核中每个消息体都有一个最大长度的限制，同时所有队列所包含的全部消息体的总长度也是有上限。在 Linux 内核中，会有两个宏定义 MSGMAX 和 MSGMNB，它们以字节为单位，分别定义了一条消息的最大长度和一个队列的最大长度。 消息队列通信过程中，存在用户态与内核态之间的数据拷贝开销，因为进程写入数据到内核中的消息队列时，会发生从用户态拷贝数据到内核态的过程，同理另一进程读取内核中的消息数据时，会发生从内核态拷贝数据到用户态的过程。 共享内存上面提到，消息队列涉及用户态与内核态之间的数据拷贝，显然这是不必要的。而共享内存的方式，就很好的去除了这个开销。 现代操作系统的内存采用的是虚拟内存技术，即每个进程的内存相互独立，互不干扰。而虚拟内存就是拿出来一块共享内存来通信。 示例代码 // Writer #include &lt;iostream&gt; #include &lt;sys/ipc.h&gt; #include &lt;sys/shm.h&gt; #include &lt;stdio.h&gt; using namespace std; int main() &#123; // ftok to generate unique key key_t key = ftok(&quot;shmfile&quot;,65); // shmget returns an identifier in shmid int shmid = shmget(key,1024,0666|IPC_CREAT); // shmat to attach to shared memory char *str = (char*) shmat(shmid,(void*)0,0); cout&lt;&lt;&quot;Write Data : &quot;; gets(str); printf(&quot;Data written in memory: %s\\n&quot;,str); //detach from shared memory shmdt(str); return 0; &#125; // Reader #include &lt;iostream&gt; #include &lt;sys/ipc.h&gt; #include &lt;sys/shm.h&gt; #include &lt;stdio.h&gt; using namespace std; int main() &#123; // ftok to generate unique key key_t key = ftok(&quot;shmfile&quot;,65); // shmget returns an identifier in shmid int shmid = shmget(key,1024,0666|IPC_CREAT); // shmat to attach to shared memory char *str = (char*) shmat(shmid,(void*)0,0); printf(&quot;Data read from memory: %s\\n&quot;,str); //detach from shared memory shmdt(str); // destroy the shared memory shmctl(shmid,IPC_RMID,NULL); return 0; &#125; 共享内存不仅仅可以作为消息通信，还可以作为进程共享其他数据用于通信、同步、互斥等，例如共享内存的锁，信号量等等。 信号量信号量不仅可以用于线程之间通信（原理和使用见[读者写者文章](.&#x2F;reader-writer control)），还可以在进程之间通信。 信号量其实是一个整型的计数器，主要用于实现进程间的互斥与同步，而不是用于缓存进程间通信的数据。 而信号量在进程之间通信主要依赖于共享内存，并强转成对应的类型。 代码同共享内存和[读者写着文章](.&#x2F;reader-writer control)类似，关键在于分配内存后强转成信号量类型。 sme_t *str = (sem_t*) shmat(shmid, NULL, 0); 信号信号和信号量是完全不同的东西，但也可以用于通信。不过，不同与其他方式，信号一般用于异常通信。 例如，可以在代码中使用system call kill 来关闭一个进程。 int kill(pid_t pid, int sig); 或者直接在shell中使用kill。可以通过kill -l查看参数 1) SIGHUP 2) SIGINT 3) SIGQUIT 4) SIGILL 5) SIGTRAP 6) SIGABRT 7) SIGBUS 8) SIGFPE 9) SIGKILL 10) SIGUSR1 11) SIGSEGV 12) SIGUSR2 13) SIGPIPE 14) SIGALRM 15) SIGTERM 16) SIGSTKFLT 17) SIGCHLD 18) SIGCONT 19) SIGSTOP 20) SIGTSTP 21) SIGTTIN 22) SIGTTOU 23) SIGURG 24) SIGXCPU 25) SIGXFSZ 26) SIGVTALRM 27) SIGPROF 28) SIGWINCH 29) SIGIO 30) SIGPWR 31) SIGSYS 34) SIGRTMIN 35) SIGRTMIN+1 36) SIGRTMIN+2 37) SIGRTMIN+3 38) SIGRTMIN+4 39) SIGRTMIN+5 40) SIGRTMIN+6 41) SIGRTMIN+7 42) SIGRTMIN+8 43) SIGRTMIN+9 44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+12 47) SIGRTMIN+13 48) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-14 51) SIGRTMAX-13 52) SIGRTMAX-12 53) SIGRTMAX-11 54) SIGRTMAX-10 55) SIGRTMAX-9 56) SIGRTMAX-8 57) SIGRTMAX-7 58) SIGRTMAX-6 59) SIGRTMAX-5 60) SIGRTMAX-4 61) SIGRTMAX-3 62) SIGRTMAX-2 63) SIGRTMAX-1 64) SIGRTMAX 常用的如 Ctrl+C 产生 SIGINT 信号，表示终止该进程； Ctrl+Z 产生 SIGTSTP 信号，表示停止该进程，但还未结束； 如果进程在后台运行，可以通过 kill 命令的方式给进程发送信号，但前提需要知道运行中的进程 PID 号，例如： kill -9 1050 ，表示给 PID 为 1050 的进程发送 SIGKILL 信号，用来立即结束该进程； 所以，信号事件的来源主要有硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令）。 信号是进程间通信机制中唯一的异步通信机制，因为可以在任何时候发送信号给某一进程，一旦有信号产生，我们就有下面这几种，用户进程对信号的处理方式。 1.执行默认操作。Linux 对每种信号都规定了默认操作，例如，上面列表中的 SIGTERM 信号，就是终止进程的意思。 2.捕捉信号。我们可以为信号定义一个信号处理函数。当信号发生时，我们就执行相应的信号处理函数。 3.忽略信号。当我们不希望处理某些信号的时候，就可以忽略该信号，不做任何处理。有两个信号是应用进程无法捕捉和忽略的，即 SIGKILL 和 SEGSTOP，它们用于在任何时候中断或结束某一进程。 实际上，对于每个进程的信号处理函数，是可以自定义的。使用signal来注册。 //define my signal handler. void sig_handler(int signum)&#123; printf(&quot;\\nInside handler function\\n&quot;); &#125; int main() &#123; singal(SIGINT, sig_handler); // register. &#125; 实际上，Java虚拟机就用到了这一技巧，使得崩溃的线程不会导致JVM崩溃。 Socket前面提到的种种方式，都是本地通信。要做到与不同主机的通信，就需要用到网络通信，就需要Socket了。 Socket编程对应两种网络协议，TCP和UDP。创建Socket需要指定相关参数 int socket(int domain, int type, int protocol); domain 参数用来指定协议族，比如 AF_INET 用于 IPV4、AF_INET6 用于 IPV6、AF_LOCAL&#x2F;AF_UNIX 用于本机； type 参数用来指定通信特性，比如 SOCK_STREAM 表示的是字节流，对应 TCP、SOCK_DGRAM 表示的是数据报，对应 UDP、SOCK_RAW 表示的是原始套接字； protocal 参数原本是用来指定通信协议的，但现在基本废弃。因为协议已经通过前面两个参数指定完成，protocol 目前一般写成 0 即可； Socket相关的内容篇幅有点大，就不展开了。以后再写一篇文章吧。","categories":[{"name":"Articles","slug":"Articles","permalink":"https://messenger1th.github.io/categories/Articles/"}],"tags":[]},{"title":"Binary Tree Traversal","slug":"Articles/Binary Tree Traversal","date":"2024-07-24T14:47:33.900Z","updated":"2024-07-24T14:47:33.900Z","comments":true,"path":"2024/07/24/Articles/Binary Tree Traversal/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Articles/Binary%20Tree%20Traversal/","excerpt":"","text":"Binary Tree TraversalRecursionvoid preOrder(vector&lt;int&gt;&amp; res,TreeNode* root)&#123; if(!root) &#123; return; &#125; res.emplace_back(root-&gt;val); preOrder(res, root-&gt;left); preOrder(res, root-&gt;right); &#125; void inOrder(vector&lt;int&gt;&amp; res,TreeNode* root)&#123; if(!root) &#123; return; &#125; inOrder(res, root-&gt;left); res.emplace_back(root-&gt;val); inOrder(res, root-&gt;right); &#125; void postOrder(vector&lt;int&gt;&amp; res,TreeNode* root)&#123; if(!root) &#123; return; &#125; postOrder(res, root-&gt;left); postOrder(res, root-&gt;right); res.emplace_back(root-&gt;val); &#125; Iteration: Recommendvector&lt;int&gt; preorderTraversal(TreeNode* root) &#123; vector&lt;int&gt; res; stack&lt;TreeNode*&gt; stk; TreeNode* node = root; while (node || !stk.empty()) &#123; while (node) &#123; res.emplace_back(node-&gt;val); //收集答案和DFS顺序一致 stk.emplace(node); node = node-&gt;left; &#125; node = stk.top(); stk.pop(); //回到子树根节点 node = node-&gt;right; //子树右子节点 &#125; return res; &#125; vector&lt;int&gt; inorderTraversal(TreeNode* root) &#123; vector&lt;int&gt; res; stack&lt;TreeNode*&gt; stk; TreeNode* node = root; while (node || !stk.empty()) &#123; while (node) &#123; stk.emplace(node); node = node-&gt;left; &#125; node = stk.top(); stk.pop(); //回到子树根节点 res.emplace_back(node-&gt;val); //收集根节点 node = node-&gt;right; //子树右子节点 &#125; return res; &#125; vector&lt;int&gt; postorderTraversal(TreeNode* root) &#123; vector&lt;int&gt; res; stack&lt;TreeNode*&gt; stk; TreeNode* node = root; TreeNode* lastFinished = nullptr; while (node || !stk.empty()) &#123; while (node) &#123; stk.emplace(node); node = node-&gt;left; &#125; node = stk.top(); stk.pop(); //回到子树根节点, 因为第一次回到时没遍历右子树，故需要一个变量判断是第一次还是第二次 if (node-&gt;right == nullptr || node-&gt;right == lastFinished) &#123; //第二次或者没有右节点。 lastFinished = node; //将该子树根节点设置为已完成。 res.emplace_back(node-&gt;val); node = nullptr; //也算是一种标记（即该树已经遍历完成）， 向上移动 &#125; else &#123; //第一次到子树根节点 stk.emplace(node); //入栈 node = node-&gt;right; //到右子树 &#125; &#125; return res; &#125; Iteration2: From Carlvector&lt;int&gt; preorderTraversal(TreeNode* root) &#123; vector&lt;int&gt; res; stack&lt;TreeNode*&gt; stk; if (root != NULL) stk.push(root); while (!stk.empty()) &#123; TreeNode* node = stk.top();stk.pop(); if (node != NULL) &#123; if (node-&gt;right) stk.push(node-&gt;right); // 右 if (node-&gt;left) stk.push(node-&gt;left); // 左 stk.push(node); // 中 stk.push(NULL); //标志位， 告诉根节点已经遍历过，需要收集答案 &#125; else &#123; node = stk.top(); stk.pop(); res.push_back(node-&gt;val); &#125; &#125; return res; &#125; vector&lt;int&gt; inorderTraversal(TreeNode* root) &#123; vector&lt;int&gt; res; stack&lt;TreeNode*&gt; stk; if (root != NULL) stk.push(root); while (!stk.empty()) &#123; TreeNode* node = stk.top();stk.pop(); if (node != NULL) &#123; if (node-&gt;right) stk.push(node-&gt;right); // 右 stk.push(node); // 中 stk.push(NULL); //标志位， 告诉根节点已经遍历过，需要收集答案 if (node-&gt;left) stk.push(node-&gt;left); // 左 &#125; else &#123; node = stk.top(); stk.pop(); res.push_back(node-&gt;val); &#125; &#125; return res; &#125; vector&lt;int&gt; postorderTraversal(TreeNode* root) &#123; vector&lt;int&gt; res; stack&lt;TreeNode*&gt; stk; if (root != NULL) stk.push(root); while (!stk.empty()) &#123; TreeNode* node = stk.top();stk.pop(); if (node != NULL) &#123; stk.push(node); // 中 stk.push(NULL); //标志位， 告诉根节点已经遍历过，需要收集答案 if (node-&gt;right) stk.push(node-&gt;right); // 右 if (node-&gt;left) stk.push(node-&gt;left); // 左 &#125; else &#123; node = stk.top(); stk.pop(); res.push_back(node-&gt;val); &#125; &#125; return res; &#125; Morrisvector&lt;int&gt; preorderTraversal(TreeNode* root) &#123; vector&lt;int&gt; res; TreeNode* node = root; while (node) &#123; if (node-&gt;left) &#123; TreeNode* predecessor = node-&gt;left; while (predecessor-&gt;right != nullptr &amp;&amp; predecessor-&gt;right != node) &#123; predecessor = predecessor-&gt;right; &#125; if (predecessor-&gt;right == node) &#123; predecessor-&gt;right = nullptr; node = node-&gt;right; &#125; else &#123; res.emplace_back(node-&gt;val); //向下的过程中需要收集， 也就是前序 predecessor-&gt;right = node; node = node-&gt;left; &#125; &#125; else &#123; res.emplace_back(node-&gt;val); //特殊处理， 没有左节点。 node = node-&gt;right; &#125; &#125; return res; &#125; vector&lt;int&gt; inorderTraversal(TreeNode* root) &#123; vector&lt;int&gt; res; TreeNode* node = root; while (node) &#123; if (node-&gt;left) &#123; TreeNode* predecessor = node-&gt;left; while (predecessor-&gt;right != nullptr &amp;&amp; predecessor-&gt;right != node) &#123; predecessor = predecessor-&gt;right; &#125; if (predecessor-&gt;right == node) &#123; res.emplace_back(node-&gt;val); //返回的过程中收集， 中序遍历 predecessor-&gt;right = nullptr; node = node-&gt;right; &#125; else &#123; predecessor-&gt;right = node; node = node-&gt;left; &#125; &#125; else &#123; res.emplace_back(node-&gt;val); //没有左节点，也算是从nullptr返回，特判收集。 node = node-&gt;right; &#125; &#125; return res; &#125; void addResult(vector&lt;int&gt;&amp; res, TreeNode* root) &#123; int cnt = 0; while (root) &#123; res.emplace_back(root-&gt;val); ++cnt; root = root-&gt;right; &#125; reverse(res.end() - cnt, res.end()); &#125; vector&lt;int&gt; postorderTraversal(TreeNode* root) &#123; vector&lt;int&gt; res; TreeNode* node = root; while (node) &#123; if (node-&gt;left) &#123; TreeNode* predecessor = node-&gt;left; while (predecessor-&gt;right != nullptr &amp;&amp; predecessor-&gt;right != node) &#123; predecessor = predecessor-&gt;right; &#125; if (predecessor-&gt;right == node) &#123; //第二次回到子树的根节点，代表左子树已经遍历完成 predecessor-&gt;right = nullptr; addResult(res, node-&gt;left); //收集左子树的右节点信息和根节点信息。 node = node-&gt;right; &#125; else &#123; predecessor-&gt;right = node; node = node-&gt;left; &#125; &#125; else &#123; node = node-&gt;right; &#125; &#125; addResult(res, root); //遍历完成， 整树右节点也需要遍历。 return res; &#125; 以上就是统一遍历法的写法了。 迭代法理解对于树的遍历，共有3种情况 第一次到根节点 左子树遍历完到根节点 右子树遍历完到根节点 对于三种遍历方式， 我们可以通过当前节点是否入栈来简化一些代码逻辑。 如preOrder只需要入栈左右子树， inOrder需要入栈3种节点，postOrder入栈3种节点， 但有多种节点访问状态。我们来看具体分析。 PreOrderTraversal对于preOrderTraversal, 只用考虑一种情况 第一次到根节点 因为， 对于preOrderTraversal， 收集答案的顺序和DFS遍历顺序是一致的。无需重复入栈。 不难写出如下代码, 每个节点都不需要重复入栈，取出便收集，有子树才入栈子树。 vector&lt;int&gt; preorderTraversal(TreeNode* root) &#123; vector&lt;int&gt; res; stack&lt;TreeNode*&gt; stk; if (root) &#123; stk.emplace(root); &#125; while (!stk.empty()) &#123; //没有对node进行状态判断， 因为只有一种情况。 TreeNode* node = stk.top(); stk.pop(); res.emplace_back(node-&gt;val); if (node-&gt;right) &#123; stk.emplace(node-&gt;right); &#125; if (node-&gt;left) &#123; stk.emplace(node-&gt;left); &#125; &#125; return res; &#125; InOrderTraversal对于inOrderTraversal, 只用考虑两种状态 第一次到根节点 左子树遍历完到根节点 因为在收集完根节点答案后，无需再借用根节点访问子节点，因此不用再次入栈， 也就是右子树收集完后，栈就为空了。 因此， 相比于统一法，有如下一种更好理解的方式。 vector&lt;int&gt; inorderTraversal(TreeNode* root) &#123; vector&lt;int&gt; res; stack&lt;TreeNode*&gt; stk; TreeNode* node = root; while (node || !stk.empty()) &#123; if (node == nullptr) &#123; //状态2：说明左子树遍历完成。 res.emplace_back(stk.top()-&gt;val); //收集在栈顶的根节点 node = stk.top()-&gt;right; //右子树 stk.pop(); //收集完就可以把根节点扔了 &#125; else &#123; //状态1：第一次到子树根节点 stk.emplace(node); //向左移动前先保存下， 因为需要二次访问。 node =node-&gt;left; &#125; &#125; return res; &#125; PostOrderTraversal对于posrOrderTraversal，3种情况都需要考虑 第一次到根节点 左子树遍历完回到根节点 右子树遍历完回到根节点 那它能否像InOrderTraversal一样，在while (node || !stk.empty())中用if直接判断状态呢？ 答案是：可以。 但是，由于目前我们只知道node是否为nullptr， 这是不足以区分这3种状态的，因此，我们采用哈希集合leftFinished来区分左子树是否遍历完成。 因此， posrOrderTraversal也可以同理实现。 vector&lt;int&gt; postorderTraversal(TreeNode* root) &#123; unordered_set&lt;TreeNode*&gt; leftFinished; stack&lt;TreeNode*&gt; stk; TreeNode* node = root; vector&lt;int&gt; res; while (node || !stk.empty()) &#123; if (node == nullptr &amp;&amp; leftFinished.count(stk.top())) &#123; //状态3: 左子树已经遍历，同时node为空， 也就是右子树也完成。 res.emplace_back(stk.top()-&gt;val); stk.pop(); // &#125; else if (node == nullptr) &#123; //状态2：左子树完了，栈顶是根节点 //左子树为空，也就是遍历完成， 将根节点（栈顶）加入集合 leftFinished.insert(stk.top()); //不弹栈，因为需要二次遍历 node = stk.top()-&gt;right;// 直接进入右子树。 &#125; else &#123; //状态1 stk.emplace(node); node = node-&gt;left; &#125; &#125; return res; &#125; 总结实际上， 迭代法做不到递归那样优雅是因为需要我们自己显式地区分状态。 在递归中，函数递归调用之前，会将当前信息压栈，以方便下一层递归结束，回到本层时，能够按照代码编写顺序执行。这个过程，就是状态区分的过程。 而迭代， 我们编码习惯导致， 我们仅仅知道node是否等于nullptr，preOrder和inOrder尚且可以用其区分状态。 但postOrder就不行了，需要辅助空间（如哈希集合，如Carl的stack加入nullptr标志位）， 或者，换一种编码思路,如Leetcode官方解答中使用的while(node)， 直接遍历到所有左节点，在这种情况下，一个**额外的lastFinished指针结合node**就可以区分这三种状态。 更新前序遍历 vector&lt;int&gt; preorderTraversal(TreeNode* root) &#123; stack&lt;TreeNode*&gt; stack; TreeNode* curr = root; vector&lt;int&gt; res; while (!stack.empty() || curr != nullptr) &#123; while (curr != nullptr) &#123; res.emplace_back(curr-&gt;val); stack.emplace(curr); curr = curr-&gt;left; &#125; curr = stack.top(); stack.pop(); curr = curr-&gt;right; &#125; return res; &#125; 中序遍历 vector&lt;int&gt; inorderTraversal(TreeNode* root) &#123; stack&lt;TreeNode*&gt; stack; vector&lt;int&gt; res; TreeNode* curr = root; while (!stack.empty() || curr != nullptr) &#123; while (curr != nullptr) &#123; stack.emplace(curr); curr = curr-&gt;left; &#125; curr = stack.top(); stack.pop(); res.emplace_back(curr-&gt;val); curr = curr-&gt;right; &#125; return res; &#125; 后序遍历vector&lt;int&gt; postorderTraversal(TreeNode* root) &#123; stack&lt;TreeNode*&gt; stack; TreeNode* hasTraversaled = nullptr; TreeNode* curr = root; vector&lt;int&gt; res; while (!stack.empty() || curr != nullptr) &#123; while (curr != nullptr) &#123; stack.emplace(curr); curr = curr-&gt;left; &#125; curr = stack.top(); stack.pop(); if (curr-&gt;right == hasTraversaled || curr-&gt;right == nullptr) &#123; hasTraversaled = curr; res.emplace_back(curr-&gt;val); curr = nullptr; &#125; else &#123; stack.emplace(curr); curr = curr-&gt;right; &#125; &#125; return res; &#125;","categories":[{"name":"Articles","slug":"Articles","permalink":"https://messenger1th.github.io/categories/Articles/"}],"tags":[]},{"title":"Compile&Link","slug":"Articles/Compile&Link","date":"2024-07-24T14:47:33.900Z","updated":"2024-07-24T14:47:33.900Z","comments":true,"path":"2024/07/24/Articles/Compile&Link/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Articles/Compile&Link/","excerpt":"","text":"编译和链接起因最近使用到一个简易RPC库，依赖项只有消息队列ZeroMQ，对应库名字是zmq。 目录结构如下 ├── buttonrpc.hpp ├── CMakeLists.txt ├── example │ ├── main_client.cpp │ └── main_server.cpp ├── README.md └── Serializer.hpp 在自定义的头文件中buttonrpc.hpp中用到了zmq库，我使用apt下载下来。 其中CMakeLists.txt文件内容如下 cmake_minimum_required(VERSION 3.23) project(buttonrpc_cpp14) set(CMAKE_CXX_STANDARD 14) include_directories(.) //添加头文件的查找路径，这样example目录下的cpp可以直接引入头文件而非完整路径。 add_executable(buttonrpc_cpp14 example/main_client.cpp) CMakeLists.txt的配置是没问题的，但使用CLionIDE编译运行时出现如下链接错误。 /usr/bin/ld: CMakeFiles/buttonrpc_cpp14.dir/example/main_client.cpp.o: in function `zmq::error_t::error_t()&#x27;: /usr/include/zmq.hpp:292: undefined reference to `zmq_errno&#x27; 在次这前，我一直以为是只要引入头文件即可使用其内容。 然而事实是，需要链接。 知识梳理编译链接生成可执行文件实际需要四个步骤，以及他们对应的g++命令 预处理（pre-process）g++ -E Preprocess only; do not compile, assemble or link. 编译 （Compile）g++ -S Compile only; do not assemble or link. 汇编（assemble）g++ -c Compile and assemble, but do not link. 链接 （link）g++ -l Place the output into file. 他们处理之后的文件后缀分别为 g++ -E main.cpp &gt; main.i 预处理后的文件 linux下以.i为后缀名，这个过程只激活预处理，不生成文件,因此你需要把它重定向到一个输出文件里 。 g++ -S main.cpp 生成main.s汇编文件。 g++ -c main.cpp生成main.o含机器指令的目标文件。 g++ main.o 链接相关文件并生成 a.out (可使用-o指定文件名字)可执行文件。 一般，直接使用g++ -c编译所有文件，然后使用g++ -o进行链接。 如果需要链接一些第三方库，需要g++ -o -l -l后面接库名。 实际上，C++标准库也是需要链接的，g++会默认链接它们，无须显式链接。 静态库和动态库静态库命名规则： Linux：libxxx.a window: libxxx.lib 制作： gcc -c file1.c file2.c ar rcs libxxx.a file1.o file2.o 动态库 命名规则： Linux：libxxx.so windows: libxxx.dll 制作 gcc -c -fpic file1.c file2.c gcc -shared file1.o file2.o -o - libxxx.so 编译后需要修改文件或环境变量。 工作原理 静态库工作gcc链接时会把静态库中的代码打包到可执行文件中。 动态库gcc链接时，动态库的代码不会被打包到可执行文件中。 当程序启动后，动态库会被动态加载到内存中，通过ldd file命令检查动态库依赖关系 系统的动态载入器获取依赖库的绝对路径。对于elf格式的可执行程序，是由ld_linux.so来完成。 先后检查文件的DT_RPATHH - &gt; LD_LIBRARY_PATH-&gt;etc/ld.so.cache文件列表-&gt;lib-&gt;/usr/lib目录后载入内存 对比 静态 动态 优点 打包、加载速度快、打包无需提供静态库、移植方便 可以实现进程中资源共享、更新、部署、发布简单 缺点 消耗系统资源，浪费内存。更新、部署、发布麻烦 加载速度慢、发布程序时需要提供依赖的动态库","categories":[{"name":"Articles","slug":"Articles","permalink":"https://messenger1th.github.io/categories/Articles/"}],"tags":[]},{"title":"Consistency","slug":"Articles/Consistency","date":"2024-07-24T14:47:33.900Z","updated":"2024-07-24T14:47:33.900Z","comments":true,"path":"2024/07/24/Articles/Consistency/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Articles/Consistency/","excerpt":"","text":"一致性一致性模型有很多，如 线性一致性 顺序一致性 因果一致性 最终一致性 等等。 线性一致性线性一致性一开始是在并发领域提出的。 并发角度一致性模型是指，在并发编程中，系统和开发者之间的一种约定。如果开发者遵循某种规则，那么开发者执行读操作或者写操作的结果是可预测的。 重点落在可预测的，可预测保证了程序逻辑的确定性。这么说起来很抽象， 在我看来，从并发角度，线性一致性避免了data race的问题，让读写操作串行化。 在每次读操作时，都能看到最新的写操作的结果。 分布式角度非严格定义：线性一致性保证分布式系统的所有操作都像原子操作，且分布式系统看起来仅仅只有一个节点。 严格定义：给点一个执行历史，根据并发操作可以扩展成多个执行序列，只要从中找出一个符合现实观察的历史，那就是线性一致的。 在我看来，一致性算是程序给用户的对于执行顺序某种保证。 比如，线性一致性保证了用户请求按照请求时间顺序执行，不同用户的命令执行顺序根据全局时间排序来执行，当然并发关系的操作的执行顺序就看程序怎么安排，这是无法保证的。 而顺序一致性只保证了一个用户的所有请求的执行顺序，而不同用户之间的请求顺序是无法保证的，可能用户 A先请求，B后请求，但用户B的请求先执行。 例子拿Raft算法举例，Raft论文中提到的最基本Raft实现（读写都是log）就是线性一致性的。 所有用户的请求，不论读写，都是在leader上请求，这就保证了后续的读一定是更新的结果。 可能你会说，leader也是会更换的呀？不同的server的日志是不同呀的？ Raft算法保证了，只有apply了的的请求才能做出回应，而apply &lt;= commit， commit了的log就一定复制到了大多数server上，就保证了就算leader变更，新leader也保留有新日志。 由于读写都是log，都需要commit后才回复，因此不论读写，Raft都保证了线性一致性。 但对于部分Raft读改进版来说，写是线性一致性写，但读不是。 写是需要改变状态机的状态的，因此写操作仍是需要apply的，但读操作不是，读并不改变状态机的状态，无需经过提交也很合理，同时也为了减轻leader的负担，Raft改进版就可以从读下手。 让其他server直接返回读的结果，无须经过leader来操作，对于任意一个server，只有他的log跟leader保持最新，他才可以说是线性一致性的。否则，读到的就不是最新的结果。就无法保证线性一致性，甚至是顺序一致性。","categories":[{"name":"Articles","slug":"Articles","permalink":"https://messenger1th.github.io/categories/Articles/"}],"tags":[]},{"title":"Hash Table","slug":"Articles/Hash Table","date":"2024-07-24T14:47:33.900Z","updated":"2024-07-24T14:47:33.901Z","comments":true,"path":"2024/07/24/Articles/Hash Table/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Articles/Hash%20Table/","excerpt":"","text":"Hash TableHash table is a actually a array . APIIt’s all O(1) time and space complexity for each function. insert search get delete Hash Function Single Function Double hash Function Hash Collisionwhat is hash collisionIt’s collision that different key has same hash value. hash is a kind of summary algorithm which compress information meaning that it’s definitely possible to collision. How to solve collision Linked hash table. Used by Linux kernel. Mostly used other application. linear detect to find next place. multi-level hash table. Cuckoo hash table. Cuckoo hash tableEach element in the hash table is a fixed size array called bucket. After the first hashing, looking for the index in the bucket, If it’s collision, it will look for another bucket’s place rather than reallocate space. Advantage Best performance and convenient for lock-free : multi-level hash table best shared between processes : Cuckoo hash table. because of its fixed size, which is easy to map file to memory. less memory usage : linked hash table Load Factor: When to rehashingWay to rehashit’s time to rehash after element rate is bigger than load factor, . block rehashing asynchronous rehashing double hash table for quick rehashing lazy rehashing: Used by Redis Asynchronous Rehashing start a new process to execute the task copying from origin table to bigger one record incoming request while rehashing using message queue or something else. Double hash table for quick rehashingexecute request for both origin table and bigger one. replace origin one by the bigger when it’s time to rehash and reallocate a bigger than current origin table. Lazy Rehashingwhen reach the rate, allocate the space for the bigger table. move the associated element when next request is coming.","categories":[{"name":"Articles","slug":"Articles","permalink":"https://messenger1th.github.io/categories/Articles/"}],"tags":[]},{"title":"Counting Sort","slug":"Articles/Counting Sort","date":"2024-07-24T14:47:33.900Z","updated":"2024-07-24T14:47:33.900Z","comments":true,"path":"2024/07/24/Articles/Counting Sort/","link":"","permalink":"https://messenger1th.github.io/2024/07/24/Articles/Counting%20Sort/","excerpt":"","text":"计数排序：Counting Sort时间复杂度：$O(n)$ 空间复杂度：$O(maxValue - minValue)$ 适用于数据范围比较小。 简单计数排序如果只是普通的值、直接排序即可。代码如下 vector&lt;int&gt; countingSort(const vector&lt;int&gt;&amp; arr) &#123; int max = *max_element(arr.begin(), arr.end()); int min = *min_element(arr.begin(), arr.end()); int n = max - min + 1; vector&lt;int&gt; count(n, 0); for (const auto&amp; e: arr) &#123; ++count[e - min]; &#125; vector&lt;int&gt; res; res.reserve(arr.size()); for (int i = 0; i &lt; n; ++i) &#123; int val = i + min; int cnt = count[i]; for (int j = 0; j &lt; cnt; ++j) &#123; res.emplace_back(val); &#125; &#125; return res; &#125; 计数排序（稳定）：实际应用考虑这样一种情况，我们有一个app，有用户类，需要对用户地年龄进行排序。上述代码还可行吗？ 对于用户，不仅含有一个值、还有其他很多信息。 拿年龄排序举例，尽管每个人的年龄相同，但他们不是同一个人。就不能简简单单地直接进行对值进行计数，然后赋值。 那计数排序行不通了吗？答案是可以的。先上代码。 #include &lt;bits/stdc++.h&gt; using namespace std; class User&#123; public: int age; string name; User(string name, int age) : name(name), age(age) &#123;&#125; &#125;; using UserPtr = shared_ptr&lt;User&gt;; auto comp1 = [] (const auto&amp; prev, const auto&amp; curr) &#123; return prev-&gt;age &lt; curr-&gt;age; &#125;; auto comp2 = [] (const auto&amp; prev, const auto&amp; curr) &#123; return prev-&gt;age &gt; curr-&gt;age; &#125;; vector&lt;UserPtr&gt; countingSort(const vector&lt;UserPtr&gt;&amp; arr) &#123; int maxAge = (*max_element(arr.begin(), arr.end(), comp1))-&gt;age; int minAge = (*max_element(arr.begin(), arr.end(), comp2))-&gt;age; int n = maxAge - minAge + 1; vector&lt;int&gt; count(n, 0); for (const auto&amp; ptr: arr) &#123; ++count[ptr-&gt;age - minAge]; &#125; partial_sum(count.begin(), count.end(), count.begin()); vector&lt;UserPtr&gt; res(arr.size()); for (int i = arr.size() - 1; i &gt;= 0; --i) &#123; int index = count[arr[i]-&gt;age - minAge] - 1; res[i] = arr[index]; --count[arr[i]-&gt;age - minAge]; &#125; return res; &#125; int main() &#123; UserPtr user1 (new User(&quot;zhangsan&quot;, 1)); UserPtr user2 (new User(&quot;lisi&quot;, 2)); UserPtr user3 (new User(&quot;liu5&quot;, 1)); vector&lt;UserPtr&gt; arr&#123;user1, user2, user3&#125;; arr = countingSort(arr); for (const auto&amp; ptr: arr) &#123; printf(&quot;%s %d\\n&quot;, ptr-&gt;name.c_str(), ptr-&gt;age); &#125; &#125; 我们使用用户指针来排序，避免用户数据的冗余构造和析构。 核心代码精简下来，精简下无关代码如下。 vector&lt;int&gt; countingSort(vector&lt;int&gt; nums) &#123; int max = *max_element(nums.begin(), nums.end()); int min = *min_element(nums.begin(), nums.end()); int n = max - min + 1; vector&lt;int&gt; count(n, 0); for (const auto&amp; e: nums) &#123; ++count[e - min]; &#125; partial_sum(count.begin(), count.end(), count.begin()); //count: 前缀和，表示该值(包括该值)对应的坐标前面有多少个元素. vector&lt;int&gt; res(nums.size()); for (int i = nums.size() - 1; i &gt;= 0; --i) &#123; int index = count[nums[i] - min] - 1; res[index] = nums[i]; --count[nums[i] - min]; &#125; return res; &#125; 步骤如下 计算出容量大小n = max - min + 1 对于每个坐标进行次数统计 前缀和运算. 从后向前(从后向前主要是为了稳定性)进行放置","categories":[{"name":"Articles","slug":"Articles","permalink":"https://messenger1th.github.io/categories/Articles/"}],"tags":[]}],"categories":[{"name":"Work","slug":"Work","permalink":"https://messenger1th.github.io/categories/Work/"},{"name":"Tools","slug":"Tools","permalink":"https://messenger1th.github.io/categories/Tools/"},{"name":"Redis","slug":"Redis","permalink":"https://messenger1th.github.io/categories/Redis/"},{"name":"Others","slug":"Others","permalink":"https://messenger1th.github.io/categories/Others/"},{"name":"Operating System","slug":"Operating-System","permalink":"https://messenger1th.github.io/categories/Operating-System/"},{"name":"MySQL","slug":"MySQL","permalink":"https://messenger1th.github.io/categories/MySQL/"},{"name":"Linux","slug":"Linux","permalink":"https://messenger1th.github.io/categories/Linux/"},{"name":"LeetCode","slug":"LeetCode","permalink":"https://messenger1th.github.io/categories/LeetCode/"},{"name":"Dynamic Programming","slug":"LeetCode/Dynamic-Programming","permalink":"https://messenger1th.github.io/categories/LeetCode/Dynamic-Programming/"},{"name":"Internet","slug":"Internet","permalink":"https://messenger1th.github.io/categories/Internet/"},{"name":"TCP&IP","slug":"Internet/TCP-IP","permalink":"https://messenger1th.github.io/categories/Internet/TCP-IP/"},{"name":"HTTP","slug":"Internet/HTTP","permalink":"https://messenger1th.github.io/categories/Internet/HTTP/"},{"name":"Golang","slug":"Golang","permalink":"https://messenger1th.github.io/categories/Golang/"},{"name":"C++","slug":"C","permalink":"https://messenger1th.github.io/categories/C/"},{"name":"Articles","slug":"Articles","permalink":"https://messenger1th.github.io/categories/Articles/"}],"tags":[]}